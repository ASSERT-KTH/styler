{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_1</th>\n",
       "      <th>ws</th>\n",
       "      <th>token_2</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Comment</td>\n",
       "      <td>1_NL</td>\n",
       "      <td>Comment</td>\n",
       "      <td>3282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Comment</td>\n",
       "      <td>1_NL</td>\n",
       "      <td>package</td>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>package</td>\n",
       "      <td>1_SP</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>2083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Identifier</td>\n",
       "      <td>0_SP</td>\n",
       "      <td>.</td>\n",
       "      <td>135330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>.</td>\n",
       "      <td>0_SP</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>146617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Identifier</td>\n",
       "      <td>0_SP</td>\n",
       "      <td>;</td>\n",
       "      <td>28148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>;</td>\n",
       "      <td>1_NL</td>\n",
       "      <td>EOF</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>;</td>\n",
       "      <td>2_NL</td>\n",
       "      <td>import</td>\n",
       "      <td>2961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>import</td>\n",
       "      <td>1_SP</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>15630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>;</td>\n",
       "      <td>1_NL</td>\n",
       "      <td>import</td>\n",
       "      <td>13795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      token_1    ws     token_2   count\n",
       "0     Comment  1_NL     Comment    3282\n",
       "1     Comment  1_NL     package     492\n",
       "2     package  1_SP  Identifier    2083\n",
       "3  Identifier  0_SP           .  135330\n",
       "4           .  0_SP  Identifier  146617\n",
       "5  Identifier  0_SP           ;   28148\n",
       "6           ;  1_NL         EOF       4\n",
       "7           ;  2_NL      import    2961\n",
       "8      import  1_SP  Identifier   15630\n",
       "9           ;  1_NL      import   13795"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../three_grams.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df = df.loc[:,['token_1', 'token_2', 'count']].groupby(['token_1', 'token_2']).agg(['count', 'sum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = count_df['count']['count']\n",
    "good_for_insertion = list(count[count>=2].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_for_insertion_index = []\n",
    "for index, (token_1, token_2) in df.loc[:,['token_1', 'token_2']].iterrows():\n",
    "    if (token_1, token_2) in good_for_insertion:\n",
    "        good_for_insertion_index.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_for_insertion_df = df.iloc[good_for_insertion_index ,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_for_insertion_set = set(\n",
    "    good_for_insertion\n",
    ")\n",
    "def is_good_for_insertion(token_a, token_b):\n",
    "    return (token_a, token_b) in good_for_insertion_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_alternatives_with_probability(token_a, ws, token_b):\n",
    "    df_token_1 = good_for_insertion_df[good_for_insertion_df.token_1 == token_a]\n",
    "    df_token_1_and_2 = df_token_1[df_token_1.token_2 == token_b]\n",
    "    final = df_token_1_and_2[df_token_1_and_2.ws != ws]\n",
    "    total = final['count'].sum()\n",
    "    return {\n",
    "        ws:count/total\n",
    "        for _, (_, ws, _, count) in final.iterrows()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2_NL': 0.6451612903225806,\n",
       " '2_NL_4_ID': 0.13978494623655913,\n",
       " '1_NL_8_ID': 0.010752688172043012,\n",
       " '3_NL': 0.010752688172043012,\n",
       " '1_NL_16_DD': 0.010752688172043012,\n",
       " '1_NL_4_DD': 0.053763440860215055,\n",
       " '2_NL_4_DD': 0.03225806451612903,\n",
       " '1_NL_8_DD': 0.03225806451612903,\n",
       " '2_NL_8_ID': 0.010752688172043012,\n",
       " '2_NL_8_DD': 0.010752688172043012,\n",
       " '1_NL_12_ID': 0.010752688172043012,\n",
       " '1_NL_2_ID': 0.010752688172043012,\n",
       " '1_NL_50_ID': 0.021505376344086023}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_alternatives_with_probability('Comment', '1_NL', 'Comment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import java_lang_utils as jlu\n",
    "from core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml import get_token_value, get_space_value\n",
    "from token_utils import whitespace_token_to_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Corpus import Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus('../corpora/repairnator-corpus/', 'repairnator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = jlu.Tokenizer()\n",
    "tokenizer_absolute = jlu.Tokenizer(relative=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../corpora/repairnator-corpus/data/51/MavenHelper.java'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_dir = corpus.files[10][2]\n",
    "file_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_source = open_file(file_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_random(alternatives):\n",
    "    random_number = random.random()\n",
    "    probability_sum = 0\n",
    "    for alternative, probability in alternatives.items():\n",
    "        probability_sum += probability\n",
    "        if random_number <= probability_sum:\n",
    "            return alternative\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_line_indent(line):\n",
    "    indent = 0\n",
    "    for c in line:\n",
    "        if c == ' ':\n",
    "            indent+=1\n",
    "        else:\n",
    "            return indent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_source(source, n_insertion=1):\n",
    "    tokenized_source = tokenizer.tokenize(source)\n",
    "    tokenized_source_absolute = tokenizer_absolute.tokenize(source)\n",
    "    insertion_spots = list(range(len(tokenized_source.tokens)-1))\n",
    "    random.shuffle(insertion_spots)\n",
    "    for spot in insertion_spots:\n",
    "        token_a = tokenized_source.tokens[spot]\n",
    "        token_b = tokenized_source.tokens[spot+1]\n",
    "        ws = tokenized_source.white_spaces[spot]\n",
    "        if is_good_for_insertion(get_token_value(token_a), get_token_value(token_b)):\n",
    "            alternatives = list_alternatives_with_probability(\n",
    "                get_token_value(token_a),\n",
    "                get_space_value(ws),\n",
    "                get_token_value(token_b)\n",
    "            )\n",
    "            alternative_selected = pick_random(alternatives)\n",
    "            alternative_selected_tuple = whitespace_token_to_tuple(alternative_selected)\n",
    "            new_ws = tokenized_source_absolute.white_spaces[spot]\n",
    "            if alternative_selected_tuple[0] == 0:\n",
    "                new_ws = alternative_selected_tuple\n",
    "            elif alternative_selected_tuple[0] != 0 and new_ws[0] == 0:\n",
    "                line = token_a.position[0]\n",
    "                indent = get_line_indent(source.split('\\n')[line-1])\n",
    "                new_ws = (alternative_selected_tuple[0], indent + alternative_selected_tuple[1])\n",
    "            else:\n",
    "                new_ws = (alternative_selected_tuple[0], new_ws[1] + (alternative_selected_tuple[1] - ws[1]))\n",
    "            if new_ws[1]>=0:\n",
    "                tokenized_source_absolute.white_spaces[spot] = new_ws\n",
    "                break\n",
    "    return tokenized_source_absolute.reformat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tokenizer_absolute.tokenize(original_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6c6,7\n",
      "< import fr.inria.spirals.repairnator.process.maven.output.MavenMuteOutputHandler;\n",
      "---\n",
      "> import fr.inria\n",
      ">     .spirals.repairnator.process.maven.output.MavenMuteOutputHandler;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modified_source = modify_source(original_source)\n",
    "file_A = save_file('./tmp/', 'orig.java', original_source)\n",
    "file_B = save_file('./tmp/', 'modif.java', modified_source)\n",
    "cmd = 'diff {} {}'.format(file_A, file_B)\n",
    "process = subprocess.Popen(cmd.split(\" \"), stdout=subprocess.PIPE)\n",
    "output = process.communicate()[0]\n",
    "print(output.decode(\"utf-8\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
