{
    "project_name": "IQSS-dataverse",
    "error_id": "101",
    "information": {
        "errors": [
            {
                "line": "127",
                "column": "13",
                "severity": "error",
                "message": "File contains tab characters (this is the first instance).",
                "source": "com.puppycrawl.tools.checkstyle.checks.whitespace.FileTabCharacterCheck"
            }
        ]
    },
    "source_code": "                ctxt.em().persist(editVersion);\n            } else {\n            \ttry {\n            \t\tctxt.em().merge(editVersion);\n            \t} catch (ConstraintViolationException e) {\n            \t\tlogger.log(Level.SEVERE,\"Exception: \");",
    "results": [
        {
            "tool": "styler",
            "errors": [
                {
                    "line": "128",
                    "column": "13",
                    "severity": "error",
                    "message": "File contains tab characters (this is the first instance).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.whitespace.FileTabCharacterCheck"
                }
            ],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/IQSS-dataverse/errored/1/101/UpdateDatasetVersionCommand.java b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/IQSS-dataverse/styler/101/UpdateDatasetVersionCommand.java\nindex 4da9e2fef2f..6b0be7b5e2c 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/IQSS-dataverse/errored/1/101/UpdateDatasetVersionCommand.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/IQSS-dataverse/styler/101/UpdateDatasetVersionCommand.java\n@@ -124,7 +124,7 @@ public class UpdateDatasetVersionCommand extends AbstractDatasetCommand<Dataset>\n             if (editVersion.getId() == null || editVersion.getId() == 0L) {\n                 ctxt.em().persist(editVersion);\n             } else {\n-            \ttry {\n+            try {\n             \t\tctxt.em().merge(editVersion);\n             \t} catch (ConstraintViolationException e) {\n             \t\tlogger.log(Level.SEVERE,\"Exception: \");\n",
            "diff_size": 1
        },
        {
            "tool": "intellij",
            "errors": [],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/IQSS-dataverse/errored/1/101/UpdateDatasetVersionCommand.java b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/IQSS-dataverse/intellij/101/UpdateDatasetVersionCommand.java\nindex 4da9e2fef2f..efcd71497d0 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/IQSS-dataverse/errored/1/101/UpdateDatasetVersionCommand.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/IQSS-dataverse/intellij/101/UpdateDatasetVersionCommand.java\n@@ -23,267 +23,270 @@ import javax.validation.ConstraintViolationException;\n import org.apache.solr.client.solrj.SolrServerException;\n \n /**\n- *\n  * @author skraffmiller\n  */\n @RequiredPermissions(Permission.EditDataset)\n public class UpdateDatasetVersionCommand extends AbstractDatasetCommand<Dataset> {\n \n-    private static final Logger logger = Logger.getLogger(UpdateDatasetVersionCommand.class.getCanonicalName());\n-    private final List<FileMetadata> filesToDelete;\n-    private boolean validateLenient = false;\n-    private final DatasetVersion clone;\n-    private final FileMetadata fmVarMet;\n-    \n-    public UpdateDatasetVersionCommand(Dataset theDataset, DataverseRequest aRequest) {\n-        super(aRequest, theDataset);\n-        this.filesToDelete = new ArrayList<>();\n-        this.clone = null;\n-        this.fmVarMet = null;\n-    }    \n-    \n-    public UpdateDatasetVersionCommand(Dataset theDataset, DataverseRequest aRequest, List<FileMetadata> filesToDelete) {\n-        super(aRequest, theDataset);\n-        this.filesToDelete = filesToDelete;\n-        this.clone = null;\n-        this.fmVarMet = null;\n+  private static final Logger logger = Logger.getLogger(UpdateDatasetVersionCommand.class.getCanonicalName());\n+  private final List<FileMetadata> filesToDelete;\n+  private boolean validateLenient = false;\n+  private final DatasetVersion clone;\n+  private final FileMetadata fmVarMet;\n+\n+  public UpdateDatasetVersionCommand(Dataset theDataset, DataverseRequest aRequest) {\n+    super(aRequest, theDataset);\n+    this.filesToDelete = new ArrayList<>();\n+    this.clone = null;\n+    this.fmVarMet = null;\n+  }\n+\n+  public UpdateDatasetVersionCommand(Dataset theDataset, DataverseRequest aRequest, List<FileMetadata> filesToDelete) {\n+    super(aRequest, theDataset);\n+    this.filesToDelete = filesToDelete;\n+    this.clone = null;\n+    this.fmVarMet = null;\n+  }\n+\n+  public UpdateDatasetVersionCommand(Dataset theDataset, DataverseRequest aRequest, List<FileMetadata> filesToDelete,\n+                                     DatasetVersion clone) {\n+    super(aRequest, theDataset);\n+    this.filesToDelete = filesToDelete;\n+    this.clone = clone;\n+    this.fmVarMet = null;\n+  }\n+\n+  public UpdateDatasetVersionCommand(Dataset theDataset, DataverseRequest aRequest, DataFile fileToDelete) {\n+    super(aRequest, theDataset);\n+\n+    // get the latest file metadata for the file; ensuring that it is a draft version\n+    this.filesToDelete = new ArrayList<>();\n+    this.clone = null;\n+    this.fmVarMet = null;\n+    for (FileMetadata fmd : theDataset.getEditVersion().getFileMetadatas()) {\n+      if (fmd.getDataFile().equals(fileToDelete)) {\n+        filesToDelete.add(fmd);\n+        break;\n+      }\n     }\n-    \n-    public UpdateDatasetVersionCommand(Dataset theDataset, DataverseRequest aRequest, List<FileMetadata> filesToDelete, DatasetVersion clone) {\n-        super(aRequest, theDataset);\n-        this.filesToDelete = filesToDelete;\n-        this.clone = clone;\n-        this.fmVarMet = null;\n+  }\n+\n+  public UpdateDatasetVersionCommand(Dataset theDataset, DataverseRequest aRequest, DatasetVersion clone) {\n+    super(aRequest, theDataset);\n+    this.filesToDelete = new ArrayList<>();\n+    this.clone = clone;\n+    this.fmVarMet = null;\n+  }\n+\n+  public UpdateDatasetVersionCommand(Dataset theDataset, DataverseRequest aRequest, FileMetadata fm) {\n+    super(aRequest, theDataset);\n+    this.filesToDelete = new ArrayList<>();\n+    this.clone = null;\n+    this.fmVarMet = fm;\n+  }\n+\n+  public boolean isValidateLenient() {\n+    return validateLenient;\n+  }\n+\n+  public void setValidateLenient(boolean validateLenient) {\n+    this.validateLenient = validateLenient;\n+  }\n+\n+  @Override\n+  public Dataset execute(CommandContext ctxt) throws CommandException {\n+    if (!(getUser() instanceof AuthenticatedUser)) {\n+      throw new IllegalCommandException(\"Only authenticated users can update datasets\", this);\n     }\n-    \n-    public UpdateDatasetVersionCommand(Dataset theDataset, DataverseRequest aRequest, DataFile fileToDelete) {\n-        super(aRequest, theDataset);\n-        \n-        // get the latest file metadata for the file; ensuring that it is a draft version\n-        this.filesToDelete = new ArrayList<>();\n-        this.clone = null;\n-        this.fmVarMet = null;\n-        for (FileMetadata fmd : theDataset.getEditVersion().getFileMetadatas()) {\n-            if (fmd.getDataFile().equals(fileToDelete)) {\n-                filesToDelete.add(fmd);\n-                break;\n-            }\n+\n+    Dataset theDataset = getDataset();\n+    ctxt.permissions().checkEditDatasetLock(theDataset, getRequest(), this);\n+    Dataset savedDataset = null;\n+\n+    try {\n+      // Invariant: Dataset has no locks preventing the update\n+      String lockInfoMessage = \"saving current edits\";\n+      DatasetLock lock = ctxt.datasets().addDatasetLock(getDataset().getId(), DatasetLock.Reason.EditInProgress,\n+        ((AuthenticatedUser) getUser()).getId(), lockInfoMessage);\n+      if (lock != null) {\n+        theDataset.addLock(lock);\n+      } else {\n+        logger.log(Level.WARNING, \"Failed to lock the dataset (dataset id={0})\", getDataset().getId());\n+      }\n+\n+      getDataset().getEditVersion(fmVarMet).setDatasetFields(getDataset().getEditVersion(fmVarMet).initDatasetFields());\n+      validateOrDie(getDataset().getEditVersion(fmVarMet), isValidateLenient());\n+\n+      final DatasetVersion editVersion = getDataset().getEditVersion(fmVarMet);\n+\n+      tidyUpFields(editVersion);\n+\n+      // Merge the new version into out JPA context, if needed.\n+      if (editVersion.getId() == null || editVersion.getId() == 0L) {\n+        ctxt.em().persist(editVersion);\n+      } else {\n+        try {\n+          ctxt.em().merge(editVersion);\n+        } catch (ConstraintViolationException e) {\n+          logger.log(Level.SEVERE, \"Exception: \");\n+          e.getConstraintViolations().forEach(err -> logger.log(Level.SEVERE, err.toString()));\n+          throw e;\n         }\n-    } \n-    \n-    public UpdateDatasetVersionCommand(Dataset theDataset, DataverseRequest aRequest, DatasetVersion clone) {\n-        super(aRequest, theDataset);\n-        this.filesToDelete = new ArrayList<>();\n-        this.clone = clone;\n-        this.fmVarMet = null;\n-    }\n+      }\n \n-    public UpdateDatasetVersionCommand(Dataset theDataset, DataverseRequest aRequest, FileMetadata fm) {\n-        super(aRequest, theDataset);\n-        this.filesToDelete = new ArrayList<>();\n-        this.clone = null;\n-        this.fmVarMet = fm;\n-    }\n+      for (DataFile dataFile : theDataset.getFiles()) {\n+        if (dataFile.getCreateDate() == null) {\n+          dataFile.setCreateDate(getTimestamp());\n+          dataFile.setCreator((AuthenticatedUser) getUser());\n+        }\n+        dataFile.setModificationTime(getTimestamp());\n+      }\n \n-    public boolean isValidateLenient() {\n-        return validateLenient;\n-    }\n+      // Remove / delete any files that were removed\n \n-    public void setValidateLenient(boolean validateLenient) {\n-        this.validateLenient = validateLenient;\n-    }\n+      // If any of the files that we are deleting has a UNF, we will need to\n+      // re-calculate the UNF of the version - since that is the product\n+      // of the UNFs of the individual files.\n+      boolean recalculateUNF = false;\n+      /*\n+       * The separate loop is just to make sure that the dataset database is updated,\n+       * specifically when an image datafile is being deleted, which is being used as\n+       * the dataset thumbnail as part of a batch delete. if we don't remove the\n+       * thumbnail association with the dataset before the actual deletion of the\n+       * file, it might throw foreign key integration violation exceptions.\n+       */\n+      for (FileMetadata fmd : filesToDelete) {\n+        // check if this file is being used as the default thumbnail\n+        if (fmd.getDataFile().equals(theDataset.getThumbnailFile())) {\n+          logger.fine(\"deleting the dataset thumbnail designation\");\n+          theDataset.setThumbnailFile(null);\n+        }\n \n-    @Override\n-    public Dataset execute(CommandContext ctxt) throws CommandException {\n-        if ( ! (getUser() instanceof AuthenticatedUser) ) {\n-            throw new IllegalCommandException(\"Only authenticated users can update datasets\", this);\n+        if (fmd.getDataFile().getUnf() != null) {\n+          recalculateUNF = true;\n         }\n-        \n-        Dataset theDataset = getDataset();        \n-        ctxt.permissions().checkEditDatasetLock(theDataset, getRequest(), this);\n-        Dataset savedDataset = null;\n-        \n-        try {\n-            // Invariant: Dataset has no locks preventing the update\n-            String lockInfoMessage = \"saving current edits\";\n-            DatasetLock lock = ctxt.datasets().addDatasetLock(getDataset().getId(), DatasetLock.Reason.EditInProgress, ((AuthenticatedUser) getUser()).getId(), lockInfoMessage);\n-            if (lock != null) {\n-                theDataset.addLock(lock);\n-            } else {\n-                logger.log(Level.WARNING, \"Failed to lock the dataset (dataset id={0})\", getDataset().getId());\n-            }\n-            \n-            getDataset().getEditVersion(fmVarMet).setDatasetFields(getDataset().getEditVersion(fmVarMet).initDatasetFields());\n-            validateOrDie(getDataset().getEditVersion(fmVarMet), isValidateLenient());\n-\n-            final DatasetVersion editVersion = getDataset().getEditVersion(fmVarMet);\n-            \n-            tidyUpFields(editVersion);\n-\n-            // Merge the new version into out JPA context, if needed.\n-            if (editVersion.getId() == null || editVersion.getId() == 0L) {\n-                ctxt.em().persist(editVersion);\n-            } else {\n-            \ttry {\n-            \t\tctxt.em().merge(editVersion);\n-            \t} catch (ConstraintViolationException e) {\n-            \t\tlogger.log(Level.SEVERE,\"Exception: \");\n-            \t\te.getConstraintViolations().forEach(err->logger.log(Level.SEVERE,err.toString()));\n-            \t\tthrow e;\n-            \t}\n-            }\n-\n-            for (DataFile dataFile : theDataset.getFiles()) {\n-                if (dataFile.getCreateDate() == null) {\n-                    dataFile.setCreateDate(getTimestamp());\n-                    dataFile.setCreator((AuthenticatedUser) getUser());\n-                }\n-                dataFile.setModificationTime(getTimestamp());\n-            }\n-\n-            // Remove / delete any files that were removed\n-\n-            // If any of the files that we are deleting has a UNF, we will need to\n-            // re-calculate the UNF of the version - since that is the product\n-            // of the UNFs of the individual files.\n-            boolean recalculateUNF = false;\n-            /*\n-             * The separate loop is just to make sure that the dataset database is updated,\n-             * specifically when an image datafile is being deleted, which is being used as\n-             * the dataset thumbnail as part of a batch delete. if we don't remove the\n-             * thumbnail association with the dataset before the actual deletion of the\n-             * file, it might throw foreign key integration violation exceptions.\n-             */\n-            for (FileMetadata fmd : filesToDelete) {\n-                // check if this file is being used as the default thumbnail\n-                if (fmd.getDataFile().equals(theDataset.getThumbnailFile())) {\n-                    logger.fine(\"deleting the dataset thumbnail designation\");\n-                    theDataset.setThumbnailFile(null);\n-                }\n-\n-                if (fmd.getDataFile().getUnf() != null) {\n-                    recalculateUNF = true;\n-                }\n-            }\n-            // we have to merge to update the database but not flush because\n-            // we don't want to create two draft versions!\n-            // Although not completely tested, it looks like this merge handles the\n-            // thumbnail case - if the filemetadata is removed from the context below and\n-            // the dataset still references it, that could cause an issue. Merging here\n-            // avoids any reference from it being the dataset thumbnail\n-            theDataset = ctxt.em().merge(theDataset);\n-\n-            /*\n-             * This code has to handle many cases, and anyone making changes should\n-             * carefully check tests and basic methods that update the dataset version. The\n-             * differences between the cases stem primarily from differences in whether the\n-             * files to add, and their filemetadata, and files to delete, and their\n-             * filemetadata have been persisted at this point, which manifests itself as to\n-             * whether they have id numbers or not, and apparently, whether or not they\n-             * exists in lists, e.g. the getFileMetadatas() list of a datafile.\n-             *\n-             * To handle this, the code is carefully checking to make sure that deletions\n-             * are deleting the right things and not, for example, doing a remove(fmd) when\n-             * the fmd.getId() is null, which just removes the first element found.\n-             */\n-            for (FileMetadata fmd : filesToDelete) {\n-                logger.fine(\"Deleting fmd: \" + fmd.getId() + \" for file: \" + fmd.getDataFile().getId());\n-                // if file is draft (ie. new to this version), delete it. Otherwise just remove\n-                // filemetadata object)\n-                // There are a few cases to handle:\n-                // * the fmd has an id (has been persisted) and is the one in the current\n-                // (draft) version\n-                // * the fmd has an id (has been persisted) but it is from a published version\n-                // so we need the corresponding one from the draft version (i.e. created during\n-                // a getEditVersion call)\n-                // * the fmd has no id (hasn't been persisted) so we have to use non-id based\n-                // means to identify it and remove it from lists\n-\n-                if (fmd.getId() != null) {\n-                    // If the datasetversion doesn't match, we have the fmd from a published version\n-                    // and we need to remove the one for the newly created draft instead, so we find\n-                    // it here\n-                    logger.fine(\"Edit ver: \" + theDataset.getEditVersion().getId());\n-                    logger.fine(\"fmd ver: \" + fmd.getDatasetVersion().getId());\n-                    if (!theDataset.getEditVersion().equals(fmd.getDatasetVersion())) {\n-                        fmd = FileMetadataUtil.getFmdForFileInEditVersion(fmd, theDataset.getEditVersion());\n-                    }\n-                } \n-                fmd = ctxt.em().merge(fmd);\n-\n-                // There are two datafile cases as well - the file has been released, so we're\n-                // just removing it from the current draft version or it is only in the draft\n-                // version and we completely remove the file.\n-                if (!fmd.getDataFile().isReleased()) {\n-                    // remove the file\n-                    ctxt.engine().submit(new DeleteDataFileCommand(fmd.getDataFile(), getRequest()));\n-                    // and remove the file from the dataset's list\n-                    theDataset.getFiles().remove(fmd.getDataFile());\n-                } else {\n-                    // if we aren't removing the file, we need to explicitly remove the fmd from the\n-                    // context and then remove it from the datafile's list\n-                    ctxt.em().remove(fmd);\n-                    FileMetadataUtil.removeFileMetadataFromList(fmd.getDataFile().getFileMetadatas(), fmd);\n-                }\n-                // In either case, to fully remove the fmd, we have to remove any other possible\n-                // references\n-                // From the datasetversion\n-                FileMetadataUtil.removeFileMetadataFromList(theDataset.getEditVersion().getFileMetadatas(), fmd);\n-                // and from the list associated with each category\n-                for (DataFileCategory cat : theDataset.getCategories()) {\n-                    FileMetadataUtil.removeFileMetadataFromList(cat.getFileMetadatas(), fmd);\n-                }\n-            }\n-            for(FileMetadata fmd: theDataset.getEditVersion().getFileMetadatas()) {\n-                logger.fine(\"FMD: \" + fmd.getId() + \" for file: \" + fmd.getDataFile().getId() + \"is in final draft version\");    \n-            }\n-            \n-            if (recalculateUNF) {\n-                ctxt.ingest().recalculateDatasetVersionUNF(theDataset.getEditVersion());\n-            }\n-\n-            theDataset.getEditVersion().setLastUpdateTime(getTimestamp());\n-            theDataset.setModificationTime(getTimestamp());\n-\n-            savedDataset = ctxt.em().merge(theDataset);\n-            ctxt.em().flush();\n-\n-            updateDatasetUser(ctxt);\n-            if (clone != null) {\n-                DatasetVersionDifference dvd = new DatasetVersionDifference(editVersion, clone);\n-                AuthenticatedUser au = (AuthenticatedUser) getUser();\n-                ctxt.datasetVersion().writeEditVersionLog(dvd, au);\n-            }\n-        } finally {\n-            // We're done making changes - remove the lock...\n-            //Failures above may occur before savedDataset is set, in which case we need to remove the lock on theDataset instead\n-            if(savedDataset!=null) {\n-            ctxt.datasets().removeDatasetLocks(savedDataset, DatasetLock.Reason.EditInProgress);\n-            } else {\n-                ctxt.datasets().removeDatasetLocks(theDataset, DatasetLock.Reason.EditInProgress);\n-            }\n+      }\n+      // we have to merge to update the database but not flush because\n+      // we don't want to create two draft versions!\n+      // Although not completely tested, it looks like this merge handles the\n+      // thumbnail case - if the filemetadata is removed from the context below and\n+      // the dataset still references it, that could cause an issue. Merging here\n+      // avoids any reference from it being the dataset thumbnail\n+      theDataset = ctxt.em().merge(theDataset);\n+\n+      /*\n+       * This code has to handle many cases, and anyone making changes should\n+       * carefully check tests and basic methods that update the dataset version. The\n+       * differences between the cases stem primarily from differences in whether the\n+       * files to add, and their filemetadata, and files to delete, and their\n+       * filemetadata have been persisted at this point, which manifests itself as to\n+       * whether they have id numbers or not, and apparently, whether or not they\n+       * exists in lists, e.g. the getFileMetadatas() list of a datafile.\n+       *\n+       * To handle this, the code is carefully checking to make sure that deletions\n+       * are deleting the right things and not, for example, doing a remove(fmd) when\n+       * the fmd.getId() is null, which just removes the first element found.\n+       */\n+      for (FileMetadata fmd : filesToDelete) {\n+        logger.fine(\"Deleting fmd: \" + fmd.getId() + \" for file: \" + fmd.getDataFile().getId());\n+        // if file is draft (ie. new to this version), delete it. Otherwise just remove\n+        // filemetadata object)\n+        // There are a few cases to handle:\n+        // * the fmd has an id (has been persisted) and is the one in the current\n+        // (draft) version\n+        // * the fmd has an id (has been persisted) but it is from a published version\n+        // so we need the corresponding one from the draft version (i.e. created during\n+        // a getEditVersion call)\n+        // * the fmd has no id (hasn't been persisted) so we have to use non-id based\n+        // means to identify it and remove it from lists\n+\n+        if (fmd.getId() != null) {\n+          // If the datasetversion doesn't match, we have the fmd from a published version\n+          // and we need to remove the one for the newly created draft instead, so we find\n+          // it here\n+          logger.fine(\"Edit ver: \" + theDataset.getEditVersion().getId());\n+          logger.fine(\"fmd ver: \" + fmd.getDatasetVersion().getId());\n+          if (!theDataset.getEditVersion().equals(fmd.getDatasetVersion())) {\n+            fmd = FileMetadataUtil.getFmdForFileInEditVersion(fmd, theDataset.getEditVersion());\n+          }\n+        }\n+        fmd = ctxt.em().merge(fmd);\n+\n+        // There are two datafile cases as well - the file has been released, so we're\n+        // just removing it from the current draft version or it is only in the draft\n+        // version and we completely remove the file.\n+        if (!fmd.getDataFile().isReleased()) {\n+          // remove the file\n+          ctxt.engine().submit(new DeleteDataFileCommand(fmd.getDataFile(), getRequest()));\n+          // and remove the file from the dataset's list\n+          theDataset.getFiles().remove(fmd.getDataFile());\n+        } else {\n+          // if we aren't removing the file, we need to explicitly remove the fmd from the\n+          // context and then remove it from the datafile's list\n+          ctxt.em().remove(fmd);\n+          FileMetadataUtil.removeFileMetadataFromList(fmd.getDataFile().getFileMetadatas(), fmd);\n+        }\n+        // In either case, to fully remove the fmd, we have to remove any other possible\n+        // references\n+        // From the datasetversion\n+        FileMetadataUtil.removeFileMetadataFromList(theDataset.getEditVersion().getFileMetadatas(), fmd);\n+        // and from the list associated with each category\n+        for (DataFileCategory cat : theDataset.getCategories()) {\n+          FileMetadataUtil.removeFileMetadataFromList(cat.getFileMetadatas(), fmd);\n         }\n+      }\n+      for (FileMetadata fmd : theDataset.getEditVersion().getFileMetadatas()) {\n+        logger.fine(\"FMD: \" + fmd.getId() + \" for file: \" + fmd.getDataFile().getId() + \"is in final draft version\");\n+      }\n+\n+      if (recalculateUNF) {\n+        ctxt.ingest().recalculateDatasetVersionUNF(theDataset.getEditVersion());\n+      }\n+\n+      theDataset.getEditVersion().setLastUpdateTime(getTimestamp());\n+      theDataset.setModificationTime(getTimestamp());\n+\n+      savedDataset = ctxt.em().merge(theDataset);\n+      ctxt.em().flush();\n \n-        return savedDataset; \n+      updateDatasetUser(ctxt);\n+      if (clone != null) {\n+        DatasetVersionDifference dvd = new DatasetVersionDifference(editVersion, clone);\n+        AuthenticatedUser au = (AuthenticatedUser) getUser();\n+        ctxt.datasetVersion().writeEditVersionLog(dvd, au);\n+      }\n+    } finally {\n+      // We're done making changes - remove the lock...\n+      //Failures above may occur before savedDataset is set, in which case we need to remove the lock on theDataset instead\n+      if (savedDataset != null) {\n+        ctxt.datasets().removeDatasetLocks(savedDataset, DatasetLock.Reason.EditInProgress);\n+      } else {\n+        ctxt.datasets().removeDatasetLocks(theDataset, DatasetLock.Reason.EditInProgress);\n+      }\n     }\n-    \n-    @Override\n-    public boolean onSuccess(CommandContext ctxt, Object r) {\n \n-        boolean retVal = true;\n-        Dataset dataset = (Dataset) r;\n+    return savedDataset;\n+  }\n \n-        try {\n-            Future<String> indexString = ctxt.index().indexDataset(dataset, true);\n-        } catch (IOException | SolrServerException e) {\n-            String failureLogText = \"Post update dataset indexing failed. You can kickoff a re-index of this dataset with: \\r\\n curl http://localhost:8080/api/admin/index/datasets/\" + dataset.getId().toString();\n-            failureLogText += \"\\r\\n\" + e.getLocalizedMessage();\n-            LoggingUtil.writeOnSuccessFailureLog(this, failureLogText, dataset);\n-            retVal = false;\n-        }\n+  @Override\n+  public boolean onSuccess(CommandContext ctxt, Object r) {\n \n-        return retVal;\n+    boolean retVal = true;\n+    Dataset dataset = (Dataset) r;\n \n+    try {\n+      Future<String> indexString = ctxt.index().indexDataset(dataset, true);\n+    } catch (IOException | SolrServerException e) {\n+      String failureLogText =\n+        \"Post update dataset indexing failed. You can kickoff a re-index of this dataset with: \\r\\n curl http://localhost:8080/api/admin/index/datasets/\" +\n+          dataset.getId().toString();\n+      failureLogText += \"\\r\\n\" + e.getLocalizedMessage();\n+      LoggingUtil.writeOnSuccessFailureLog(this, failureLogText, dataset);\n+      retVal = false;\n     }\n \n+    return retVal;\n+\n+  }\n+\n }\n",
            "diff_size": 361
        },
        {
            "tool": "naturalize",
            "errors": [
                {
                    "line": "130",
                    "column": "13",
                    "severity": "error",
                    "message": "File contains tab characters (this is the first instance).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.whitespace.FileTabCharacterCheck"
                }
            ],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/IQSS-dataverse/errored/1/101/UpdateDatasetVersionCommand.java b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/IQSS-dataverse/naturalize/101/UpdateDatasetVersionCommand.java\nindex 4da9e2fef2f..3216d026c63 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/IQSS-dataverse/errored/1/101/UpdateDatasetVersionCommand.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/IQSS-dataverse/naturalize/101/UpdateDatasetVersionCommand.java\n@@ -119,19 +119,18 @@ public class UpdateDatasetVersionCommand extends AbstractDatasetCommand<Dataset>\n             final DatasetVersion editVersion = getDataset().getEditVersion(fmVarMet);\n             \n             tidyUpFields(editVersion);\n-\n-            // Merge the new version into out JPA context, if needed.\n+// Merge the new version into out JPA context, if needed.\n             if (editVersion.getId() == null || editVersion.getId() == 0L) {\n                 ctxt.em().persist(editVersion);\n             } else {\n-            \ttry {\n-            \t\tctxt.em().merge(editVersion);\n-            \t} catch (ConstraintViolationException e) {\n-            \t\tlogger.log(Level.SEVERE,\"Exception: \");\n+    try {\n+    ctxt.em().merge(editVersion);\n+    } catch (ConstraintViolationException e) {\n+    logger.log(Level.SEVERE,\"Exception: \");\n             \t\te.getConstraintViolations().forEach(err->logger.log(Level.SEVERE,err.toString()));\n             \t\tthrow e;\n-            \t}\n-            }\n+    }\n+    }\n \n             for (DataFile dataFile : theDataset.getFiles()) {\n                 if (dataFile.getCreateDate() == null) {\n@@ -234,9 +233,9 @@ public class UpdateDatasetVersionCommand extends AbstractDatasetCommand<Dataset>\n                     FileMetadataUtil.removeFileMetadataFromList(cat.getFileMetadatas(), fmd);\n                 }\n             }\n-            for(FileMetadata fmd: theDataset.getEditVersion().getFileMetadatas()) {\n-                logger.fine(\"FMD: \" + fmd.getId() + \" for file: \" + fmd.getDataFile().getId() + \"is in final draft version\");    \n-            }\n+            for (FileMetadata fmd: theDataset.getEditVersion().getFileMetadatas()) {\n+                logger.fine(\"FMD: \" + fmd.getId() + \" for file: \" + fmd.getDataFile().getId() + \"is in final draft version\");\n+    }\n             \n             if (recalculateUNF) {\n                 ctxt.ingest().recalculateDatasetVersionUNF(theDataset.getEditVersion());\n@@ -286,4 +285,4 @@ public class UpdateDatasetVersionCommand extends AbstractDatasetCommand<Dataset>\n \n     }\n \n-}\n+}\n\\ No newline at end of file\n",
            "diff_size": 12
        },
        {
            "tool": "codebuff",
            "errors": [],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/IQSS-dataverse/errored/1/101/UpdateDatasetVersionCommand.java b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/IQSS-dataverse/codebuff/101/UpdateDatasetVersionCommand.java\nindex 4da9e2fef2f..566d9f0aef0 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/IQSS-dataverse/errored/1/101/UpdateDatasetVersionCommand.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/IQSS-dataverse/codebuff/101/UpdateDatasetVersionCommand.java\n@@ -10,22 +10,21 @@ import edu.harvard.iq.dataverse.engine.command.RequiredPermissions;\n import edu.harvard.iq.dataverse.engine.command.exception.CommandException;\n import edu.harvard.iq.dataverse.engine.command.exception.IllegalCommandException;\n import edu.harvard.iq.dataverse.util.FileMetadataUtil;\n-\n import java.io.IOException;\n import java.util.ArrayList;\n import java.util.List;\n import java.util.concurrent.Future;\n import java.util.logging.Level;\n import java.util.logging.Logger;\n-\n import javax.validation.ConstraintViolationException;\n-\n import org.apache.solr.client.solrj.SolrServerException;\n \n /**\n  *\n  * @author skraffmiller\n  */\n+\n+\n @RequiredPermissions(Permission.EditDataset)\n public class UpdateDatasetVersionCommand extends AbstractDatasetCommand<Dataset> {\n \n@@ -34,28 +33,28 @@ public class UpdateDatasetVersionCommand extends AbstractDatasetCommand<Dataset>\n     private boolean validateLenient = false;\n     private final DatasetVersion clone;\n     private final FileMetadata fmVarMet;\n-    \n+\n     public UpdateDatasetVersionCommand(Dataset theDataset, DataverseRequest aRequest) {\n         super(aRequest, theDataset);\n         this.filesToDelete = new ArrayList<>();\n         this.clone = null;\n         this.fmVarMet = null;\n-    }    \n-    \n+    }\n+\n     public UpdateDatasetVersionCommand(Dataset theDataset, DataverseRequest aRequest, List<FileMetadata> filesToDelete) {\n         super(aRequest, theDataset);\n         this.filesToDelete = filesToDelete;\n         this.clone = null;\n         this.fmVarMet = null;\n     }\n-    \n+\n     public UpdateDatasetVersionCommand(Dataset theDataset, DataverseRequest aRequest, List<FileMetadata> filesToDelete, DatasetVersion clone) {\n         super(aRequest, theDataset);\n         this.filesToDelete = filesToDelete;\n         this.clone = clone;\n         this.fmVarMet = null;\n     }\n-    \n+\n     public UpdateDatasetVersionCommand(Dataset theDataset, DataverseRequest aRequest, DataFile fileToDelete) {\n         super(aRequest, theDataset);\n         \n@@ -63,14 +62,15 @@ public class UpdateDatasetVersionCommand extends AbstractDatasetCommand<Dataset>\n         this.filesToDelete = new ArrayList<>();\n         this.clone = null;\n         this.fmVarMet = null;\n+\n         for (FileMetadata fmd : theDataset.getEditVersion().getFileMetadatas()) {\n             if (fmd.getDataFile().equals(fileToDelete)) {\n                 filesToDelete.add(fmd);\n                 break;\n             }\n         }\n-    } \n-    \n+    }\n+\n     public UpdateDatasetVersionCommand(Dataset theDataset, DataverseRequest aRequest, DatasetVersion clone) {\n         super(aRequest, theDataset);\n         this.filesToDelete = new ArrayList<>();\n@@ -95,42 +95,41 @@ public class UpdateDatasetVersionCommand extends AbstractDatasetCommand<Dataset>\n \n     @Override\n     public Dataset execute(CommandContext ctxt) throws CommandException {\n-        if ( ! (getUser() instanceof AuthenticatedUser) ) {\n+        if (!(getUser() instanceof AuthenticatedUser)) {\n             throw new IllegalCommandException(\"Only authenticated users can update datasets\", this);\n         }\n-        \n-        Dataset theDataset = getDataset();        \n+\n+        Dataset theDataset = getDataset();\n         ctxt.permissions().checkEditDatasetLock(theDataset, getRequest(), this);\n         Dataset savedDataset = null;\n-        \n         try {\n             // Invariant: Dataset has no locks preventing the update\n             String lockInfoMessage = \"saving current edits\";\n-            DatasetLock lock = ctxt.datasets().addDatasetLock(getDataset().getId(), DatasetLock.Reason.EditInProgress, ((AuthenticatedUser) getUser()).getId(), lockInfoMessage);\n+            DatasetLock lock = ctxt.datasets().addDatasetLock(getDataset().getId(),\n+                                                                 DatasetLock.Reason.EditInProgress,\n+                                                                 ((AuthenticatedUser) getUser()).getId(),\n+                                                                 lockInfoMessage);\n             if (lock != null) {\n                 theDataset.addLock(lock);\n             } else {\n                 logger.log(Level.WARNING, \"Failed to lock the dataset (dataset id={0})\", getDataset().getId());\n             }\n-            \n             getDataset().getEditVersion(fmVarMet).setDatasetFields(getDataset().getEditVersion(fmVarMet).initDatasetFields());\n             validateOrDie(getDataset().getEditVersion(fmVarMet), isValidateLenient());\n-\n             final DatasetVersion editVersion = getDataset().getEditVersion(fmVarMet);\n-            \n             tidyUpFields(editVersion);\n \n             // Merge the new version into out JPA context, if needed.\n             if (editVersion.getId() == null || editVersion.getId() == 0L) {\n                 ctxt.em().persist(editVersion);\n             } else {\n-            \ttry {\n-            \t\tctxt.em().merge(editVersion);\n-            \t} catch (ConstraintViolationException e) {\n-            \t\tlogger.log(Level.SEVERE,\"Exception: \");\n-            \t\te.getConstraintViolations().forEach(err->logger.log(Level.SEVERE,err.toString()));\n-            \t\tthrow e;\n-            \t}\n+                try {\n+                    ctxt.em().merge(editVersion);\n+                } catch (ConstraintViolationException e) {\n+                    logger.log(Level.SEVERE, \"Exception: \");\n+                    e.getConstraintViolations().forEach(err -> logger.log(Level.SEVERE, err.toString()));\n+                    throw e;\n+                }\n             }\n \n             for (DataFile dataFile : theDataset.getFiles()) {\n@@ -146,6 +145,7 @@ public class UpdateDatasetVersionCommand extends AbstractDatasetCommand<Dataset>\n             // If any of the files that we are deleting has a UNF, we will need to\n             // re-calculate the UNF of the version - since that is the product\n             // of the UNFs of the individual files.\n+\n             boolean recalculateUNF = false;\n             /*\n              * The separate loop is just to make sure that the dataset database is updated,\n@@ -186,6 +186,7 @@ public class UpdateDatasetVersionCommand extends AbstractDatasetCommand<Dataset>\n              * are deleting the right things and not, for example, doing a remove(fmd) when\n              * the fmd.getId() is null, which just removes the first element found.\n              */\n+\n             for (FileMetadata fmd : filesToDelete) {\n                 logger.fine(\"Deleting fmd: \" + fmd.getId() + \" for file: \" + fmd.getDataFile().getId());\n                 // if file is draft (ie. new to this version), delete it. Otherwise just remove\n@@ -198,7 +199,6 @@ public class UpdateDatasetVersionCommand extends AbstractDatasetCommand<Dataset>\n                 // a getEditVersion call)\n                 // * the fmd has no id (hasn't been persisted) so we have to use non-id based\n                 // means to identify it and remove it from lists\n-\n                 if (fmd.getId() != null) {\n                     // If the datasetversion doesn't match, we have the fmd from a published version\n                     // and we need to remove the one for the newly created draft instead, so we find\n@@ -208,7 +208,7 @@ public class UpdateDatasetVersionCommand extends AbstractDatasetCommand<Dataset>\n                     if (!theDataset.getEditVersion().equals(fmd.getDatasetVersion())) {\n                         fmd = FileMetadataUtil.getFmdForFileInEditVersion(fmd, theDataset.getEditVersion());\n                     }\n-                } \n+                }\n                 fmd = ctxt.em().merge(fmd);\n \n                 // There are two datafile cases as well - the file has been released, so we're\n@@ -230,24 +230,23 @@ public class UpdateDatasetVersionCommand extends AbstractDatasetCommand<Dataset>\n                 // From the datasetversion\n                 FileMetadataUtil.removeFileMetadataFromList(theDataset.getEditVersion().getFileMetadatas(), fmd);\n                 // and from the list associated with each category\n+\n                 for (DataFileCategory cat : theDataset.getCategories()) {\n                     FileMetadataUtil.removeFileMetadataFromList(cat.getFileMetadatas(), fmd);\n                 }\n             }\n-            for(FileMetadata fmd: theDataset.getEditVersion().getFileMetadatas()) {\n-                logger.fine(\"FMD: \" + fmd.getId() + \" for file: \" + fmd.getDataFile().getId() + \"is in final draft version\");    \n+\n+            for (FileMetadata fmd : theDataset.getEditVersion().getFileMetadatas()) {\n+                logger.fine(\"FMD: \" + fmd.getId() + \" for file: \" + fmd.getDataFile().getId() + \"is in final draft version\");\n             }\n-            \n+\n             if (recalculateUNF) {\n                 ctxt.ingest().recalculateDatasetVersionUNF(theDataset.getEditVersion());\n             }\n-\n             theDataset.getEditVersion().setLastUpdateTime(getTimestamp());\n             theDataset.setModificationTime(getTimestamp());\n-\n             savedDataset = ctxt.em().merge(theDataset);\n             ctxt.em().flush();\n-\n             updateDatasetUser(ctxt);\n             if (clone != null) {\n                 DatasetVersionDifference dvd = new DatasetVersionDifference(editVersion, clone);\n@@ -257,22 +256,19 @@ public class UpdateDatasetVersionCommand extends AbstractDatasetCommand<Dataset>\n         } finally {\n             // We're done making changes - remove the lock...\n             //Failures above may occur before savedDataset is set, in which case we need to remove the lock on theDataset instead\n-            if(savedDataset!=null) {\n-            ctxt.datasets().removeDatasetLocks(savedDataset, DatasetLock.Reason.EditInProgress);\n+            if (savedDataset != null) {\n+                ctxt.datasets().removeDatasetLocks(savedDataset, DatasetLock.Reason.EditInProgress);\n             } else {\n                 ctxt.datasets().removeDatasetLocks(theDataset, DatasetLock.Reason.EditInProgress);\n             }\n         }\n-\n-        return savedDataset; \n+        return savedDataset;\n     }\n-    \n+\n     @Override\n     public boolean onSuccess(CommandContext ctxt, Object r) {\n-\n         boolean retVal = true;\n         Dataset dataset = (Dataset) r;\n-\n         try {\n             Future<String> indexString = ctxt.index().indexDataset(dataset, true);\n         } catch (IOException | SolrServerException e) {\n@@ -281,9 +277,7 @@ public class UpdateDatasetVersionCommand extends AbstractDatasetCommand<Dataset>\n             LoggingUtil.writeOnSuccessFailureLog(this, failureLogText, dataset);\n             retVal = false;\n         }\n-\n         return retVal;\n-\n     }\n \n-}\n+}\n\\ No newline at end of file\n",
            "diff_size": 53
        },
        {
            "tool": "styler_random",
            "errors": [
                {
                    "line": "128",
                    "column": "13",
                    "severity": "error",
                    "message": "File contains tab characters (this is the first instance).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.whitespace.FileTabCharacterCheck"
                }
            ],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/IQSS-dataverse/errored/1/101/UpdateDatasetVersionCommand.java b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/IQSS-dataverse/styler_random/101/UpdateDatasetVersionCommand.java\nindex 4da9e2fef2f..6b0be7b5e2c 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/IQSS-dataverse/errored/1/101/UpdateDatasetVersionCommand.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/IQSS-dataverse/styler_random/101/UpdateDatasetVersionCommand.java\n@@ -124,7 +124,7 @@ public class UpdateDatasetVersionCommand extends AbstractDatasetCommand<Dataset>\n             if (editVersion.getId() == null || editVersion.getId() == 0L) {\n                 ctxt.em().persist(editVersion);\n             } else {\n-            \ttry {\n+            try {\n             \t\tctxt.em().merge(editVersion);\n             \t} catch (ConstraintViolationException e) {\n             \t\tlogger.log(Level.SEVERE,\"Exception: \");\n",
            "diff_size": 1
        },
        {
            "tool": "styler_three_grams",
            "errors": [
                {
                    "line": "128",
                    "column": "13",
                    "severity": "error",
                    "message": "File contains tab characters (this is the first instance).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.whitespace.FileTabCharacterCheck"
                }
            ],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/IQSS-dataverse/errored/1/101/UpdateDatasetVersionCommand.java b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/IQSS-dataverse/styler_three_grams/101/UpdateDatasetVersionCommand.java\nindex 4da9e2fef2f..9ef865aa642 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/IQSS-dataverse/errored/1/101/UpdateDatasetVersionCommand.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/IQSS-dataverse/styler_three_grams/101/UpdateDatasetVersionCommand.java\n@@ -124,7 +124,7 @@ public class UpdateDatasetVersionCommand extends AbstractDatasetCommand<Dataset>\n             if (editVersion.getId() == null || editVersion.getId() == 0L) {\n                 ctxt.em().persist(editVersion);\n             } else {\n-            \ttry {\n+                try {\n             \t\tctxt.em().merge(editVersion);\n             \t} catch (ConstraintViolationException e) {\n             \t\tlogger.log(Level.SEVERE,\"Exception: \");\n",
            "diff_size": 1
        }
    ],
    "repaired_by": [
        "intellij",
        "codebuff"
    ],
    "not_repaired_by": [
        "styler",
        "naturalize",
        "styler_random",
        "styler_three_grams"
    ]
}