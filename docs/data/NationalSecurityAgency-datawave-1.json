{
    "project_name": "NationalSecurityAgency-datawave",
    "error_id": "1",
    "information": {
        "errors": [
            {
                "line": "23",
                "severity": "error",
                "message": "Accumulo non-public classes imported",
                "source": "com.puppycrawl.tools.checkstyle.checks.regexp.RegexpSinglelineJavaCheck"
            }
        ]
    },
    "source_code": "import org.apache.accumulo.core.client.admin.NamespaceOperations;\nimport org.apache.accumulo.core.client.admin.TableOperations;\nimport org.apache.accumulo.core.conf.Property;\nimport org.apache.accumulo.core.iterators.Combiner;\nimport org.apache.accumulo.core.iterators.IteratorUtil;\nimport org.apache.hadoop.conf.Configuration;",
    "results": [
        {
            "tool": "styler",
            "errors": [],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/NationalSecurityAgency-datawave/errored/1/1/TableConfigurationUtil.java b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/NationalSecurityAgency-datawave/styler/1/TableConfigurationUtil.java\nindex dd4b03b676e..554794a9d15 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/NationalSecurityAgency-datawave/errored/1/1/TableConfigurationUtil.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/NationalSecurityAgency-datawave/styler/1/TableConfigurationUtil.java\n@@ -20,8 +20,9 @@ import org.apache.accumulo.core.client.AccumuloSecurityException;\n import org.apache.accumulo.core.client.TableNotFoundException;\n import org.apache.accumulo.core.client.admin.NamespaceOperations;\n import org.apache.accumulo.core.client.admin.TableOperations;\n-import org.apache.accumulo.core.conf.Property;\n-import org.apache.accumulo.core.iterators.Combiner;\n+import\n+org.apache.accumulo.core.conf.Property;\n+ import org.apache.accumulo.core.iterators.Combiner;\n import org.apache.accumulo.core.iterators.IteratorUtil;\n import org.apache.hadoop.conf.Configuration;\n import org.apache.log4j.Logger;\n",
            "diff_size": 3
        },
        {
            "tool": "intellij",
            "errors": [
                {
                    "line": "23",
                    "severity": "error",
                    "message": "Accumulo non-public classes imported",
                    "source": "com.puppycrawl.tools.checkstyle.checks.regexp.RegexpSinglelineJavaCheck"
                }
            ],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/NationalSecurityAgency-datawave/errored/1/1/TableConfigurationUtil.java b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/NationalSecurityAgency-datawave/intellij/1/TableConfigurationUtil.java\nindex dd4b03b676e..b56e2a4830c 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/NationalSecurityAgency-datawave/errored/1/1/TableConfigurationUtil.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/NationalSecurityAgency-datawave/intellij/1/TableConfigurationUtil.java\n@@ -34,428 +34,422 @@ import java.util.Map;\n import java.util.Set;\n \n public class TableConfigurationUtil {\n-    \n-    protected static final Logger log = Logger.getLogger(TableConfigurationUtil.class.getName());\n-    private String[] tableNames;\n-    private AccumuloHelper accumuloHelper;\n-    \n-    public TableConfigurationUtil(Configuration conf) {\n-        registerTableNames(conf);\n-        accumuloHelper = new AccumuloHelper();\n-        accumuloHelper.setup(conf);\n-    }\n-    \n-    public String[] getTableNames() {\n-        return tableNames;\n-    }\n-    \n-    /**\n-     * @param conf\n-     *            configuration file that contains data handler types and other information necessary for determining the set of tables required\n-     * @return true if a non-empty comma separated list of table names was properly set to conf's job table.names property\n-     */\n-    private boolean registerTableNames(Configuration conf) {\n-        Set<String> tables = getTables(conf);\n-        \n-        if (tables.isEmpty()) {\n-            log.error(\"Configured tables for configured data types is empty\");\n-            return false;\n-        }\n-        tableNames = tables.toArray(new String[tables.size()]);\n-        conf.set(\"job.table.names\", org.apache.hadoop.util.StringUtils.join(\",\", tableNames));\n-        return true;\n+\n+  protected static final Logger log = Logger.getLogger(TableConfigurationUtil.class.getName());\n+  private String[] tableNames;\n+  private AccumuloHelper accumuloHelper;\n+\n+  public TableConfigurationUtil(Configuration conf) {\n+    registerTableNames(conf);\n+    accumuloHelper = new AccumuloHelper();\n+    accumuloHelper.setup(conf);\n+  }\n+\n+  public String[] getTableNames() {\n+    return tableNames;\n+  }\n+\n+  /**\n+   * @param conf configuration file that contains data handler types and other information necessary for determining the set of tables required\n+   * @return true if a non-empty comma separated list of table names was properly set to conf's job table.names property\n+   */\n+  private boolean registerTableNames(Configuration conf) {\n+    Set<String> tables = getTables(conf);\n+\n+    if (tables.isEmpty()) {\n+      log.error(\"Configured tables for configured data types is empty\");\n+      return false;\n     }\n-    \n-    /**\n-     * Get the table names\n-     *\n-     * @param conf\n-     *            hadoop configuration\n-     * @return map of table names to priorities\n-     */\n-    public static Set<String> getTables(Configuration conf) throws IllegalArgumentException {\n-        TypeRegistry.getInstance(conf);\n-        \n-        Set<String> tables = new HashSet<>();\n-        for (Type type : TypeRegistry.getTypes()) {\n-            if (type.getDefaultDataTypeHandlers() != null) {\n-                for (String handlerClassName : type.getDefaultDataTypeHandlers()) {\n-                    Class<? extends DataTypeHandler<?>> handlerClass;\n-                    try {\n-                        handlerClass = TypeRegistry.getHandlerClass(handlerClassName);\n-                    } catch (ClassNotFoundException e) {\n-                        throw new IllegalArgumentException(\"Unable to find \" + handlerClassName, e);\n-                    }\n-                    DataTypeHandler<?> handler;\n-                    try {\n-                        handler = handlerClass.newInstance();\n-                    } catch (InstantiationException e) {\n-                        throw new IllegalArgumentException(\"Unable to instantiate \" + handlerClassName, e);\n-                    } catch (IllegalAccessException e) {\n-                        throw new IllegalArgumentException(\"Unable to access default constructor for \" + handlerClassName, e);\n-                    }\n-                    String[] handlerTableNames = handler.getTableNames(conf);\n-                    Collections.addAll(tables, handlerTableNames);\n-                }\n-            }\n-            if (type.getDefaultDataTypeFilters() != null) {\n-                for (String filterClassNames : type.getDefaultDataTypeFilters()) {\n-                    Class<? extends KeyValueFilter<?,?>> filterClass;\n-                    try {\n-                        filterClass = TypeRegistry.getFilterClass(filterClassNames);\n-                    } catch (ClassNotFoundException e) {\n-                        throw new IllegalArgumentException(\"Unable to find \" + filterClassNames, e);\n-                    }\n-                    KeyValueFilter<?,?> filter;\n-                    try {\n-                        filter = filterClass.newInstance();\n-                    } catch (InstantiationException e) {\n-                        throw new IllegalArgumentException(\"Unable to instantiate \" + filterClassNames, e);\n-                    } catch (IllegalAccessException e) {\n-                        throw new IllegalArgumentException(\"Unable to access default constructor for \" + filterClassNames, e);\n-                    }\n-                    String[] filterTableNames = filter.getTableNames(conf);\n-                    Collections.addAll(tables, filterTableNames);\n-                }\n-            }\n+    tableNames = tables.toArray(new String[tables.size()]);\n+    conf.set(\"job.table.names\", org.apache.hadoop.util.StringUtils.join(\",\", tableNames));\n+    return true;\n+  }\n+\n+  /**\n+   * Get the table names\n+   *\n+   * @param conf hadoop configuration\n+   * @return map of table names to priorities\n+   */\n+  public static Set<String> getTables(Configuration conf) throws IllegalArgumentException {\n+    TypeRegistry.getInstance(conf);\n+\n+    Set<String> tables = new HashSet<>();\n+    for (Type type : TypeRegistry.getTypes()) {\n+      if (type.getDefaultDataTypeHandlers() != null) {\n+        for (String handlerClassName : type.getDefaultDataTypeHandlers()) {\n+          Class<? extends DataTypeHandler<?>> handlerClass;\n+          try {\n+            handlerClass = TypeRegistry.getHandlerClass(handlerClassName);\n+          } catch (ClassNotFoundException e) {\n+            throw new IllegalArgumentException(\"Unable to find \" + handlerClassName, e);\n+          }\n+          DataTypeHandler<?> handler;\n+          try {\n+            handler = handlerClass.newInstance();\n+          } catch (InstantiationException e) {\n+            throw new IllegalArgumentException(\"Unable to instantiate \" + handlerClassName, e);\n+          } catch (IllegalAccessException e) {\n+            throw new IllegalArgumentException(\"Unable to access default constructor for \" + handlerClassName, e);\n+          }\n+          String[] handlerTableNames = handler.getTableNames(conf);\n+          Collections.addAll(tables, handlerTableNames);\n         }\n-        \n-        if (MetricsConfiguration.isEnabled(conf)) {\n-            String metricsTable = MetricsConfiguration.getTable(conf);\n-            if (org.apache.commons.lang.StringUtils.isNotBlank(metricsTable)) {\n-                tables.add(metricsTable);\n-            }\n+      }\n+      if (type.getDefaultDataTypeFilters() != null) {\n+        for (String filterClassNames : type.getDefaultDataTypeFilters()) {\n+          Class<? extends KeyValueFilter<?, ?>> filterClass;\n+          try {\n+            filterClass = TypeRegistry.getFilterClass(filterClassNames);\n+          } catch (ClassNotFoundException e) {\n+            throw new IllegalArgumentException(\"Unable to find \" + filterClassNames, e);\n+          }\n+          KeyValueFilter<?, ?> filter;\n+          try {\n+            filter = filterClass.newInstance();\n+          } catch (InstantiationException e) {\n+            throw new IllegalArgumentException(\"Unable to instantiate \" + filterClassNames, e);\n+          } catch (IllegalAccessException e) {\n+            throw new IllegalArgumentException(\"Unable to access default constructor for \" + filterClassNames, e);\n+          }\n+          String[] filterTableNames = filter.getTableNames(conf);\n+          Collections.addAll(tables, filterTableNames);\n         }\n-        \n-        return tables;\n+      }\n     }\n-    \n-    /**\n-     * Configure the accumulo tables (create and set aggregators etc)\n-     *\n-     * @param conf\n-     * @throws AccumuloSecurityException\n-     * @throws AccumuloException\n-     * @throws TableNotFoundException\n-     */\n-    public boolean configureTables(Configuration conf) throws AccumuloSecurityException, AccumuloException, TableNotFoundException {\n-        try (AccumuloClient client = accumuloHelper.newClient()) {\n-            // Check to see if the tables exist\n-            TableOperations tops = client.tableOperations();\n-            NamespaceOperations namespaceOperations = client.namespaceOperations();\n-            createAndConfigureTablesIfNecessary(tableNames, tops, namespaceOperations, conf, log, false);\n-        }\n-        \n-        return true;\n+\n+    if (MetricsConfiguration.isEnabled(conf)) {\n+      String metricsTable = MetricsConfiguration.getTable(conf);\n+      if (org.apache.commons.lang.StringUtils.isNotBlank(metricsTable)) {\n+        tables.add(metricsTable);\n+      }\n     }\n-    \n-    /**\n-     * Creates the tables that are needed to load data using this ingest job if they don't already exist. If a table is created, it is configured with the\n-     * appropriate iterators, aggregators, and locality groups that are required for ingest and query functionality to work correctly.\n-     *\n-     * @param tableNames\n-     *            the names of the table to create if they don't exist\n-     * @param tops\n-     *            accumulo table operations helper for checking/creating tables\n-     * @param conf\n-     *            the Hadoop {@link Configuration} for retrieving table configuration information\n-     * @param log\n-     *            a logger for diagnostic messages\n-     * @param enableBloomFilters\n-     *            an indication of whether bloom filters should be enabled in the configuration\n-     * @throws AccumuloSecurityException\n-     * @throws AccumuloException\n-     * @throws TableNotFoundException\n-     */\n-    protected void createAndConfigureTablesIfNecessary(String[] tableNames, TableOperations tops, NamespaceOperations namespaceOperations, Configuration conf,\n-                    Logger log, boolean enableBloomFilters) throws AccumuloSecurityException, AccumuloException, TableNotFoundException {\n-        for (String table : tableNames) {\n-            createNamespaceIfNecessary(namespaceOperations, table);\n-            // If the tables don't exist, then create them.\n-            try {\n-                if (!tops.exists(table)) {\n-                    tops.create(table);\n-                }\n-            } catch (TableExistsException te) {\n-                // in this case, somebody else must have created the table after our existence check\n-                log.info(\"Tried to create \" + table + \" but somebody beat us to the punch\");\n-            }\n-        }\n-        \n-        // Pass along the enabling of bloom filters using the configuration\n-        conf.setBoolean(ShardTableConfigHelper.ENABLE_BLOOM_FILTERS, enableBloomFilters);\n-        \n-        configureTablesIfNecessary(tableNames, tops, conf, log);\n+\n+    return tables;\n+  }\n+\n+  /**\n+   * Configure the accumulo tables (create and set aggregators etc)\n+   *\n+   * @param conf\n+   * @throws AccumuloSecurityException\n+   * @throws AccumuloException\n+   * @throws TableNotFoundException\n+   */\n+  public boolean configureTables(Configuration conf)\n+      throws AccumuloSecurityException, AccumuloException, TableNotFoundException {\n+    try (AccumuloClient client = accumuloHelper.newClient()) {\n+      // Check to see if the tables exist\n+      TableOperations tops = client.tableOperations();\n+      NamespaceOperations namespaceOperations = client.namespaceOperations();\n+      createAndConfigureTablesIfNecessary(tableNames, tops, namespaceOperations, conf, log, false);\n     }\n-    \n-    private void createNamespaceIfNecessary(NamespaceOperations namespaceOperations, String table) throws AccumuloException, AccumuloSecurityException {\n-        // if the table has a namespace in it that doesn't already exist, create it\n-        if (table.contains(\".\")) {\n-            String namespace = table.split(\"\\\\.\")[0];\n-            try {\n-                if (!namespaceOperations.exists(namespace)) {\n-                    namespaceOperations.create(namespace);\n-                }\n-            } catch (NamespaceExistsException e) {\n-                // in this case, somebody else must have created the namespace after our existence check\n-                log.info(\"Tried to create \" + namespace + \" but somebody beat us to the punch\");\n-            }\n+\n+    return true;\n+  }\n+\n+  /**\n+   * Creates the tables that are needed to load data using this ingest job if they don't already exist. If a table is created, it is configured with the\n+   * appropriate iterators, aggregators, and locality groups that are required for ingest and query functionality to work correctly.\n+   *\n+   * @param tableNames         the names of the table to create if they don't exist\n+   * @param tops               accumulo table operations helper for checking/creating tables\n+   * @param conf               the Hadoop {@link Configuration} for retrieving table configuration information\n+   * @param log                a logger for diagnostic messages\n+   * @param enableBloomFilters an indication of whether bloom filters should be enabled in the configuration\n+   * @throws AccumuloSecurityException\n+   * @throws AccumuloException\n+   * @throws TableNotFoundException\n+   */\n+  protected void createAndConfigureTablesIfNecessary(String[] tableNames, TableOperations tops,\n+                                                     NamespaceOperations namespaceOperations, Configuration conf,\n+                                                     Logger log, boolean enableBloomFilters)\n+      throws AccumuloSecurityException, AccumuloException, TableNotFoundException {\n+    for (String table : tableNames) {\n+      createNamespaceIfNecessary(namespaceOperations, table);\n+      // If the tables don't exist, then create them.\n+      try {\n+        if (!tops.exists(table)) {\n+          tops.create(table);\n         }\n+      } catch (TableExistsException te) {\n+        // in this case, somebody else must have created the table after our existence check\n+        log.info(\"Tried to create \" + table + \" but somebody beat us to the punch\");\n+      }\n     }\n-    \n-    /**\n-     * Configures tables that are needed to load data using this ingest job, only if they don't already have the required configuration.\n-     *\n-     * @param tableNames\n-     *            the names of the tables to configure\n-     * @param tops\n-     *            accumulo table operations helper for configuring tables\n-     * @param conf\n-     *            the Hadoop {@link Configuration} for retrieving ingest table configuration information\n-     * @param log\n-     *            a {@link Logger} for diagnostic messages\n-     * @throws AccumuloSecurityException\n-     * @throws AccumuloException\n-     * @throws TableNotFoundException\n-     */\n-    private void configureTablesIfNecessary(String[] tableNames, TableOperations tops, Configuration conf, Logger log) throws AccumuloSecurityException,\n-                    AccumuloException, TableNotFoundException {\n-        \n-        Map<String,TableConfigHelper> tableConfigs = getTableConfigs(log, conf, tableNames);\n-        \n-        for (String table : tableNames) {\n-            TableConfigHelper tableHelper = tableConfigs.get(table);\n-            if (tableHelper != null) {\n-                tableHelper.configure(tops);\n-            } else {\n-                log.info(\"No configuration supplied for table \" + table);\n-            }\n+\n+    // Pass along the enabling of bloom filters using the configuration\n+    conf.setBoolean(ShardTableConfigHelper.ENABLE_BLOOM_FILTERS, enableBloomFilters);\n+\n+    configureTablesIfNecessary(tableNames, tops, conf, log);\n+  }\n+\n+  private void createNamespaceIfNecessary(NamespaceOperations namespaceOperations, String table)\n+      throws AccumuloException, AccumuloSecurityException {\n+    // if the table has a namespace in it that doesn't already exist, create it\n+    if (table.contains(\".\")) {\n+      String namespace = table.split(\"\\\\.\")[0];\n+      try {\n+        if (!namespaceOperations.exists(namespace)) {\n+          namespaceOperations.create(namespace);\n         }\n+      } catch (NamespaceExistsException e) {\n+        // in this case, somebody else must have created the namespace after our existence check\n+        log.info(\"Tried to create \" + namespace + \" but somebody beat us to the punch\");\n+      }\n     }\n-    \n-    /**\n-     * Instantiates TableConfigHelper classes for tables as defined in the configuration\n-     *\n-     * @param log\n-     *            a {@link Logger} for diagnostic messages\n-     * @param conf\n-     *            the Hadoop {@link Configuration} for retrieving ingest table configuration information\n-     * @param tableNames\n-     *            the names of the tables to configure\n-     * @return Map&lt;String,TableConfigHelper&gt; map from table names to their setup TableConfigHelper classes\n-     */\n-    private Map<String,TableConfigHelper> getTableConfigs(Logger log, Configuration conf, String[] tableNames) {\n-        \n-        Map<String,TableConfigHelper> helperMap = new HashMap<>(tableNames.length);\n-        \n-        for (String table : tableNames) {\n-            helperMap.put(table, TableConfigHelperFactory.create(table, conf, log));\n-        }\n-        \n-        return helperMap;\n+  }\n+\n+  /**\n+   * Configures tables that are needed to load data using this ingest job, only if they don't already have the required configuration.\n+   *\n+   * @param tableNames the names of the tables to configure\n+   * @param tops       accumulo table operations helper for configuring tables\n+   * @param conf       the Hadoop {@link Configuration} for retrieving ingest table configuration information\n+   * @param log        a {@link Logger} for diagnostic messages\n+   * @throws AccumuloSecurityException\n+   * @throws AccumuloException\n+   * @throws TableNotFoundException\n+   */\n+  private void configureTablesIfNecessary(String[] tableNames, TableOperations tops, Configuration conf, Logger log)\n+      throws AccumuloSecurityException,\n+      AccumuloException, TableNotFoundException {\n+\n+    Map<String, TableConfigHelper> tableConfigs = getTableConfigs(log, conf, tableNames);\n+\n+    for (String table : tableNames) {\n+      TableConfigHelper tableHelper = tableConfigs.get(table);\n+      if (tableHelper != null) {\n+        tableHelper.configure(tops);\n+      } else {\n+        log.info(\"No configuration supplied for table \" + table);\n+      }\n     }\n-    \n-    /**\n-     * Get the table priorities\n-     *\n-     * @param conf\n-     *            hadoop configuration\n-     * @return map of table names to priorities\n-     */\n-    public static Map<String,Integer> getTablePriorities(Configuration conf) {\n-        TypeRegistry.getInstance(conf);\n-        Map<String,Integer> tablePriorities = new HashMap<>();\n-        for (Type type : TypeRegistry.getTypes()) {\n-            if (null != type.getDefaultDataTypeHandlers()) {\n-                for (String handlerClassName : type.getDefaultDataTypeHandlers()) {\n-                    Class<? extends DataTypeHandler<?>> handlerClass;\n-                    try {\n-                        handlerClass = TypeRegistry.getHandlerClass(handlerClassName);\n-                    } catch (ClassNotFoundException e) {\n-                        throw new IllegalArgumentException(\"Unable to find \" + handlerClassName, e);\n-                    }\n-                    DataTypeHandler<?> handler;\n-                    try {\n-                        handler = handlerClass.newInstance();\n-                    } catch (InstantiationException e) {\n-                        throw new IllegalArgumentException(\"Unable to instantiate \" + handlerClassName, e);\n-                    } catch (IllegalAccessException e) {\n-                        throw new IllegalArgumentException(\"Unable to access default constructor for \" + handlerClassName, e);\n-                    }\n-                    String[] handlerTableNames = handler.getTableNames(conf);\n-                    int[] handlerTablePriorities = handler.getTableLoaderPriorities(conf);\n-                    for (int i = 0; i < handlerTableNames.length; i++) {\n-                        tablePriorities.put(handlerTableNames[i], handlerTablePriorities[i]);\n-                    }\n-                }\n-            }\n-            if (null != type.getDefaultDataTypeFilters()) {\n-                for (String filterClassNames : type.getDefaultDataTypeFilters()) {\n-                    Class<? extends KeyValueFilter<?,?>> filterClass;\n-                    try {\n-                        filterClass = TypeRegistry.getFilterClass(filterClassNames);\n-                    } catch (ClassNotFoundException e) {\n-                        throw new IllegalArgumentException(\"Unable to find \" + filterClassNames, e);\n-                    }\n-                    KeyValueFilter<?,?> filter;\n-                    try {\n-                        filter = filterClass.newInstance();\n-                    } catch (InstantiationException e) {\n-                        throw new IllegalArgumentException(\"Unable to instantiate \" + filterClassNames, e);\n-                    } catch (IllegalAccessException e) {\n-                        throw new IllegalArgumentException(\"Unable to access default constructor for \" + filterClassNames, e);\n-                    }\n-                    String[] filterTableNames = filter.getTableNames(conf);\n-                    int[] filterTablePriorities = filter.getTableLoaderPriorities(conf);\n-                    for (int i = 0; i < filterTableNames.length; i++) {\n-                        tablePriorities.put(filterTableNames[i], filterTablePriorities[i]);\n-                    }\n-                }\n-            }\n+  }\n+\n+  /**\n+   * Instantiates TableConfigHelper classes for tables as defined in the configuration\n+   *\n+   * @param log        a {@link Logger} for diagnostic messages\n+   * @param conf       the Hadoop {@link Configuration} for retrieving ingest table configuration information\n+   * @param tableNames the names of the tables to configure\n+   * @return Map&lt;String,TableConfigHelper&gt; map from table names to their setup TableConfigHelper classes\n+   */\n+  private Map<String, TableConfigHelper> getTableConfigs(Logger log, Configuration conf, String[] tableNames) {\n+\n+    Map<String, TableConfigHelper> helperMap = new HashMap<>(tableNames.length);\n+\n+    for (String table : tableNames) {\n+      helperMap.put(table, TableConfigHelperFactory.create(table, conf, log));\n+    }\n+\n+    return helperMap;\n+  }\n+\n+  /**\n+   * Get the table priorities\n+   *\n+   * @param conf hadoop configuration\n+   * @return map of table names to priorities\n+   */\n+  public static Map<String, Integer> getTablePriorities(Configuration conf) {\n+    TypeRegistry.getInstance(conf);\n+    Map<String, Integer> tablePriorities = new HashMap<>();\n+    for (Type type : TypeRegistry.getTypes()) {\n+      if (null != type.getDefaultDataTypeHandlers()) {\n+        for (String handlerClassName : type.getDefaultDataTypeHandlers()) {\n+          Class<? extends DataTypeHandler<?>> handlerClass;\n+          try {\n+            handlerClass = TypeRegistry.getHandlerClass(handlerClassName);\n+          } catch (ClassNotFoundException e) {\n+            throw new IllegalArgumentException(\"Unable to find \" + handlerClassName, e);\n+          }\n+          DataTypeHandler<?> handler;\n+          try {\n+            handler = handlerClass.newInstance();\n+          } catch (InstantiationException e) {\n+            throw new IllegalArgumentException(\"Unable to instantiate \" + handlerClassName, e);\n+          } catch (IllegalAccessException e) {\n+            throw new IllegalArgumentException(\"Unable to access default constructor for \" + handlerClassName, e);\n+          }\n+          String[] handlerTableNames = handler.getTableNames(conf);\n+          int[] handlerTablePriorities = handler.getTableLoaderPriorities(conf);\n+          for (int i = 0; i < handlerTableNames.length; i++) {\n+            tablePriorities.put(handlerTableNames[i], handlerTablePriorities[i]);\n+          }\n         }\n-        \n-        if (MetricsConfiguration.isEnabled(conf)) {\n-            String metricsTable = MetricsConfiguration.getTable(conf);\n-            int priority = MetricsConfiguration.getTablePriority(conf);\n-            if (org.apache.commons.lang.StringUtils.isNotBlank(metricsTable)) {\n-                tablePriorities.put(metricsTable, priority);\n-            }\n+      }\n+      if (null != type.getDefaultDataTypeFilters()) {\n+        for (String filterClassNames : type.getDefaultDataTypeFilters()) {\n+          Class<? extends KeyValueFilter<?, ?>> filterClass;\n+          try {\n+            filterClass = TypeRegistry.getFilterClass(filterClassNames);\n+          } catch (ClassNotFoundException e) {\n+            throw new IllegalArgumentException(\"Unable to find \" + filterClassNames, e);\n+          }\n+          KeyValueFilter<?, ?> filter;\n+          try {\n+            filter = filterClass.newInstance();\n+          } catch (InstantiationException e) {\n+            throw new IllegalArgumentException(\"Unable to instantiate \" + filterClassNames, e);\n+          } catch (IllegalAccessException e) {\n+            throw new IllegalArgumentException(\"Unable to access default constructor for \" + filterClassNames, e);\n+          }\n+          String[] filterTableNames = filter.getTableNames(conf);\n+          int[] filterTablePriorities = filter.getTableLoaderPriorities(conf);\n+          for (int i = 0; i < filterTableNames.length; i++) {\n+            tablePriorities.put(filterTableNames[i], filterTablePriorities[i]);\n+          }\n         }\n-        \n-        return tablePriorities;\n+      }\n+    }\n+\n+    if (MetricsConfiguration.isEnabled(conf)) {\n+      String metricsTable = MetricsConfiguration.getTable(conf);\n+      int priority = MetricsConfiguration.getTablePriority(conf);\n+      if (org.apache.commons.lang.StringUtils.isNotBlank(metricsTable)) {\n+        tablePriorities.put(metricsTable, priority);\n+      }\n+    }\n+\n+    return tablePriorities;\n+  }\n+\n+  /**\n+   * Looks up aggregator configuration for all of the tables in {@code tableNames} and serializes the configuration into {@code conf}, so that it is available\n+   * for retrieval and use in mappers or reducers. Currently, this is used in {@link AggregatingReducer} and its subclasses to aggregate output key/value\n+   * pairs rather than making accumulo do it at scan or major compaction time on the resulting rfile.\n+   *\n+   * @param accumuloHelper for accessing tableOperations\n+   * @param conf           the Hadoop configuration into which serialized aggregator configuration is placed\n+   * @param log            a logger for sending diagnostic information\n+   * @throws AccumuloSecurityException\n+   * @throws AccumuloException\n+   * @throws TableNotFoundException\n+   * @throws ClassNotFoundException\n+   */\n+  void serializeAggregatorConfiguration(AccumuloHelper accumuloHelper, Configuration conf, Logger log)\n+      throws AccumuloException, ClassNotFoundException,\n+      TableNotFoundException, AccumuloSecurityException {\n+\n+    if (conf.getBoolean(TableConfigCache.ACCUMULO_CONFIG_CACHE_ENABLE_PROPERTY, false)) {\n+      TableConfigCache cache = new TableConfigCache(conf);\n+      try {\n+        cache.read();\n+        return;\n+      } catch (Exception e) {\n+        log.error(\"Unable to read accumulo config cache at \" + cache.getCacheFilePath() +\n+            \". Proceeding to read directly from Accumulo.\");\n+      }\n+    }\n+    Map<String, String> configMap = getTableAggregatorConfigs(accumuloHelper, log, tableNames);\n+    for (Map.Entry entry : configMap.entrySet()) {\n+      conf.set(entry.getKey().toString(), entry.getValue().toString());\n     }\n-    \n-    /**\n-     * Looks up aggregator configuration for all of the tables in {@code tableNames} and serializes the configuration into {@code conf}, so that it is available\n-     * for retrieval and use in mappers or reducers. Currently, this is used in {@link AggregatingReducer} and its subclasses to aggregate output key/value\n-     * pairs rather than making accumulo do it at scan or major compaction time on the resulting rfile.\n-     *\n-     * @param accumuloHelper\n-     *            for accessing tableOperations\n-     * @param conf\n-     *            the Hadoop configuration into which serialized aggregator configuration is placed\n-     * @param log\n-     *            a logger for sending diagnostic information\n-     * @throws AccumuloSecurityException\n-     * @throws AccumuloException\n-     * @throws TableNotFoundException\n-     * @throws ClassNotFoundException\n-     */\n-    void serializeAggregatorConfiguration(AccumuloHelper accumuloHelper, Configuration conf, Logger log) throws AccumuloException, ClassNotFoundException,\n-                    TableNotFoundException, AccumuloSecurityException {\n-        \n-        if (conf.getBoolean(TableConfigCache.ACCUMULO_CONFIG_CACHE_ENABLE_PROPERTY, false)) {\n-            TableConfigCache cache = new TableConfigCache(conf);\n-            try {\n-                cache.read();\n-                return;\n-            } catch (Exception e) {\n-                log.error(\"Unable to read accumulo config cache at \" + cache.getCacheFilePath() + \". Proceeding to read directly from Accumulo.\");\n+\n+  }\n+\n+  public Map<String, String> getTableAggregatorConfigs()\n+      throws AccumuloException, ClassNotFoundException, TableNotFoundException, AccumuloSecurityException {\n+    return getTableAggregatorConfigs(accumuloHelper, log, tableNames);\n+  }\n+\n+  private static Map<String, String> getTableAggregatorConfigs(AccumuloHelper accumuloHelper, Logger log,\n+                                                               String[] tableNames)\n+      throws AccumuloSecurityException, AccumuloException, TableNotFoundException, ClassNotFoundException {\n+\n+    Map<String, String> configMap = new HashMap<>();\n+    try (AccumuloClient client = accumuloHelper.newClient()) {\n+      TableOperations tops = client.tableOperations();\n+\n+      // We're arbitrarily choosing the scan scope for gathering aggregator information.\n+      // For the aggregators configured in this job, that's ok since they are added to all\n+      // scopes. If someone manually added another aggregator and didn't apply it to scan\n+      // time, then we wouldn't pick that up here, but the chances of that are very small\n+      // since any aggregation we care about in the reducer doesn't make sense unless the\n+      // aggregator is a scan aggregator.\n+      IteratorUtil.IteratorScope scope = IteratorUtil.IteratorScope.scan;\n+      for (String table : tableNames) {\n+        ArrayList<IteratorSetting> iters = new ArrayList<>();\n+        HashMap<String, Map<String, String>> allOptions = new HashMap<>();\n+\n+        // Go through all of the configuration properties of this table and figure out which\n+        // properties represent iterator configuration. For those that do, store the iterator\n+        // setup and options in a map so that we can group together all of the options for each\n+        // iterator.\n+        for (Map.Entry<String, String> entry : tops.getProperties(table)) {\n+\n+          if (entry.getKey().startsWith(Property.TABLE_ITERATOR_PREFIX.getKey())) {\n+\n+            String suffix = entry.getKey().substring(Property.TABLE_ITERATOR_PREFIX.getKey().length());\n+            String suffixSplit[] = suffix.split(\"\\\\.\", 4);\n+\n+            if (!suffixSplit[0].equals(scope.name())) {\n+              continue;\n+            }\n+\n+            if (suffixSplit.length == 2) {\n+              String sa[] = entry.getValue().split(\",\");\n+              int prio = Integer.parseInt(sa[0]);\n+              String className = sa[1];\n+              iters.add(new IteratorSetting(prio, suffixSplit[1], className));\n+            } else if (suffixSplit.length == 4 && suffixSplit[2].equals(\"opt\")) {\n+              String iterName = suffixSplit[1];\n+              String optName = suffixSplit[3];\n+\n+              Map<String, String> options = allOptions.get(iterName);\n+              if (options == null) {\n+                options = new HashMap<>();\n+                allOptions.put(iterName, options);\n+              }\n+\n+              options.put(optName, entry.getValue());\n+\n+            } else {\n+              log.warn(\"Unrecognizable option: \" + entry.getKey());\n             }\n+          }\n         }\n-        Map<String,String> configMap = getTableAggregatorConfigs(accumuloHelper, log, tableNames);\n-        for (Map.Entry entry : configMap.entrySet()) {\n-            conf.set(entry.getKey().toString(), entry.getValue().toString());\n+\n+        // Now go through all of the iterators, and for those that are aggregators, store\n+        // the options in the Hadoop config so that we can parse it back out in the reducer.\n+        for (IteratorSetting iter : iters) {\n+          Class<?> klass = Class.forName(iter.getIteratorClass());\n+          if (PropogatingIterator.class.isAssignableFrom(klass)) {\n+            Map<String, String> options = allOptions.get(iter.getName());\n+            if (null != options) {\n+              for (Map.Entry<String, String> option : options.entrySet()) {\n+                String key = String.format(\"aggregator.%s.%d.%s\", table, iter.getPriority(), option.getKey());\n+                configMap.put(key, option.getValue());\n+              }\n+            } else {\n+              log.trace(\"Skipping iterator class \" + iter.getIteratorClass() + \" since it doesn't have options.\");\n+            }\n+\n+          } else {\n+            log.trace(\n+                \"Skipping iterator class \" + iter.getIteratorClass() + \" since it doesn't appear to be a combiner.\");\n+          }\n         }\n-        \n-    }\n-    \n-    public Map<String,String> getTableAggregatorConfigs() throws AccumuloException, ClassNotFoundException, TableNotFoundException, AccumuloSecurityException {\n-        return getTableAggregatorConfigs(accumuloHelper, log, tableNames);\n-    }\n-    \n-    private static Map<String,String> getTableAggregatorConfigs(AccumuloHelper accumuloHelper, Logger log, String[] tableNames)\n-                    throws AccumuloSecurityException, AccumuloException, TableNotFoundException, ClassNotFoundException {\n-        \n-        Map<String,String> configMap = new HashMap<>();\n-        try (AccumuloClient client = accumuloHelper.newClient()) {\n-            TableOperations tops = client.tableOperations();\n-            \n-            // We're arbitrarily choosing the scan scope for gathering aggregator information.\n-            // For the aggregators configured in this job, that's ok since they are added to all\n-            // scopes. If someone manually added another aggregator and didn't apply it to scan\n-            // time, then we wouldn't pick that up here, but the chances of that are very small\n-            // since any aggregation we care about in the reducer doesn't make sense unless the\n-            // aggregator is a scan aggregator.\n-            IteratorUtil.IteratorScope scope = IteratorUtil.IteratorScope.scan;\n-            for (String table : tableNames) {\n-                ArrayList<IteratorSetting> iters = new ArrayList<>();\n-                HashMap<String,Map<String,String>> allOptions = new HashMap<>();\n-                \n-                // Go through all of the configuration properties of this table and figure out which\n-                // properties represent iterator configuration. For those that do, store the iterator\n-                // setup and options in a map so that we can group together all of the options for each\n-                // iterator.\n-                for (Map.Entry<String,String> entry : tops.getProperties(table)) {\n-                    \n-                    if (entry.getKey().startsWith(Property.TABLE_ITERATOR_PREFIX.getKey())) {\n-                        \n-                        String suffix = entry.getKey().substring(Property.TABLE_ITERATOR_PREFIX.getKey().length());\n-                        String suffixSplit[] = suffix.split(\"\\\\.\", 4);\n-                        \n-                        if (!suffixSplit[0].equals(scope.name())) {\n-                            continue;\n-                        }\n-                        \n-                        if (suffixSplit.length == 2) {\n-                            String sa[] = entry.getValue().split(\",\");\n-                            int prio = Integer.parseInt(sa[0]);\n-                            String className = sa[1];\n-                            iters.add(new IteratorSetting(prio, suffixSplit[1], className));\n-                        } else if (suffixSplit.length == 4 && suffixSplit[2].equals(\"opt\")) {\n-                            String iterName = suffixSplit[1];\n-                            String optName = suffixSplit[3];\n-                            \n-                            Map<String,String> options = allOptions.get(iterName);\n-                            if (options == null) {\n-                                options = new HashMap<>();\n-                                allOptions.put(iterName, options);\n-                            }\n-                            \n-                            options.put(optName, entry.getValue());\n-                            \n-                        } else {\n-                            log.warn(\"Unrecognizable option: \" + entry.getKey());\n-                        }\n-                    }\n-                }\n-                \n-                // Now go through all of the iterators, and for those that are aggregators, store\n-                // the options in the Hadoop config so that we can parse it back out in the reducer.\n-                for (IteratorSetting iter : iters) {\n-                    Class<?> klass = Class.forName(iter.getIteratorClass());\n-                    if (PropogatingIterator.class.isAssignableFrom(klass)) {\n-                        Map<String,String> options = allOptions.get(iter.getName());\n-                        if (null != options) {\n-                            for (Map.Entry<String,String> option : options.entrySet()) {\n-                                String key = String.format(\"aggregator.%s.%d.%s\", table, iter.getPriority(), option.getKey());\n-                                configMap.put(key, option.getValue());\n-                            }\n-                        } else\n-                            log.trace(\"Skipping iterator class \" + iter.getIteratorClass() + \" since it doesn't have options.\");\n-                        \n-                    } else {\n-                        log.trace(\"Skipping iterator class \" + iter.getIteratorClass() + \" since it doesn't appear to be a combiner.\");\n-                    }\n-                }\n-                \n-                for (IteratorSetting iter : iters) {\n-                    Class<?> klass = Class.forName(iter.getIteratorClass());\n-                    if (Combiner.class.isAssignableFrom(klass)) {\n-                        Map<String,String> options = allOptions.get(iter.getName());\n-                        if (null != options) {\n-                            String key = String.format(\"combiner.%s.%d.iterClazz\", table, iter.getPriority());\n-                            configMap.put(key, iter.getIteratorClass());\n-                            for (Map.Entry<String,String> option : options.entrySet()) {\n-                                key = String.format(\"combiner.%s.%d.%s\", table, iter.getPriority(), option.getKey());\n-                                configMap.put(key, option.getValue());\n-                            }\n-                        } else\n-                            log.trace(\"Skipping iterator class \" + iter.getIteratorClass() + \" since it doesn't have options.\");\n-                    }\n-                }\n+\n+        for (IteratorSetting iter : iters) {\n+          Class<?> klass = Class.forName(iter.getIteratorClass());\n+          if (Combiner.class.isAssignableFrom(klass)) {\n+            Map<String, String> options = allOptions.get(iter.getName());\n+            if (null != options) {\n+              String key = String.format(\"combiner.%s.%d.iterClazz\", table, iter.getPriority());\n+              configMap.put(key, iter.getIteratorClass());\n+              for (Map.Entry<String, String> option : options.entrySet()) {\n+                key = String.format(\"combiner.%s.%d.%s\", table, iter.getPriority(), option.getKey());\n+                configMap.put(key, option.getValue());\n+              }\n+            } else {\n+              log.trace(\"Skipping iterator class \" + iter.getIteratorClass() + \" since it doesn't have options.\");\n             }\n+          }\n         }\n-        return configMap;\n+      }\n     }\n+    return configMap;\n+  }\n }\n",
            "diff_size": 556
        },
        {
            "tool": "naturalize",
            "errors": [
                {
                    "line": "23",
                    "severity": "error",
                    "message": "Accumulo non-public classes imported",
                    "source": "com.puppycrawl.tools.checkstyle.checks.regexp.RegexpSinglelineJavaCheck"
                }
            ],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/NationalSecurityAgency-datawave/errored/1/1/TableConfigurationUtil.java b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/NationalSecurityAgency-datawave/naturalize/1/TableConfigurationUtil.java\nindex dd4b03b676e..dec886f4b10 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/NationalSecurityAgency-datawave/errored/1/1/TableConfigurationUtil.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/NationalSecurityAgency-datawave/naturalize/1/TableConfigurationUtil.java\n@@ -394,7 +394,7 @@ public class TableConfigurationUtil {\n                         String suffixSplit[] = suffix.split(\"\\\\.\", 4);\n                         \n                         if (!suffixSplit[0].equals(scope.name())) {\n-                            continue;\n+    continue;\n                         }\n                         \n                         if (suffixSplit.length == 2) {\n@@ -405,9 +405,8 @@ public class TableConfigurationUtil {\n                         } else if (suffixSplit.length == 4 && suffixSplit[2].equals(\"opt\")) {\n                             String iterName = suffixSplit[1];\n                             String optName = suffixSplit[3];\n-                            \n-                            Map<String,String> options = allOptions.get(iterName);\n-                            if (options == null) {\n+Map<String,String> options = allOptions.get(iterName);\n+if (options == null) {\n                                 options = new HashMap<>();\n                                 allOptions.put(iterName, options);\n                             }\n@@ -433,8 +432,7 @@ public class TableConfigurationUtil {\n                             }\n                         } else\n                             log.trace(\"Skipping iterator class \" + iter.getIteratorClass() + \" since it doesn't have options.\");\n-                        \n-                    } else {\n+    } else {\n                         log.trace(\"Skipping iterator class \" + iter.getIteratorClass() + \" since it doesn't appear to be a combiner.\");\n                     }\n                 }\n@@ -458,4 +456,4 @@ public class TableConfigurationUtil {\n         }\n         return configMap;\n     }\n-}\n+}\n\\ No newline at end of file\n",
            "diff_size": 7
        },
        {
            "tool": "codebuff",
            "errors": [
                {
                    "line": "23",
                    "severity": "error",
                    "message": "Accumulo non-public classes imported",
                    "source": "com.puppycrawl.tools.checkstyle.checks.regexp.RegexpSinglelineJavaCheck"
                }
            ],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/NationalSecurityAgency-datawave/errored/1/1/TableConfigurationUtil.java b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/NationalSecurityAgency-datawave/codebuff/1/TableConfigurationUtil.java\nindex dd4b03b676e..39b06b75c18 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/NationalSecurityAgency-datawave/errored/1/1/TableConfigurationUtil.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/NationalSecurityAgency-datawave/codebuff/1/TableConfigurationUtil.java\n@@ -25,7 +25,6 @@ import org.apache.accumulo.core.iterators.Combiner;\n import org.apache.accumulo.core.iterators.IteratorUtil;\n import org.apache.hadoop.conf.Configuration;\n import org.apache.log4j.Logger;\n-\n import java.util.ArrayList;\n import java.util.Collections;\n import java.util.HashMap;\n@@ -33,18 +32,19 @@ import java.util.HashSet;\n import java.util.Map;\n import java.util.Set;\n \n+\n public class TableConfigurationUtil {\n-    \n+\n     protected static final Logger log = Logger.getLogger(TableConfigurationUtil.class.getName());\n     private String[] tableNames;\n     private AccumuloHelper accumuloHelper;\n-    \n+\n     public TableConfigurationUtil(Configuration conf) {\n         registerTableNames(conf);\n         accumuloHelper = new AccumuloHelper();\n         accumuloHelper.setup(conf);\n     }\n-    \n+\n     public String[] getTableNames() {\n         return tableNames;\n     }\n@@ -54,9 +54,9 @@ public class TableConfigurationUtil {\n      *            configuration file that contains data handler types and other information necessary for determining the set of tables required\n      * @return true if a non-empty comma separated list of table names was properly set to conf's job table.names property\n      */\n+\n     private boolean registerTableNames(Configuration conf) {\n         Set<String> tables = getTables(conf);\n-        \n         if (tables.isEmpty()) {\n             log.error(\"Configured tables for configured data types is empty\");\n             return false;\n@@ -73,9 +73,10 @@ public class TableConfigurationUtil {\n      *            hadoop configuration\n      * @return map of table names to priorities\n      */\n+\n     public static Set<String> getTables(Configuration conf) throws IllegalArgumentException {\n         TypeRegistry.getInstance(conf);\n-        \n+\n         Set<String> tables = new HashSet<>();\n         for (Type type : TypeRegistry.getTypes()) {\n             if (type.getDefaultDataTypeHandlers() != null) {\n@@ -86,6 +87,7 @@ public class TableConfigurationUtil {\n                     } catch (ClassNotFoundException e) {\n                         throw new IllegalArgumentException(\"Unable to find \" + handlerClassName, e);\n                     }\n+\n                     DataTypeHandler<?> handler;\n                     try {\n                         handler = handlerClass.newInstance();\n@@ -94,10 +96,13 @@ public class TableConfigurationUtil {\n                     } catch (IllegalAccessException e) {\n                         throw new IllegalArgumentException(\"Unable to access default constructor for \" + handlerClassName, e);\n                     }\n+\n                     String[] handlerTableNames = handler.getTableNames(conf);\n                     Collections.addAll(tables, handlerTableNames);\n                 }\n             }\n+\n+\n             if (type.getDefaultDataTypeFilters() != null) {\n                 for (String filterClassNames : type.getDefaultDataTypeFilters()) {\n                     Class<? extends KeyValueFilter<?,?>> filterClass;\n@@ -106,6 +111,7 @@ public class TableConfigurationUtil {\n                     } catch (ClassNotFoundException e) {\n                         throw new IllegalArgumentException(\"Unable to find \" + filterClassNames, e);\n                     }\n+\n                     KeyValueFilter<?,?> filter;\n                     try {\n                         filter = filterClass.newInstance();\n@@ -114,19 +120,20 @@ public class TableConfigurationUtil {\n                     } catch (IllegalAccessException e) {\n                         throw new IllegalArgumentException(\"Unable to access default constructor for \" + filterClassNames, e);\n                     }\n+\n                     String[] filterTableNames = filter.getTableNames(conf);\n                     Collections.addAll(tables, filterTableNames);\n                 }\n             }\n         }\n-        \n+\n+\n         if (MetricsConfiguration.isEnabled(conf)) {\n             String metricsTable = MetricsConfiguration.getTable(conf);\n             if (org.apache.commons.lang.StringUtils.isNotBlank(metricsTable)) {\n                 tables.add(metricsTable);\n             }\n         }\n-        \n         return tables;\n     }\n     \n@@ -138,6 +145,7 @@ public class TableConfigurationUtil {\n      * @throws AccumuloException\n      * @throws TableNotFoundException\n      */\n+\n     public boolean configureTables(Configuration conf) throws AccumuloSecurityException, AccumuloException, TableNotFoundException {\n         try (AccumuloClient client = accumuloHelper.newClient()) {\n             // Check to see if the tables exist\n@@ -145,7 +153,6 @@ public class TableConfigurationUtil {\n             NamespaceOperations namespaceOperations = client.namespaceOperations();\n             createAndConfigureTablesIfNecessary(tableNames, tops, namespaceOperations, conf, log, false);\n         }\n-        \n         return true;\n     }\n     \n@@ -167,8 +174,8 @@ public class TableConfigurationUtil {\n      * @throws AccumuloException\n      * @throws TableNotFoundException\n      */\n-    protected void createAndConfigureTablesIfNecessary(String[] tableNames, TableOperations tops, NamespaceOperations namespaceOperations, Configuration conf,\n-                    Logger log, boolean enableBloomFilters) throws AccumuloSecurityException, AccumuloException, TableNotFoundException {\n+\n+    protected void createAndConfigureTablesIfNecessary(String[] tableNames, TableOperations tops, NamespaceOperations namespaceOperations, Configuration conf, Logger log, boolean enableBloomFilters) throws AccumuloSecurityException, AccumuloException, TableNotFoundException {\n         for (String table : tableNames) {\n             createNamespaceIfNecessary(namespaceOperations, table);\n             // If the tables don't exist, then create them.\n@@ -184,11 +191,11 @@ public class TableConfigurationUtil {\n         \n         // Pass along the enabling of bloom filters using the configuration\n         conf.setBoolean(ShardTableConfigHelper.ENABLE_BLOOM_FILTERS, enableBloomFilters);\n-        \n         configureTablesIfNecessary(tableNames, tops, conf, log);\n     }\n-    \n-    private void createNamespaceIfNecessary(NamespaceOperations namespaceOperations, String table) throws AccumuloException, AccumuloSecurityException {\n+\n+    private void createNamespaceIfNecessary(NamespaceOperations namespaceOperations, String table) throws AccumuloException,\n+        AccumuloSecurityException {\n         // if the table has a namespace in it that doesn't already exist, create it\n         if (table.contains(\".\")) {\n             String namespace = table.split(\"\\\\.\")[0];\n@@ -218,11 +225,9 @@ public class TableConfigurationUtil {\n      * @throws AccumuloException\n      * @throws TableNotFoundException\n      */\n-    private void configureTablesIfNecessary(String[] tableNames, TableOperations tops, Configuration conf, Logger log) throws AccumuloSecurityException,\n-                    AccumuloException, TableNotFoundException {\n-        \n+\n+    private void configureTablesIfNecessary(String[] tableNames, TableOperations tops, Configuration conf, Logger log) throws AccumuloSecurityException, AccumuloException, TableNotFoundException {\n         Map<String,TableConfigHelper> tableConfigs = getTableConfigs(log, conf, tableNames);\n-        \n         for (String table : tableNames) {\n             TableConfigHelper tableHelper = tableConfigs.get(table);\n             if (tableHelper != null) {\n@@ -244,14 +249,12 @@ public class TableConfigurationUtil {\n      *            the names of the tables to configure\n      * @return Map&lt;String,TableConfigHelper&gt; map from table names to their setup TableConfigHelper classes\n      */\n+\n     private Map<String,TableConfigHelper> getTableConfigs(Logger log, Configuration conf, String[] tableNames) {\n-        \n         Map<String,TableConfigHelper> helperMap = new HashMap<>(tableNames.length);\n-        \n         for (String table : tableNames) {\n             helperMap.put(table, TableConfigHelperFactory.create(table, conf, log));\n         }\n-        \n         return helperMap;\n     }\n     \n@@ -262,8 +265,10 @@ public class TableConfigurationUtil {\n      *            hadoop configuration\n      * @return map of table names to priorities\n      */\n+\n     public static Map<String,Integer> getTablePriorities(Configuration conf) {\n         TypeRegistry.getInstance(conf);\n+\n         Map<String,Integer> tablePriorities = new HashMap<>();\n         for (Type type : TypeRegistry.getTypes()) {\n             if (null != type.getDefaultDataTypeHandlers()) {\n@@ -274,6 +279,7 @@ public class TableConfigurationUtil {\n                     } catch (ClassNotFoundException e) {\n                         throw new IllegalArgumentException(\"Unable to find \" + handlerClassName, e);\n                     }\n+\n                     DataTypeHandler<?> handler;\n                     try {\n                         handler = handlerClass.newInstance();\n@@ -282,6 +288,7 @@ public class TableConfigurationUtil {\n                     } catch (IllegalAccessException e) {\n                         throw new IllegalArgumentException(\"Unable to access default constructor for \" + handlerClassName, e);\n                     }\n+\n                     String[] handlerTableNames = handler.getTableNames(conf);\n                     int[] handlerTablePriorities = handler.getTableLoaderPriorities(conf);\n                     for (int i = 0; i < handlerTableNames.length; i++) {\n@@ -289,6 +296,8 @@ public class TableConfigurationUtil {\n                     }\n                 }\n             }\n+\n+\n             if (null != type.getDefaultDataTypeFilters()) {\n                 for (String filterClassNames : type.getDefaultDataTypeFilters()) {\n                     Class<? extends KeyValueFilter<?,?>> filterClass;\n@@ -297,6 +306,7 @@ public class TableConfigurationUtil {\n                     } catch (ClassNotFoundException e) {\n                         throw new IllegalArgumentException(\"Unable to find \" + filterClassNames, e);\n                     }\n+\n                     KeyValueFilter<?,?> filter;\n                     try {\n                         filter = filterClass.newInstance();\n@@ -305,6 +315,7 @@ public class TableConfigurationUtil {\n                     } catch (IllegalAccessException e) {\n                         throw new IllegalArgumentException(\"Unable to access default constructor for \" + filterClassNames, e);\n                     }\n+\n                     String[] filterTableNames = filter.getTableNames(conf);\n                     int[] filterTablePriorities = filter.getTableLoaderPriorities(conf);\n                     for (int i = 0; i < filterTableNames.length; i++) {\n@@ -313,7 +324,8 @@ public class TableConfigurationUtil {\n                 }\n             }\n         }\n-        \n+\n+\n         if (MetricsConfiguration.isEnabled(conf)) {\n             String metricsTable = MetricsConfiguration.getTable(conf);\n             int priority = MetricsConfiguration.getTablePriority(conf);\n@@ -321,7 +333,6 @@ public class TableConfigurationUtil {\n                 tablePriorities.put(metricsTable, priority);\n             }\n         }\n-        \n         return tablePriorities;\n     }\n     \n@@ -341,9 +352,8 @@ public class TableConfigurationUtil {\n      * @throws TableNotFoundException\n      * @throws ClassNotFoundException\n      */\n-    void serializeAggregatorConfiguration(AccumuloHelper accumuloHelper, Configuration conf, Logger log) throws AccumuloException, ClassNotFoundException,\n-                    TableNotFoundException, AccumuloSecurityException {\n-        \n+\n+    void serializeAggregatorConfiguration(AccumuloHelper accumuloHelper, Configuration conf, Logger log) throws AccumuloException, ClassNotFoundException, TableNotFoundException, AccumuloSecurityException {\n         if (conf.getBoolean(TableConfigCache.ACCUMULO_CONFIG_CACHE_ENABLE_PROPERTY, false)) {\n             TableConfigCache cache = new TableConfigCache(conf);\n             try {\n@@ -353,20 +363,18 @@ public class TableConfigurationUtil {\n                 log.error(\"Unable to read accumulo config cache at \" + cache.getCacheFilePath() + \". Proceeding to read directly from Accumulo.\");\n             }\n         }\n+\n         Map<String,String> configMap = getTableAggregatorConfigs(accumuloHelper, log, tableNames);\n         for (Map.Entry entry : configMap.entrySet()) {\n             conf.set(entry.getKey().toString(), entry.getValue().toString());\n         }\n-        \n     }\n-    \n+\n     public Map<String,String> getTableAggregatorConfigs() throws AccumuloException, ClassNotFoundException, TableNotFoundException, AccumuloSecurityException {\n         return getTableAggregatorConfigs(accumuloHelper, log, tableNames);\n     }\n-    \n-    private static Map<String,String> getTableAggregatorConfigs(AccumuloHelper accumuloHelper, Logger log, String[] tableNames)\n-                    throws AccumuloSecurityException, AccumuloException, TableNotFoundException, ClassNotFoundException {\n-        \n+\n+    private static Map<String,String> getTableAggregatorConfigs(AccumuloHelper accumuloHelper, Logger log, String[] tableNames) throws AccumuloSecurityException, AccumuloException, TableNotFoundException, ClassNotFoundException {\n         Map<String,String> configMap = new HashMap<>();\n         try (AccumuloClient client = accumuloHelper.newClient()) {\n             TableOperations tops = client.tableOperations();\n@@ -387,16 +395,14 @@ public class TableConfigurationUtil {\n                 // setup and options in a map so that we can group together all of the options for each\n                 // iterator.\n                 for (Map.Entry<String,String> entry : tops.getProperties(table)) {\n-                    \n                     if (entry.getKey().startsWith(Property.TABLE_ITERATOR_PREFIX.getKey())) {\n-                        \n                         String suffix = entry.getKey().substring(Property.TABLE_ITERATOR_PREFIX.getKey().length());\n                         String suffixSplit[] = suffix.split(\"\\\\.\", 4);\n-                        \n                         if (!suffixSplit[0].equals(scope.name())) {\n                             continue;\n                         }\n-                        \n+\n+\n                         if (suffixSplit.length == 2) {\n                             String sa[] = entry.getValue().split(\",\");\n                             int prio = Integer.parseInt(sa[0]);\n@@ -405,16 +411,13 @@ public class TableConfigurationUtil {\n                         } else if (suffixSplit.length == 4 && suffixSplit[2].equals(\"opt\")) {\n                             String iterName = suffixSplit[1];\n                             String optName = suffixSplit[3];\n-                            \n                             Map<String,String> options = allOptions.get(iterName);\n                             if (options == null) {\n                                 options = new HashMap<>();\n                                 allOptions.put(iterName, options);\n                             }\n-                            \n                             options.put(optName, entry.getValue());\n-                            \n-                        } else {\n+                                                                                            } else {\n                             log.warn(\"Unrecognizable option: \" + entry.getKey());\n                         }\n                     }\n@@ -433,12 +436,10 @@ public class TableConfigurationUtil {\n                             }\n                         } else\n                             log.trace(\"Skipping iterator class \" + iter.getIteratorClass() + \" since it doesn't have options.\");\n-                        \n                     } else {\n                         log.trace(\"Skipping iterator class \" + iter.getIteratorClass() + \" since it doesn't appear to be a combiner.\");\n                     }\n                 }\n-                \n                 for (IteratorSetting iter : iters) {\n                     Class<?> klass = Class.forName(iter.getIteratorClass());\n                     if (Combiner.class.isAssignableFrom(klass)) {\n@@ -446,6 +447,7 @@ public class TableConfigurationUtil {\n                         if (null != options) {\n                             String key = String.format(\"combiner.%s.%d.iterClazz\", table, iter.getPriority());\n                             configMap.put(key, iter.getIteratorClass());\n+\n                             for (Map.Entry<String,String> option : options.entrySet()) {\n                                 key = String.format(\"combiner.%s.%d.%s\", table, iter.getPriority(), option.getKey());\n                                 configMap.put(key, option.getValue());\n@@ -458,4 +460,5 @@ public class TableConfigurationUtil {\n         }\n         return configMap;\n     }\n-}\n+\n+}\n\\ No newline at end of file\n",
            "diff_size": 69
        },
        {
            "tool": "styler_random",
            "errors": [
                {
                    "line": "23",
                    "severity": "error",
                    "message": "Accumulo non-public classes imported",
                    "source": "com.puppycrawl.tools.checkstyle.checks.regexp.RegexpSinglelineJavaCheck"
                }
            ],
            "diff": "",
            "diff_size": 0
        },
        {
            "tool": "styler_three_grams",
            "errors": [],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/NationalSecurityAgency-datawave/errored/1/1/TableConfigurationUtil.java b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/NationalSecurityAgency-datawave/styler_three_grams/1/TableConfigurationUtil.java\nindex dd4b03b676e..554794a9d15 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/NationalSecurityAgency-datawave/errored/1/1/TableConfigurationUtil.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/NationalSecurityAgency-datawave/styler_three_grams/1/TableConfigurationUtil.java\n@@ -20,8 +20,9 @@ import org.apache.accumulo.core.client.AccumuloSecurityException;\n import org.apache.accumulo.core.client.TableNotFoundException;\n import org.apache.accumulo.core.client.admin.NamespaceOperations;\n import org.apache.accumulo.core.client.admin.TableOperations;\n-import org.apache.accumulo.core.conf.Property;\n-import org.apache.accumulo.core.iterators.Combiner;\n+import\n+org.apache.accumulo.core.conf.Property;\n+ import org.apache.accumulo.core.iterators.Combiner;\n import org.apache.accumulo.core.iterators.IteratorUtil;\n import org.apache.hadoop.conf.Configuration;\n import org.apache.log4j.Logger;\n",
            "diff_size": 3
        }
    ],
    "repaired_by": [
        "styler",
        "styler_three_grams"
    ],
    "not_repaired_by": [
        "intellij",
        "naturalize",
        "codebuff",
        "styler_random"
    ]
}