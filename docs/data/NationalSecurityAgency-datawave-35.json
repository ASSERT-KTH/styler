{
    "project_name": "NationalSecurityAgency-datawave",
    "error_id": "35",
    "information": {
        "errors": [
            {
                "line": "17",
                "severity": "error",
                "message": "Accumulo non-public classes imported",
                "source": "com.puppycrawl.tools.checkstyle.checks.regexp.RegexpSinglelineJavaCheck"
            }
        ]
    },
    "source_code": "import org.apache.accumulo.core.client.Connector;\nimport org.apache.accumulo.core.client.IteratorSetting;\nimport org.apache.accumulo.core.conf.AccumuloConfiguration;\nimport org.apache.accumulo.core.data.ByteSequence;\nimport org.apache.accumulo.core.data.Key;\nimport org.apache.accumulo.core.data.Range;",
    "results": [
        {
            "tool": "styler",
            "errors": [],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/NationalSecurityAgency-datawave/errored/1/35/RfileScanner.java b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/NationalSecurityAgency-datawave/styler/35/RfileScanner.java\nindex 3e3e12e1f1d..0e36c53ee93 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/NationalSecurityAgency-datawave/errored/1/35/RfileScanner.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/NationalSecurityAgency-datawave/styler/35/RfileScanner.java\n@@ -14,8 +14,9 @@ import java.util.concurrent.atomic.AtomicBoolean;\n import org.apache.accumulo.core.client.BatchScanner;\n import org.apache.accumulo.core.client.Connector;\n import org.apache.accumulo.core.client.IteratorSetting;\n-import org.apache.accumulo.core.conf.AccumuloConfiguration;\n-import org.apache.accumulo.core.data.ByteSequence;\n+import\n+org.apache.accumulo.core.conf.AccumuloConfiguration;\n+ import org.apache.accumulo.core.data.ByteSequence;\n import org.apache.accumulo.core.data.Key;\n import org.apache.accumulo.core.data.Range;\n import org.apache.accumulo.core.data.Value;\n",
            "diff_size": 3
        },
        {
            "tool": "intellij",
            "errors": [
                {
                    "line": "17",
                    "severity": "error",
                    "message": "Accumulo non-public classes imported",
                    "source": "com.puppycrawl.tools.checkstyle.checks.regexp.RegexpSinglelineJavaCheck"
                }
            ],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/NationalSecurityAgency-datawave/errored/1/35/RfileScanner.java b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/NationalSecurityAgency-datawave/intellij/35/RfileScanner.java\nindex 3e3e12e1f1d..3fb55796d22 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/NationalSecurityAgency-datawave/errored/1/35/RfileScanner.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/NationalSecurityAgency-datawave/intellij/35/RfileScanner.java\n@@ -37,220 +37,224 @@ import datawave.security.iterator.ConfigurableVisibilityFilter;\n import datawave.security.util.AuthorizationsUtil;\n \n public class RfileScanner extends SessionOptions implements BatchScanner, Closeable {\n-    \n-    private static final Logger log = Logger.getLogger(RfileScanner.class);\n-    \n-    private List<Range> ranges;\n-    private String table;\n-    private Configuration conf;\n-    \n-    protected List<RecordIterator> iterators;\n-    \n-    protected Set<Authorizations> auths;\n-    \n-    protected Iterator<Authorizations> authIter;\n-    \n-    protected String recordIterAuthString;\n-    \n-    protected AtomicBoolean resought = new AtomicBoolean(false);\n-    \n-    protected AtomicBoolean closed = new AtomicBoolean(false);\n-    \n-    private static Cache<String,AccumuloConfiguration> tableConfigMap = CacheBuilder.newBuilder().maximumSize(100).concurrencyLevel(100)\n-                    .expireAfterAccess(24, TimeUnit.HOURS).build();\n-    \n-    private static Cache<String,String> tableIdMap = CacheBuilder.newBuilder().maximumSize(100).concurrencyLevel(100).expireAfterAccess(24, TimeUnit.HOURS)\n-                    .build();\n-    \n-    protected Connector connector;\n-    \n-    public RfileScanner(Connector connector, Configuration conf, String table, Set<Authorizations> auths, int numQueryThreads) {\n-        ArgumentChecker.notNull(connector, conf, table, auths);\n-        this.table = table;\n-        this.auths = auths;\n-        this.connector = connector;\n-        ranges = null;\n-        authIter = AuthorizationsUtil.minimize(auths).iterator();\n-        recordIterAuthString = authIter.next().toString();\n-        iterators = Lists.newArrayList();\n-        iterators = Collections.synchronizedList(iterators);\n-        setConfiguration(conf);\n-    }\n-    \n-    public void setConfiguration(Configuration conf) {\n-        this.conf = new Configuration(conf);\n-        \n-        this.conf.setBoolean(MultiRfileInputformat.CACHE_METADATA, true);\n-        this.conf.set(\"recorditer.auth.string\", recordIterAuthString);\n-    }\n-    \n-    @Override\n-    public void setRanges(Collection<Range> ranges) {\n-        if (ranges == null || ranges.isEmpty()) {\n-            throw new IllegalArgumentException(\"ranges must be non null and contain at least 1 range\");\n-        }\n-        \n-        this.ranges = Lists.newArrayList(ranges);\n-        \n+\n+  private static final Logger log = Logger.getLogger(RfileScanner.class);\n+\n+  private List<Range> ranges;\n+  private String table;\n+  private Configuration conf;\n+\n+  protected List<RecordIterator> iterators;\n+\n+  protected Set<Authorizations> auths;\n+\n+  protected Iterator<Authorizations> authIter;\n+\n+  protected String recordIterAuthString;\n+\n+  protected AtomicBoolean resought = new AtomicBoolean(false);\n+\n+  protected AtomicBoolean closed = new AtomicBoolean(false);\n+\n+  private static Cache<String, AccumuloConfiguration> tableConfigMap =\n+      CacheBuilder.newBuilder().maximumSize(100).concurrencyLevel(100)\n+          .expireAfterAccess(24, TimeUnit.HOURS).build();\n+\n+  private static Cache<String, String> tableIdMap =\n+      CacheBuilder.newBuilder().maximumSize(100).concurrencyLevel(100).expireAfterAccess(24, TimeUnit.HOURS)\n+          .build();\n+\n+  protected Connector connector;\n+\n+  public RfileScanner(Connector connector, Configuration conf, String table, Set<Authorizations> auths,\n+                      int numQueryThreads) {\n+    ArgumentChecker.notNull(connector, conf, table, auths);\n+    this.table = table;\n+    this.auths = auths;\n+    this.connector = connector;\n+    ranges = null;\n+    authIter = AuthorizationsUtil.minimize(auths).iterator();\n+    recordIterAuthString = authIter.next().toString();\n+    iterators = Lists.newArrayList();\n+    iterators = Collections.synchronizedList(iterators);\n+    setConfiguration(conf);\n+  }\n+\n+  public void setConfiguration(Configuration conf) {\n+    this.conf = new Configuration(conf);\n+\n+    this.conf.setBoolean(MultiRfileInputformat.CACHE_METADATA, true);\n+    this.conf.set(\"recorditer.auth.string\", recordIterAuthString);\n+  }\n+\n+  @Override\n+  public void setRanges(Collection<Range> ranges) {\n+    if (ranges == null || ranges.isEmpty()) {\n+      throw new IllegalArgumentException(\"ranges must be non null and contain at least 1 range\");\n     }\n-    \n-    protected void addVisibilityFilters(Iterator<Authorizations> iter) {\n-        for (int priority = 10; iter.hasNext(); priority++) {\n-            IteratorSetting cfg = new IteratorSetting(priority, ConfigurableVisibilityFilter.class);\n-            cfg.setName(\"visibilityFilter\" + priority);\n-            cfg.addOption(ConfigurableVisibilityFilter.AUTHORIZATIONS_OPT, iter.next().toString());\n-            BulkInputFormat.addIterator(conf, cfg);\n-        }\n+\n+    this.ranges = Lists.newArrayList(ranges);\n+\n+  }\n+\n+  protected void addVisibilityFilters(Iterator<Authorizations> iter) {\n+    for (int priority = 10; iter.hasNext(); priority++) {\n+      IteratorSetting cfg = new IteratorSetting(priority, ConfigurableVisibilityFilter.class);\n+      cfg.setName(\"visibilityFilter\" + priority);\n+      cfg.addOption(ConfigurableVisibilityFilter.AUTHORIZATIONS_OPT, iter.next().toString());\n+      BulkInputFormat.addIterator(conf, cfg);\n     }\n-    \n-    public void seek(Range range) throws IOException {\n-        seek(range, Collections.emptyList(), false);\n+  }\n+\n+  public void seek(Range range) throws IOException {\n+    seek(range, Collections.emptyList(), false);\n+  }\n+\n+  public void seek(Range range, Collection<ByteSequence> columnFamilies, boolean inclusive) throws IOException {\n+    for (RecordIterator ri : iterators) {\n+      ri.seek(range, columnFamilies, inclusive);\n     }\n-    \n-    public void seek(Range range, Collection<ByteSequence> columnFamilies, boolean inclusive) throws IOException {\n-        for (RecordIterator ri : iterators) {\n-            ri.seek(range, columnFamilies, inclusive);\n-        }\n-        resought.set(true);\n+    resought.set(true);\n+  }\n+\n+  protected Iterator<Entry<Key, Value>> getIterator(List<InputSplit> splits, AccumuloConfiguration acuTableConf) {\n+    // optimization for single tablets\n+    Iterator<Entry<Key, Value>> kv = Iterators.emptyIterator();\n+    for (InputSplit split : splits) {\n+      RecordIterator recordIter = null;\n+\n+      recordIter = new RecordIterator((TabletSplitSplit) split, acuTableConf, conf);\n+\n+      iterators.add(recordIter);\n+\n+      kv = Iterators.concat(kv, new RfileIterator(recordIter));\n+\n     }\n-    \n-    protected Iterator<Entry<Key,Value>> getIterator(List<InputSplit> splits, AccumuloConfiguration acuTableConf) {\n-        // optimization for single tablets\n-        Iterator<Entry<Key,Value>> kv = Iterators.emptyIterator();\n-        for (InputSplit split : splits) {\n-            RecordIterator recordIter = null;\n-            \n-            recordIter = new RecordIterator((TabletSplitSplit) split, acuTableConf, conf);\n-            \n-            iterators.add(recordIter);\n-            \n-            kv = Iterators.concat(kv, new RfileIterator(recordIter));\n-            \n+\n+    return kv;\n+  }\n+\n+  @Override\n+  public Iterator<Entry<Key, Value>> iterator() {\n+\n+    Iterator<Entry<Key, Value>> kv = null;\n+    try {\n+      if (resought.get()) {\n+        resought.set(false);\n+\n+        kv = Iterators.emptyIterator();\n+\n+        for (RecordIterator recordIterator : iterators) {\n+          kv = Iterators.concat(kv, new RfileIterator(recordIterator));\n         }\n-        \n         return kv;\n-    }\n-    \n-    @Override\n-    public Iterator<Entry<Key,Value>> iterator() {\n-        \n-        Iterator<Entry<Key,Value>> kv = null;\n-        try {\n-            if (resought.get()) {\n-                resought.set(false);\n-                \n-                kv = Iterators.emptyIterator();\n-                \n-                for (RecordIterator recordIterator : iterators) {\n-                    kv = Iterators.concat(kv, new RfileIterator(recordIterator));\n-                }\n-                return kv;\n-            }\n-            if (ranges == null) {\n-                throw new IllegalStateException(\"ranges not set\");\n-            }\n-            addVisibilityFilters(authIter);\n-            List<InputSplit> splits;\n-            for (IteratorSetting setting : getIterators()) {\n-                BulkInputFormat.addIterator(conf, setting);\n+      }\n+      if (ranges == null) {\n+        throw new IllegalStateException(\"ranges not set\");\n+      }\n+      addVisibilityFilters(authIter);\n+      List<InputSplit> splits;\n+      for (IteratorSetting setting : getIterators()) {\n+        BulkInputFormat.addIterator(conf, setting);\n+      }\n+\n+      final long failureSleep =\n+          conf.getLong(RecordIterator.RECORDITER_FAILURE_SLEEP_INTERVAL, RecordIterator.DEFAULT_FAILURE_SLEEP);\n+      try {\n+        splits = MultiRfileInputformat.computeSplitPoints(connector, conf, table, ranges);\n+        if (log.isDebugEnabled()) {\n+          log.debug(\"Completed \" + splits.size() + \" splits\");\n+        }\n+        String tableId = tableIdMap.getIfPresent(table);\n+        if (null == tableId) {\n+          tableId = connector.tableOperations().tableIdMap().get(table);\n+          tableIdMap.put(table, tableId);\n+        }\n+        AccumuloConfiguration acuTableConf = tableConfigMap.getIfPresent(tableId);\n+        if (null == acuTableConf) {\n+          acuTableConf = AccumuloConfiguration.getTableConfiguration(connector, tableId);\n+          tableConfigMap.put(tableId, acuTableConf);\n+        }\n+\n+        int maxRetries = conf.getInt(RecordIterator.RECORDITER_FAILURE_COUNT_MAX, RecordIterator.FAILURE_MAX_DEFAULT);\n+        int retries = 0;\n+        do {\n+          if (closed.get()) {\n+            log.warn(\"Giving up because we are closed\");\n+            break;\n+          }\n+          try {\n+            kv = getIterator(splits, acuTableConf);\n+          } catch (Exception e) {\n+            log.debug(\"Failed to get iterator for splits\", e);\n+\n+            // clear out the iterators\n+            clearIterators();\n+\n+            // an exception has occurred that won't allow us to open the files. perhaps one was moved\n+            // immediately upon opening the tablet.\n+            if (++retries > maxRetries) {\n+              log.warn(\"Giving up because\" + retries + \" >= \" + maxRetries, e);\n+              throw e;\n             }\n-            \n-            final long failureSleep = conf.getLong(RecordIterator.RECORDITER_FAILURE_SLEEP_INTERVAL, RecordIterator.DEFAULT_FAILURE_SLEEP);\n-            try {\n-                splits = MultiRfileInputformat.computeSplitPoints(connector, conf, table, ranges);\n-                if (log.isDebugEnabled()) {\n-                    log.debug(\"Completed \" + splits.size() + \" splits\");\n-                }\n-                String tableId = tableIdMap.getIfPresent(table);\n-                if (null == tableId) {\n-                    tableId = connector.tableOperations().tableIdMap().get(table);\n-                    tableIdMap.put(table, tableId);\n-                }\n-                AccumuloConfiguration acuTableConf = tableConfigMap.getIfPresent(tableId);\n-                if (null == acuTableConf) {\n-                    acuTableConf = AccumuloConfiguration.getTableConfiguration(connector, tableId);\n-                    tableConfigMap.put(tableId, acuTableConf);\n-                }\n-                \n-                int maxRetries = conf.getInt(RecordIterator.RECORDITER_FAILURE_COUNT_MAX, RecordIterator.FAILURE_MAX_DEFAULT);\n-                int retries = 0;\n-                do {\n-                    if (closed.get()) {\n-                        log.warn(\"Giving up because we are closed\");\n-                        break;\n-                    }\n-                    try {\n-                        kv = getIterator(splits, acuTableConf);\n-                    } catch (Exception e) {\n-                        log.debug(\"Failed to get iterator for splits\", e);\n-                        \n-                        // clear out the iterators\n-                        clearIterators();\n-                        \n-                        // an exception has occurred that won't allow us to open the files. perhaps one was moved\n-                        // immediately upon opening the tablet.\n-                        if (++retries > maxRetries) {\n-                            log.warn(\"Giving up because\" + retries + \" >= \" + maxRetries, e);\n-                            throw e;\n-                        }\n-                        if (log.isDebugEnabled()) {\n-                            log.debug(\"Retry #\" + retries + \" to get splits and build an iterator\");\n-                        }\n-                        \n-                        MultiRfileInputformat.clearMetadataCache();\n-                        \n-                        Thread.sleep(failureSleep);\n-                        \n-                        splits = MultiRfileInputformat.computeSplitPoints(connector, conf, table, ranges);\n-                        if (log.isDebugEnabled()) {\n-                            log.debug(\"Recomputed \" + splits.size() + \" splits\");\n-                        }\n-                    }\n-                    if (log.isTraceEnabled()) {\n-                        log.trace(\"KV iterator is \" + (kv == null ? \"null\" : \"not null\"));\n-                    }\n-                } while (null == kv);\n-                \n-            } catch (Exception e) {\n-                IOUtils.cleanup(null, this);\n-                throw new RuntimeException(e);\n+            if (log.isDebugEnabled()) {\n+              log.debug(\"Retry #\" + retries + \" to get splits and build an iterator\");\n             }\n-        } finally {\n-            /**\n-             * This is required because Hadoop will swallow the interrupt. As a result we must notify ourselves that the interrupt occurred. In doing so we call\n-             * a subsequent close here since we weren't interrupted in the call to getIterator(...).\n-             */\n-            if (closed.get()) {\n-                close();\n+\n+            MultiRfileInputformat.clearMetadataCache();\n+\n+            Thread.sleep(failureSleep);\n+\n+            splits = MultiRfileInputformat.computeSplitPoints(connector, conf, table, ranges);\n+            if (log.isDebugEnabled()) {\n+              log.debug(\"Recomputed \" + splits.size() + \" splits\");\n             }\n-        }\n-        return kv;\n-        \n-    }\n-    \n-    @Override\n-    public void close() {\n-        log.info(\"Closing RfileScanner\");\n-        /**\n-         * This is required because Hadoop will swallow the interrupt. As a result we must notify ourselves that the interrupt occurred. In doing so we call a\n-         * subsequent close here since we weren't interrupted in the call to getIterator(...).\n-         */\n-        closed.set(true);\n-        \n-        clearIterators();\n+          }\n+          if (log.isTraceEnabled()) {\n+            log.trace(\"KV iterator is \" + (kv == null ? \"null\" : \"not null\"));\n+          }\n+        } while (null == kv);\n+\n+      } catch (Exception e) {\n+        IOUtils.cleanup(null, this);\n+        throw new RuntimeException(e);\n+      }\n+    } finally {\n+      /**\n+       * This is required because Hadoop will swallow the interrupt. As a result we must notify ourselves that the interrupt occurred. In doing so we call\n+       * a subsequent close here since we weren't interrupted in the call to getIterator(...).\n+       */\n+      if (closed.get()) {\n+        close();\n+      }\n     }\n-    \n+    return kv;\n+\n+  }\n+\n+  @Override\n+  public void close() {\n+    log.info(\"Closing RfileScanner\");\n     /**\n-     * Clear out the current set of iterators\n+     * This is required because Hadoop will swallow the interrupt. As a result we must notify ourselves that the interrupt occurred. In doing so we call a\n+     * subsequent close here since we weren't interrupted in the call to getIterator(...).\n      */\n-    private void clearIterators() {\n-        for (RecordIterator iter : iterators) {\n-            try {\n-                iter.close();\n-            } catch (IOException e) {\n-                log.error(e);\n-            }\n-        }\n-        iterators = Lists.newArrayList();\n+    closed.set(true);\n+\n+    clearIterators();\n+  }\n+\n+  /**\n+   * Clear out the current set of iterators\n+   */\n+  private void clearIterators() {\n+    for (RecordIterator iter : iterators) {\n+      try {\n+        iter.close();\n+      } catch (IOException e) {\n+        log.error(e);\n+      }\n     }\n+    iterators = Lists.newArrayList();\n+  }\n }\n",
            "diff_size": 267
        },
        {
            "tool": "naturalize",
            "errors": [
                {
                    "line": "17",
                    "severity": "error",
                    "message": "Accumulo non-public classes imported",
                    "source": "com.puppycrawl.tools.checkstyle.checks.regexp.RegexpSinglelineJavaCheck"
                }
            ],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/NationalSecurityAgency-datawave/errored/1/35/RfileScanner.java b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/NationalSecurityAgency-datawave/naturalize/35/RfileScanner.java\nindex 3e3e12e1f1d..4698f4c94d2 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/NationalSecurityAgency-datawave/errored/1/35/RfileScanner.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/NationalSecurityAgency-datawave/naturalize/35/RfileScanner.java\n@@ -59,8 +59,7 @@ public class RfileScanner extends SessionOptions implements BatchScanner, Closea\n     private static Cache<String,AccumuloConfiguration> tableConfigMap = CacheBuilder.newBuilder().maximumSize(100).concurrencyLevel(100)\n                     .expireAfterAccess(24, TimeUnit.HOURS).build();\n     \n-    private static Cache<String,String> tableIdMap = CacheBuilder.newBuilder().maximumSize(100).concurrencyLevel(100).expireAfterAccess(24, TimeUnit.HOURS)\n-                    .build();\n+    private static Cache<String,String> tableIdMap = CacheBuilder.newBuilder().maximumSize(100).concurrencyLevel(100).expireAfterAccess(24, TimeUnit.HOURS).build();\n     \n     protected Connector connector;\n     \n@@ -202,7 +201,7 @@ public class RfileScanner extends SessionOptions implements BatchScanner, Closea\n                         Thread.sleep(failureSleep);\n                         \n                         splits = MultiRfileInputformat.computeSplitPoints(connector, conf, table, ranges);\n-                        if (log.isDebugEnabled()) {\n+if (log.isDebugEnabled()) {\n                             log.debug(\"Recomputed \" + splits.size() + \" splits\");\n                         }\n                     }\n@@ -253,4 +252,4 @@ public class RfileScanner extends SessionOptions implements BatchScanner, Closea\n         }\n         iterators = Lists.newArrayList();\n     }\n-}\n+}\n\\ No newline at end of file\n",
            "diff_size": 4
        },
        {
            "tool": "codebuff",
            "errors": [
                {
                    "line": "16",
                    "severity": "error",
                    "message": "Accumulo non-public classes imported",
                    "source": "com.puppycrawl.tools.checkstyle.checks.regexp.RegexpSinglelineJavaCheck"
                }
            ],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/NationalSecurityAgency-datawave/errored/1/35/RfileScanner.java b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/NationalSecurityAgency-datawave/codebuff/35/RfileScanner.java\nindex 3e3e12e1f1d..e6b0204295e 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/NationalSecurityAgency-datawave/errored/1/35/RfileScanner.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/NationalSecurityAgency-datawave/codebuff/35/RfileScanner.java\n@@ -10,7 +10,6 @@ import java.util.Map.Entry;\n import java.util.Set;\n import java.util.concurrent.TimeUnit;\n import java.util.concurrent.atomic.AtomicBoolean;\n-\n import org.apache.accumulo.core.client.BatchScanner;\n import org.apache.accumulo.core.client.Connector;\n import org.apache.accumulo.core.client.IteratorSetting;\n@@ -25,45 +24,31 @@ import org.apache.hadoop.conf.Configuration;\n import org.apache.hadoop.io.IOUtils;\n import org.apache.hadoop.mapreduce.InputSplit;\n import org.apache.log4j.Logger;\n-\n import com.google.common.cache.Cache;\n import com.google.common.cache.CacheBuilder;\n import com.google.common.collect.Iterators;\n import com.google.common.collect.Lists;\n-\n import datawave.mr.bulk.split.TabletSplitSplit;\n import datawave.query.tables.SessionOptions;\n import datawave.security.iterator.ConfigurableVisibilityFilter;\n import datawave.security.util.AuthorizationsUtil;\n \n+\n public class RfileScanner extends SessionOptions implements BatchScanner, Closeable {\n-    \n     private static final Logger log = Logger.getLogger(RfileScanner.class);\n-    \n     private List<Range> ranges;\n     private String table;\n     private Configuration conf;\n-    \n     protected List<RecordIterator> iterators;\n-    \n     protected Set<Authorizations> auths;\n-    \n     protected Iterator<Authorizations> authIter;\n-    \n     protected String recordIterAuthString;\n-    \n     protected AtomicBoolean resought = new AtomicBoolean(false);\n-    \n     protected AtomicBoolean closed = new AtomicBoolean(false);\n-    \n-    private static Cache<String,AccumuloConfiguration> tableConfigMap = CacheBuilder.newBuilder().maximumSize(100).concurrencyLevel(100)\n-                    .expireAfterAccess(24, TimeUnit.HOURS).build();\n-    \n-    private static Cache<String,String> tableIdMap = CacheBuilder.newBuilder().maximumSize(100).concurrencyLevel(100).expireAfterAccess(24, TimeUnit.HOURS)\n-                    .build();\n-    \n+    private static Cache<String,AccumuloConfiguration> tableConfigMap = CacheBuilder.newBuilder().maximumSize(100).concurrencyLevel(100).expireAfterAccess(24, TimeUnit.HOURS).build();\n+    private static Cache<String,String> tableIdMap = CacheBuilder.newBuilder().maximumSize(100).concurrencyLevel(100).expireAfterAccess(24, TimeUnit.HOURS).build();\n     protected Connector connector;\n-    \n+\n     public RfileScanner(Connector connector, Configuration conf, String table, Set<Authorizations> auths, int numQueryThreads) {\n         ArgumentChecker.notNull(connector, conf, table, auths);\n         this.table = table;\n@@ -76,24 +61,21 @@ public class RfileScanner extends SessionOptions implements BatchScanner, Closea\n         iterators = Collections.synchronizedList(iterators);\n         setConfiguration(conf);\n     }\n-    \n+\n     public void setConfiguration(Configuration conf) {\n         this.conf = new Configuration(conf);\n-        \n         this.conf.setBoolean(MultiRfileInputformat.CACHE_METADATA, true);\n         this.conf.set(\"recorditer.auth.string\", recordIterAuthString);\n     }\n-    \n+\n     @Override\n     public void setRanges(Collection<Range> ranges) {\n         if (ranges == null || ranges.isEmpty()) {\n             throw new IllegalArgumentException(\"ranges must be non null and contain at least 1 range\");\n         }\n-        \n         this.ranges = Lists.newArrayList(ranges);\n-        \n     }\n-    \n+\n     protected void addVisibilityFilters(Iterator<Authorizations> iter) {\n         for (int priority = 10; iter.hasNext(); priority++) {\n             IteratorSetting cfg = new IteratorSetting(priority, ConfigurableVisibilityFilter.class);\n@@ -102,76 +84,73 @@ public class RfileScanner extends SessionOptions implements BatchScanner, Closea\n             BulkInputFormat.addIterator(conf, cfg);\n         }\n     }\n-    \n+\n     public void seek(Range range) throws IOException {\n         seek(range, Collections.emptyList(), false);\n     }\n-    \n+\n     public void seek(Range range, Collection<ByteSequence> columnFamilies, boolean inclusive) throws IOException {\n         for (RecordIterator ri : iterators) {\n             ri.seek(range, columnFamilies, inclusive);\n         }\n         resought.set(true);\n     }\n-    \n+\n     protected Iterator<Entry<Key,Value>> getIterator(List<InputSplit> splits, AccumuloConfiguration acuTableConf) {\n         // optimization for single tablets\n         Iterator<Entry<Key,Value>> kv = Iterators.emptyIterator();\n         for (InputSplit split : splits) {\n             RecordIterator recordIter = null;\n-            \n             recordIter = new RecordIterator((TabletSplitSplit) split, acuTableConf, conf);\n-            \n             iterators.add(recordIter);\n-            \n             kv = Iterators.concat(kv, new RfileIterator(recordIter));\n-            \n         }\n-        \n         return kv;\n     }\n-    \n+\n     @Override\n     public Iterator<Entry<Key,Value>> iterator() {\n-        \n         Iterator<Entry<Key,Value>> kv = null;\n         try {\n             if (resought.get()) {\n                 resought.set(false);\n-                \n                 kv = Iterators.emptyIterator();\n-                \n+\n                 for (RecordIterator recordIterator : iterators) {\n                     kv = Iterators.concat(kv, new RfileIterator(recordIterator));\n                 }\n                 return kv;\n             }\n+\n+\n             if (ranges == null) {\n                 throw new IllegalStateException(\"ranges not set\");\n             }\n             addVisibilityFilters(authIter);\n+\n             List<InputSplit> splits;\n             for (IteratorSetting setting : getIterators()) {\n                 BulkInputFormat.addIterator(conf, setting);\n             }\n-            \n+\n             final long failureSleep = conf.getLong(RecordIterator.RECORDITER_FAILURE_SLEEP_INTERVAL, RecordIterator.DEFAULT_FAILURE_SLEEP);\n             try {\n                 splits = MultiRfileInputformat.computeSplitPoints(connector, conf, table, ranges);\n                 if (log.isDebugEnabled()) {\n                     log.debug(\"Completed \" + splits.size() + \" splits\");\n                 }\n+\n                 String tableId = tableIdMap.getIfPresent(table);\n                 if (null == tableId) {\n                     tableId = connector.tableOperations().tableIdMap().get(table);\n                     tableIdMap.put(table, tableId);\n                 }\n+\n                 AccumuloConfiguration acuTableConf = tableConfigMap.getIfPresent(tableId);\n                 if (null == acuTableConf) {\n                     acuTableConf = AccumuloConfiguration.getTableConfiguration(connector, tableId);\n                     tableConfigMap.put(tableId, acuTableConf);\n                 }\n-                \n                 int maxRetries = conf.getInt(RecordIterator.RECORDITER_FAILURE_COUNT_MAX, RecordIterator.FAILURE_MAX_DEFAULT);\n                 int retries = 0;\n                 do {\n@@ -179,6 +158,7 @@ public class RfileScanner extends SessionOptions implements BatchScanner, Closea\n                         log.warn(\"Giving up because we are closed\");\n                         break;\n                     }\n+\n                     try {\n                         kv = getIterator(splits, acuTableConf);\n                     } catch (Exception e) {\n@@ -193,24 +173,24 @@ public class RfileScanner extends SessionOptions implements BatchScanner, Closea\n                             log.warn(\"Giving up because\" + retries + \" >= \" + maxRetries, e);\n                             throw e;\n                         }\n+\n+\n                         if (log.isDebugEnabled()) {\n                             log.debug(\"Retry #\" + retries + \" to get splits and build an iterator\");\n                         }\n-                        \n                         MultiRfileInputformat.clearMetadataCache();\n-                        \n                         Thread.sleep(failureSleep);\n-                        \n                         splits = MultiRfileInputformat.computeSplitPoints(connector, conf, table, ranges);\n                         if (log.isDebugEnabled()) {\n                             log.debug(\"Recomputed \" + splits.size() + \" splits\");\n                         }\n                     }\n+\n+\n                     if (log.isTraceEnabled()) {\n                         log.trace(\"KV iterator is \" + (kv == null ? \"null\" : \"not null\"));\n                     }\n                 } while (null == kv);\n-                \n             } catch (Exception e) {\n                 IOUtils.cleanup(null, this);\n                 throw new RuntimeException(e);\n@@ -225,9 +205,8 @@ public class RfileScanner extends SessionOptions implements BatchScanner, Closea\n             }\n         }\n         return kv;\n-        \n     }\n-    \n+\n     @Override\n     public void close() {\n         log.info(\"Closing RfileScanner\");\n@@ -236,13 +215,13 @@ public class RfileScanner extends SessionOptions implements BatchScanner, Closea\n          * subsequent close here since we weren't interrupted in the call to getIterator(...).\n          */\n         closed.set(true);\n-        \n         clearIterators();\n     }\n     \n     /**\n      * Clear out the current set of iterators\n      */\n+\n     private void clearIterators() {\n         for (RecordIterator iter : iterators) {\n             try {\n@@ -253,4 +232,4 @@ public class RfileScanner extends SessionOptions implements BatchScanner, Closea\n         }\n         iterators = Lists.newArrayList();\n     }\n-}\n+}\n\\ No newline at end of file\n",
            "diff_size": 59
        },
        {
            "tool": "styler_random",
            "errors": [
                {
                    "line": "17",
                    "severity": "error",
                    "message": "Accumulo non-public classes imported",
                    "source": "com.puppycrawl.tools.checkstyle.checks.regexp.RegexpSinglelineJavaCheck"
                }
            ],
            "diff": "",
            "diff_size": 0
        },
        {
            "tool": "styler_three_grams",
            "errors": [],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/NationalSecurityAgency-datawave/errored/1/35/RfileScanner.java b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/NationalSecurityAgency-datawave/styler_three_grams/35/RfileScanner.java\nindex 3e3e12e1f1d..0e36c53ee93 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/NationalSecurityAgency-datawave/errored/1/35/RfileScanner.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/NationalSecurityAgency-datawave/styler_three_grams/35/RfileScanner.java\n@@ -14,8 +14,9 @@ import java.util.concurrent.atomic.AtomicBoolean;\n import org.apache.accumulo.core.client.BatchScanner;\n import org.apache.accumulo.core.client.Connector;\n import org.apache.accumulo.core.client.IteratorSetting;\n-import org.apache.accumulo.core.conf.AccumuloConfiguration;\n-import org.apache.accumulo.core.data.ByteSequence;\n+import\n+org.apache.accumulo.core.conf.AccumuloConfiguration;\n+ import org.apache.accumulo.core.data.ByteSequence;\n import org.apache.accumulo.core.data.Key;\n import org.apache.accumulo.core.data.Range;\n import org.apache.accumulo.core.data.Value;\n",
            "diff_size": 3
        }
    ],
    "repaired_by": [
        "styler",
        "styler_three_grams"
    ],
    "not_repaired_by": [
        "intellij",
        "naturalize",
        "codebuff",
        "styler_random"
    ]
}