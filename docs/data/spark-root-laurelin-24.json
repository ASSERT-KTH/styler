{
    "project_name": "spark-root-laurelin",
    "error_id": "24",
    "information": {
        "errors": [
            {
                "line": "156",
                "column": "73",
                "severity": "warning",
                "message": "WhitespaceAround: ':' is not preceded with whitespace.",
                "source": "com.puppycrawl.tools.checkstyle.checks.whitespace.WhitespaceAroundCheck"
            }
        ]
    },
    "source_code": "        }\n\n        assert qualifiedListingToStatusMap.size() >= globResolved.size(): \"qualifiedlisting < globresolved\";\n\n        /*\n         *  At this point, we have a list of post-globbing URIs and lists of",
    "results": [
        {
            "tool": "styler",
            "errors": [],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/spark-root-laurelin/errored/1/24/IOFactory.java b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/spark-root-laurelin/styler/24/IOFactory.java\nindex 07824e1d7b5..30cfb5b0d2f 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/spark-root-laurelin/errored/1/24/IOFactory.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/spark-root-laurelin/styler/24/IOFactory.java\n@@ -153,7 +153,7 @@ public class IOFactory {\n             }\n         }\n \n-        assert qualifiedListingToStatusMap.size() >= globResolved.size(): \"qualifiedlisting < globresolved\";\n+        assert qualifiedListingToStatusMap.size() >= globResolved.size() : \"qualifiedlisting < globresolved\";\n \n         /*\n          *  At this point, we have a list of post-globbing URIs and lists of\n",
            "diff_size": 1
        },
        {
            "tool": "intellij",
            "errors": [
                {
                    "line": "161",
                    "column": "77",
                    "severity": "warning",
                    "message": "'==' should be on a new line.",
                    "source": "com.puppycrawl.tools.checkstyle.checks.whitespace.OperatorWrapCheck"
                },
                {
                    "line": "197",
                    "column": "39",
                    "severity": "warning",
                    "message": "'&&' should be on a new line.",
                    "source": "com.puppycrawl.tools.checkstyle.checks.whitespace.OperatorWrapCheck"
                }
            ],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/spark-root-laurelin/errored/1/24/IOFactory.java b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/spark-root-laurelin/intellij/24/IOFactory.java\nindex 07824e1d7b5..3c93af24863 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/spark-root-laurelin/errored/1/24/IOFactory.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/spark-root-laurelin/intellij/24/IOFactory.java\n@@ -54,7 +54,9 @@ public class IOFactory {\n         return ret;\n     }\n \n-    private static FileSystem getFileSystemFromPath(Path path, Configuration hadoopConf) throws IOException {\n+    private static FileSystem getFileSystemFromPath(Path path,\n+                                                    Configuration hadoopConf)\n+        throws IOException {\n         FileSystem ret;\n         if (Pattern.matches(hadoopPattern, path.toString())) {\n             ret = path.getFileSystem(hadoopConf);\n@@ -72,10 +74,12 @@ public class IOFactory {\n      * @return Fully expanded list of ROOT file paths\n      * @throws IOException If any globs don't resolve or paths don't exist\n      */\n-    public static List<Path> resolvePathList(List<String> paths) throws IOException {\n+    public static List<Path> resolvePathList(List<String> paths)\n+        throws IOException {\n         Configuration hadoopConf;\n         try {\n-            hadoopConf = SparkSession.active().sparkContext().hadoopConfiguration();\n+            hadoopConf =\n+                SparkSession.active().sparkContext().hadoopConfiguration();\n         } catch (IllegalStateException e) {\n             hadoopConf = new Configuration();\n         }\n@@ -87,15 +91,17 @@ public class IOFactory {\n      * directories listed in the list. This version of resolvePathList is used\n      * in unit tests to inject a custom hadoop config.\n      *\n-     * @param paths Paths to be expanded\n+     * @param paths      Paths to be expanded\n      * @param hadoopConf hadoop configuration to use.\n      * @return Fully expanded list of ROOT file paths\n      * @throws IOException If any globs don't resolve or paths don't exist\n      */\n-    public static List<Path> resolvePathList(List<String> paths, Configuration hadoopConf) throws IOException {\n+    public static List<Path> resolvePathList(List<String> paths,\n+                                             Configuration hadoopConf)\n+        throws IOException {\n         List<Path> globResolved = new ArrayList<Path>(paths.size());\n         // First perform any globbing\n-        for (String path: paths) {\n+        for (String path : paths) {\n             if (isGlob(path)) {\n                 globResolved.addAll(resolveGlob(path, hadoopConf));\n             } else {\n@@ -128,40 +134,47 @@ public class IOFactory {\n \n         // Loop over all the paths and keep the unique parents of them all\n         // TODO: Is repeatedly instantiating FileSystem objects slow over WAN?\n-        Map<Path, List<FileStatus>> parentDirectories = new HashMap<Path, List<FileStatus>>();\n+        Map<Path, List<FileStatus>> parentDirectories =\n+            new HashMap<Path, List<FileStatus>>();\n         Map<Path, Path> childToParentMap = new HashMap<Path, Path>();\n         Map<Path, Path> qualifiedChildToParentMap = new HashMap<Path, Path>();\n-        for (Path path: globResolved) {\n+        for (Path path : globResolved) {\n             Path parent = path.getParent();\n             parentDirectories.put(parent, null);\n             childToParentMap.put(path, parent);\n             FileSystem fs = getFileSystemFromPath(parent, hadoopConf);\n-            Path qualifiedChild = path.makeQualified(fs.getUri(), fs.getWorkingDirectory());\n+            Path qualifiedChild =\n+                path.makeQualified(fs.getUri(), fs.getWorkingDirectory());\n             qualifiedChildToParentMap.put(qualifiedChild, parent);\n         }\n \n         // Retrieve the listing for all the parent dirs\n-        Map<Path, List<FileStatus>> parentToStatusMap = new HashMap<Path, List<FileStatus>>();\n-        Map<Path, FileStatus> qualifiedListingToStatusMap = new HashMap<Path, FileStatus>();\n-        for (Path parent: parentDirectories.keySet()) {\n+        Map<Path, List<FileStatus>> parentToStatusMap =\n+            new HashMap<Path, List<FileStatus>>();\n+        Map<Path, FileStatus> qualifiedListingToStatusMap =\n+            new HashMap<Path, FileStatus>();\n+        for (Path parent : parentDirectories.keySet()) {\n             FileSystem fs = getFileSystemFromPath(parent, hadoopConf);\n             FileStatus[] listing = fs.listStatus(parent);\n             parentToStatusMap.put(parent, Arrays.asList(listing));\n-            for (FileStatus s: listing) {\n-                assert qualifiedListingToStatusMap.containsKey(s.getPath()) == false;\n+            for (FileStatus s : listing) {\n+                assert qualifiedListingToStatusMap.containsKey(s.getPath()) ==\n+                    false;\n                 qualifiedListingToStatusMap.put(s.getPath(), s);\n             }\n         }\n \n-        assert qualifiedListingToStatusMap.size() >= globResolved.size(): \"qualifiedlisting < globresolved\";\n+        assert qualifiedListingToStatusMap.size() >= globResolved.size() :\n+            \"qualifiedlisting < globresolved\";\n \n         /*\n          *  At this point, we have a list of post-globbing URIs and lists of\n          *  FileStatus for every parent of those URIs. Use this to make a map of\n          *  Globbed path -> FileStatus\n          */\n-        Map<Path, FileStatus> clientRequestedPathToStatusMap = new HashMap<Path, FileStatus>();\n-        for (Entry<Path, Path> e: qualifiedChildToParentMap.entrySet()) {\n+        Map<Path, FileStatus> clientRequestedPathToStatusMap =\n+            new HashMap<Path, FileStatus>();\n+        for (Entry<Path, Path> e : qualifiedChildToParentMap.entrySet()) {\n             if (!qualifiedListingToStatusMap.containsKey(e.getKey())) {\n                 throw new IOException(\"Path not found: \" + e.getKey());\n             }\n@@ -171,15 +184,18 @@ public class IOFactory {\n \n         // Walk the statuses to sort between files and directories\n         List<Path> ret = new ArrayList<Path>(globResolved.size());\n-        for (FileStatus status: clientRequestedPathToStatusMap.values()) {\n+        for (FileStatus status : clientRequestedPathToStatusMap.values()) {\n             Path path = status.getPath();\n             if (status.isDirectory()) {\n                 // We were given a directory, add everything recursively\n-                FileSystem fs = getFileSystemFromPath(status.getPath(), hadoopConf);\n-                RemoteIterator<LocatedFileStatus> fileList = fs.listFiles(status.getPath(), true);\n+                FileSystem fs =\n+                    getFileSystemFromPath(status.getPath(), hadoopConf);\n+                RemoteIterator<LocatedFileStatus> fileList =\n+                    fs.listFiles(status.getPath(), true);\n                 while (fileList.hasNext()) {\n                     LocatedFileStatus file = fileList.next();\n-                    if (file.isFile() && (file.getPath().getName().endsWith(\".root\"))) {\n+                    if (file.isFile() &&\n+                        (file.getPath().getName().endsWith(\".root\"))) {\n                         ret.add(file.getPath());\n                     }\n                 }\n@@ -195,26 +211,32 @@ public class IOFactory {\n \n     /**\n      * Perform glob expansion on a path\n-     * @param path Glob to expand\n+     *\n+     * @param path       Glob to expand\n      * @param hadoopConf configuration to use\n      * @return List of paths that match the given glob\n      * @throws IOException Nothing matches the given glob\n      */\n-    private static List<Path> resolveGlob(String path, Configuration hadoopConf) throws IOException {\n+    private static List<Path> resolveGlob(String path, Configuration hadoopConf)\n+        throws IOException {\n         Path hdfsPath = new Path(path);\n         FileSystem fs = getFileSystemFromPath(hdfsPath, hadoopConf);\n-        Path qualified = hdfsPath.makeQualified(fs.getUri(), fs.getWorkingDirectory());\n-        Seq<Path> globPath = SparkHadoopUtil.get().globPathIfNecessary(fs, qualified);\n+        Path qualified =\n+            hdfsPath.makeQualified(fs.getUri(), fs.getWorkingDirectory());\n+        Seq<Path> globPath =\n+            SparkHadoopUtil.get().globPathIfNecessary(fs, qualified);\n         if (globPath.isEmpty()) {\n             throw new IOException(\"Path does not exist: \" + qualified);\n         }\n         // TODO: Is this stable across Scala versions?\n-        List<Path> ret = JavaConverters.seqAsJavaListConverter(globPath).asJava();\n+        List<Path> ret =\n+            JavaConverters.seqAsJavaListConverter(globPath).asJava();\n         return ret;\n     }\n \n     /**\n      * See if the given path has any glob metacharacters\n+     *\n      * @param path Input path\n      * @return True if the path looks like a glob. False otherwise.\n      */\n",
            "diff_size": 48
        },
        {
            "tool": "naturalize",
            "errors": [
                {
                    "line": "47",
                    "column": "5",
                    "severity": "warning",
                    "message": "'if rcurly' has incorrect indentation level 4, expected level should be 8.",
                    "source": "com.puppycrawl.tools.checkstyle.checks.indentation.IndentationCheck"
                },
                {
                    "line": "155",
                    "column": "73",
                    "severity": "warning",
                    "message": "WhitespaceAround: ':' is not preceded with whitespace.",
                    "source": "com.puppycrawl.tools.checkstyle.checks.whitespace.WhitespaceAroundCheck"
                },
                {
                    "line": "211",
                    "column": "1",
                    "severity": "warning",
                    "message": "Comment has incorrect indentation level 0, expected is 8, indentation should be the same level as line 212.",
                    "source": "com.puppycrawl.tools.checkstyle.checks.indentation.CommentsIndentationCheck"
                }
            ],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/spark-root-laurelin/errored/1/24/IOFactory.java b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/spark-root-laurelin/naturalize/24/IOFactory.java\nindex 07824e1d7b5..6b87ebfe3f2 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/spark-root-laurelin/errored/1/24/IOFactory.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/spark-root-laurelin/naturalize/24/IOFactory.java\n@@ -44,8 +44,7 @@ public class IOFactory {\n             //Only support reading xz-compressed files locally\n             path = path.replace(\"$$XZ$$\", \"\");\n             ret = new XZDecompressionWrapper(path);\n-\n-        } else if (Pattern.matches(hadoopPattern, path)) {\n+    } else if (Pattern.matches(hadoopPattern, path)) {\n             ret = new HadoopFile(path);\n         } else {\n             ret = new NIOFile(path);\n@@ -208,7 +207,8 @@ public class IOFactory {\n         if (globPath.isEmpty()) {\n             throw new IOException(\"Path does not exist: \" + qualified);\n         }\n-        // TODO: Is this stable across Scala versions?\n+\n+// TODO: Is this stable across Scala versions?\n         List<Path> ret = JavaConverters.seqAsJavaListConverter(globPath).asJava();\n         return ret;\n     }\n@@ -221,4 +221,4 @@ public class IOFactory {\n     private static boolean isGlob(String path) {\n         return path.matches(\".*[{}\\\\[\\\\]*?].*\");\n     }\n-}\n+}\n\\ No newline at end of file\n",
            "diff_size": 5
        },
        {
            "tool": "codebuff",
            "errors": [
                {
                    "line": "48",
                    "column": "20",
                    "severity": "warning",
                    "message": "'else' child has incorrect indentation level 19, expected level should be 12.",
                    "source": "com.puppycrawl.tools.checkstyle.checks.indentation.IndentationCheck"
                },
                {
                    "line": "153",
                    "column": "73",
                    "severity": "warning",
                    "message": "WhitespaceAround: ':' is not preceded with whitespace.",
                    "source": "com.puppycrawl.tools.checkstyle.checks.whitespace.WhitespaceAroundCheck"
                },
                {
                    "line": "186",
                    "column": "24",
                    "severity": "warning",
                    "message": "'else' child has incorrect indentation level 23, expected level should be 16.",
                    "source": "com.puppycrawl.tools.checkstyle.checks.indentation.IndentationCheck"
                }
            ],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/spark-root-laurelin/errored/1/24/IOFactory.java b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/spark-root-laurelin/codebuff/24/IOFactory.java\nindex 07824e1d7b5..ec30910a160 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/spark-root-laurelin/errored/1/24/IOFactory.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/spark-root-laurelin/codebuff/24/IOFactory.java\n@@ -12,7 +12,6 @@ import java.util.List;\n import java.util.Map;\n import java.util.Map.Entry;\n import java.util.regex.Pattern;\n-\n import org.apache.hadoop.conf.Configuration;\n import org.apache.hadoop.fs.FileStatus;\n import org.apache.hadoop.fs.FileSystem;\n@@ -21,7 +20,6 @@ import org.apache.hadoop.fs.Path;\n import org.apache.hadoop.fs.RemoteIterator;\n import org.apache.spark.deploy.SparkHadoopUtil;\n import org.apache.spark.sql.SparkSession;\n-\n import edu.vanderbilt.accre.laurelin.root_proxy.XZDecompressionWrapper;\n import scala.collection.JavaConverters;\n import scala.collection.Seq;\n@@ -44,13 +42,11 @@ public class IOFactory {\n             //Only support reading xz-compressed files locally\n             path = path.replace(\"$$XZ$$\", \"\");\n             ret = new XZDecompressionWrapper(path);\n-\n         } else if (Pattern.matches(hadoopPattern, path)) {\n             ret = new HadoopFile(path);\n         } else {\n-            ret = new NIOFile(path);\n+                   ret = new NIOFile(path);\n         }\n-\n         return ret;\n     }\n \n@@ -72,6 +68,7 @@ public class IOFactory {\n      * @return Fully expanded list of ROOT file paths\n      * @throws IOException If any globs don't resolve or paths don't exist\n      */\n+\n     public static List<Path> resolvePathList(List<String> paths) throws IOException {\n         Configuration hadoopConf;\n         try {\n@@ -92,6 +89,7 @@ public class IOFactory {\n      * @return Fully expanded list of ROOT file paths\n      * @throws IOException If any globs don't resolve or paths don't exist\n      */\n+\n     public static List<Path> resolvePathList(List<String> paths, Configuration hadoopConf) throws IOException {\n         List<Path> globResolved = new ArrayList<Path>(paths.size());\n         // First perform any globbing\n@@ -152,7 +150,6 @@ public class IOFactory {\n                 qualifiedListingToStatusMap.put(s.getPath(), s);\n             }\n         }\n-\n         assert qualifiedListingToStatusMap.size() >= globResolved.size(): \"qualifiedlisting < globresolved\";\n \n         /*\n@@ -186,10 +183,9 @@ public class IOFactory {\n             } else if (status.isFile()) {\n                 ret.add(status.getPath());\n             } else {\n-                throw new IOException(\"File '\" + path + \"' is an unknown type\");\n+                       throw new IOException(\"File '\" + path + \"' is an unknown type\");\n             }\n         }\n-\n         return ret;\n     }\n \n@@ -200,6 +196,7 @@ public class IOFactory {\n      * @return List of paths that match the given glob\n      * @throws IOException Nothing matches the given glob\n      */\n+\n     private static List<Path> resolveGlob(String path, Configuration hadoopConf) throws IOException {\n         Path hdfsPath = new Path(path);\n         FileSystem fs = getFileSystemFromPath(hdfsPath, hadoopConf);\n@@ -218,7 +215,8 @@ public class IOFactory {\n      * @param path Input path\n      * @return True if the path looks like a glob. False otherwise.\n      */\n+\n     private static boolean isGlob(String path) {\n         return path.matches(\".*[{}\\\\[\\\\]*?].*\");\n     }\n-}\n+}\n\\ No newline at end of file\n",
            "diff_size": 13
        },
        {
            "tool": "styler_random",
            "errors": [],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/spark-root-laurelin/errored/1/24/IOFactory.java b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/spark-root-laurelin/styler_random/24/IOFactory.java\nindex 07824e1d7b5..30cfb5b0d2f 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/spark-root-laurelin/errored/1/24/IOFactory.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/spark-root-laurelin/styler_random/24/IOFactory.java\n@@ -153,7 +153,7 @@ public class IOFactory {\n             }\n         }\n \n-        assert qualifiedListingToStatusMap.size() >= globResolved.size(): \"qualifiedlisting < globresolved\";\n+        assert qualifiedListingToStatusMap.size() >= globResolved.size() : \"qualifiedlisting < globresolved\";\n \n         /*\n          *  At this point, we have a list of post-globbing URIs and lists of\n",
            "diff_size": 1
        },
        {
            "tool": "styler_three_grams",
            "errors": [],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/spark-root-laurelin/errored/1/24/IOFactory.java b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/spark-root-laurelin/styler_three_grams/24/IOFactory.java\nindex 07824e1d7b5..30cfb5b0d2f 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/spark-root-laurelin/errored/1/24/IOFactory.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/spark-root-laurelin/styler_three_grams/24/IOFactory.java\n@@ -153,7 +153,7 @@ public class IOFactory {\n             }\n         }\n \n-        assert qualifiedListingToStatusMap.size() >= globResolved.size(): \"qualifiedlisting < globresolved\";\n+        assert qualifiedListingToStatusMap.size() >= globResolved.size() : \"qualifiedlisting < globresolved\";\n \n         /*\n          *  At this point, we have a list of post-globbing URIs and lists of\n",
            "diff_size": 1
        }
    ],
    "repaired_by": [
        "styler",
        "styler_random",
        "styler_three_grams"
    ],
    "not_repaired_by": [
        "intellij",
        "naturalize",
        "codebuff"
    ]
}