{
    "project_name": "NationalSecurityAgency-datawave",
    "error_id": "85",
    "information": {
        "errors": [
            {
                "line": "11",
                "severity": "error",
                "message": "Accumulo non-public classes imported",
                "source": "com.puppycrawl.tools.checkstyle.checks.regexp.RegexpSinglelineJavaCheck"
            }
        ]
    },
    "source_code": "import org.apache.accumulo.core.data.Value;\nimport org.apache.accumulo.core.security.ColumnVisibility;\nimport org.apache.accumulo.hadoop.mapreduce.AccumuloOutputFormat;\nimport org.apache.hadoop.io.Text;\nimport org.apache.hadoop.io.Writable;\nimport org.apache.hadoop.mapred.lib.aggregate.LongValueSum;",
    "results": [
        {
            "tool": "styler",
            "errors": [
                {
                    "line": "11",
                    "severity": "error",
                    "message": "Accumulo non-public classes imported",
                    "source": "com.puppycrawl.tools.checkstyle.checks.regexp.RegexpSinglelineJavaCheck"
                }
            ],
            "diff": "",
            "diff_size": 0
        },
        {
            "tool": "intellij",
            "errors": [
                {
                    "line": "11",
                    "severity": "error",
                    "message": "Accumulo non-public classes imported",
                    "source": "com.puppycrawl.tools.checkstyle.checks.regexp.RegexpSinglelineJavaCheck"
                }
            ],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/NationalSecurityAgency-datawave/errored/1/85/MetricsDailySummaryReducer.java b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/NationalSecurityAgency-datawave/intellij/85/MetricsDailySummaryReducer.java\nindex 450da89169c..10c84e82d68 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/NationalSecurityAgency-datawave/errored/1/85/MetricsDailySummaryReducer.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/NationalSecurityAgency-datawave/intellij/85/MetricsDailySummaryReducer.java\n@@ -25,217 +25,225 @@ import java.util.Collections;\n  * Writes daily/hourly summary metrics information out to Accumulo. All incoming keys having the same date, metric name, metric value have their counts added\n  * together before the ouptut is returned.\n  */\n-public class MetricsDailySummaryReducer extends Reducer<Key,Value,Text,Mutation> {\n-    public static final String STATS_METRIC_VALUE = \"__stats__\";\n-    private static final Text STATS_METRIC_TEXT = new Text(STATS_METRIC_VALUE);\n-    public static final String PERCENTILE_STATS_METRIC_VALUE = \"__pstats__\";\n-    private static final Text PERCENTILE_STATS_METRIC_TEXT = new Text(PERCENTILE_STATS_METRIC_VALUE);\n-    private static final Text MIN_TEXT = new Text(\"MIN\");\n-    private static final Text MAX_TEXT = new Text(\"MAX\");\n-    private static final Text MEDIAN_TEXT = new Text(\"MEDIAN\");\n-    private static final Text AVERAGE_TEXT = new Text(\"AVERAGE\");\n-    private static final Text PERCENTILE_TEXT = new Text(\"95TH_PERCENTILE\");\n-    private static final int MAX_MEDIAN_COUNT = 4000000;\n-    \n-    private Text holder = new Text();\n-    private ArrayList<Long> longs = new ArrayList<>(MAX_MEDIAN_COUNT);\n-    private ArrayList<WeightedPair> pairs = new ArrayList<>(MAX_MEDIAN_COUNT);\n-    private Text empty = new Text();\n-    \n-    @Override\n-    protected void reduce(Key key, Iterable<Value> values, Context context) throws IOException, InterruptedException {\n-        key.getColumnQualifier(holder);\n-        Mutation m;\n-        if (STATS_METRIC_TEXT.equals(holder))\n-            m = statsMutation(key, values);\n-        else if (PERCENTILE_STATS_METRIC_TEXT.equals(holder))\n-            m = statsPercentileMutation(key, values);\n-        else\n-            m = sumMutation(key, values);\n-        context.write(empty, m);\n+public class MetricsDailySummaryReducer extends Reducer<Key, Value, Text, Mutation> {\n+  public static final String STATS_METRIC_VALUE = \"__stats__\";\n+  private static final Text STATS_METRIC_TEXT = new Text(STATS_METRIC_VALUE);\n+  public static final String PERCENTILE_STATS_METRIC_VALUE = \"__pstats__\";\n+  private static final Text PERCENTILE_STATS_METRIC_TEXT = new Text(PERCENTILE_STATS_METRIC_VALUE);\n+  private static final Text MIN_TEXT = new Text(\"MIN\");\n+  private static final Text MAX_TEXT = new Text(\"MAX\");\n+  private static final Text MEDIAN_TEXT = new Text(\"MEDIAN\");\n+  private static final Text AVERAGE_TEXT = new Text(\"AVERAGE\");\n+  private static final Text PERCENTILE_TEXT = new Text(\"95TH_PERCENTILE\");\n+  private static final int MAX_MEDIAN_COUNT = 4000000;\n+\n+  private Text holder = new Text();\n+  private ArrayList<Long> longs = new ArrayList<>(MAX_MEDIAN_COUNT);\n+  private ArrayList<WeightedPair> pairs = new ArrayList<>(MAX_MEDIAN_COUNT);\n+  private Text empty = new Text();\n+\n+  @Override\n+  protected void reduce(Key key, Iterable<Value> values, Context context) throws IOException, InterruptedException {\n+    key.getColumnQualifier(holder);\n+    Mutation m;\n+    if (STATS_METRIC_TEXT.equals(holder)) {\n+      m = statsMutation(key, values);\n+    } else if (PERCENTILE_STATS_METRIC_TEXT.equals(holder)) {\n+      m = statsPercentileMutation(key, values);\n+    } else {\n+      m = sumMutation(key, values);\n     }\n-    \n-    /**\n-     * Computes a simple summation metric value. The key is written out as is and the values, assumed to be string longs, are aggregated and written out.\n-     */\n-    private Mutation sumMutation(Key key, Iterable<Value> values) {\n-        LongValueSum sum = new LongValueSum();\n-        for (Value v : values)\n-            sum.addNextValue(v);\n-        \n-        ColumnVisibility columnVisibility = new ColumnVisibility(key.getColumnVisibility());\n-        Mutation m = new Mutation(key.getRow());\n-        m.put(key.getColumnFamily(), key.getColumnQualifier(), columnVisibility, new Value(sum.getReport().getBytes()));\n-        return m;\n+    context.write(empty, m);\n+  }\n+\n+  /**\n+   * Computes a simple summation metric value. The key is written out as is and the values, assumed to be string longs, are aggregated and written out.\n+   */\n+  private Mutation sumMutation(Key key, Iterable<Value> values) {\n+    LongValueSum sum = new LongValueSum();\n+    for (Value v : values) {\n+      sum.addNextValue(v);\n     }\n-    \n-    /**\n-     * Computes a \"stats\" metric value. Each incoming value in {@code values} is assumed to be a unique value. We calculate min, max, median, and average values\n-     * and include those in the output mutation. Note that median will only be calculated if there are not more than {@code MAX_MEDIAN_COUNT} values. This\n-     * restriction prevents us from using too much memory in the task tracker.\n-     */\n-    private Mutation statsMutation(Key key, Iterable<Value> values) {\n-        long numLongs = 0;\n-        long min = Long.MAX_VALUE;\n-        long max = Long.MIN_VALUE;\n-        longs.clear();\n-        LongValueSum sum = new LongValueSum();\n-        for (Value v : values) {\n-            ++numLongs;\n-            long aLong = Long.parseLong(v.toString());\n-            min = Math.min(aLong, min);\n-            max = Math.max(aLong, max);\n-            sum.addNextValue(aLong);\n-            \n-            if (numLongs <= MAX_MEDIAN_COUNT)\n-                longs.add(aLong);\n-        }\n-        numLongs = Math.max(1, numLongs);\n-        \n-        String average = String.format(\"%1.4f\", sum.getSum() / (double) numLongs);\n-        \n-        ColumnVisibility columnVisibility = new ColumnVisibility(key.getColumnVisibility());\n-        Text columnFamily = key.getColumnFamily();\n-        Mutation m = new Mutation(key.getRow());\n-        m.put(columnFamily, MIN_TEXT, columnVisibility, new Value(Long.toString(min).getBytes()));\n-        m.put(columnFamily, MAX_TEXT, columnVisibility, new Value(Long.toString(max).getBytes()));\n-        m.put(columnFamily, AVERAGE_TEXT, columnVisibility, new Value(average.getBytes()));\n-        if (numLongs <= MAX_MEDIAN_COUNT) {\n-            Collections.sort(longs);\n-            String median = \"\" + longs.get(longs.size() / 2);\n-            m.put(columnFamily, MEDIAN_TEXT, columnVisibility, new Value(median.getBytes()));\n-        }\n-        return m;\n+\n+    ColumnVisibility columnVisibility = new ColumnVisibility(key.getColumnVisibility());\n+    Mutation m = new Mutation(key.getRow());\n+    m.put(key.getColumnFamily(), key.getColumnQualifier(), columnVisibility, new Value(sum.getReport().getBytes()));\n+    return m;\n+  }\n+\n+  /**\n+   * Computes a \"stats\" metric value. Each incoming value in {@code values} is assumed to be a unique value. We calculate min, max, median, and average values\n+   * and include those in the output mutation. Note that median will only be calculated if there are not more than {@code MAX_MEDIAN_COUNT} values. This\n+   * restriction prevents us from using too much memory in the task tracker.\n+   */\n+  private Mutation statsMutation(Key key, Iterable<Value> values) {\n+    long numLongs = 0;\n+    long min = Long.MAX_VALUE;\n+    long max = Long.MIN_VALUE;\n+    longs.clear();\n+    LongValueSum sum = new LongValueSum();\n+    for (Value v : values) {\n+      ++numLongs;\n+      long aLong = Long.parseLong(v.toString());\n+      min = Math.min(aLong, min);\n+      max = Math.max(aLong, max);\n+      sum.addNextValue(aLong);\n+\n+      if (numLongs <= MAX_MEDIAN_COUNT) {\n+        longs.add(aLong);\n+      }\n     }\n-    \n-    /**\n-     * Computes a \"percentile stats\" metric value. Each incoming value in {@code values} is assumed to be a unique value. We calculate min, max, median, and\n-     * average values and include those in the output mutation. Note that median will only be calculated if there are not more than {@code MAX_MEDIAN_COUNT}\n-     * values. This restriction prevents us from using too much memory in the task tracker. In this variant, each value is assumed to be a serialized\n-     * {@link WeightedPair} object. If the median can be calculated, then the 95% percentile weighted value is also emitted as a statistic. The weights are\n-     * summed, and the value at the 95th percentile of the weights is returned. (e.g., for event latencies, each pair's value is the latency and the weight is\n-     * the number of events at that latency, so we return the latency (value) from the list that represents 95% of the events (weights).\n-     */\n-    private Mutation statsPercentileMutation(Key key, Iterable<Value> values) {\n-        long numPairs = 0;\n-        long min = Long.MAX_VALUE;\n-        long max = Long.MIN_VALUE;\n-        pairs.clear();\n-        LongValueSum valueSum = new LongValueSum();\n-        LongValueSum weightSum = new LongValueSum();\n-        for (Value v : values) {\n-            ++numPairs;\n-            WeightedPair pair = WeightedPair.parseValue(v);\n-            min = Math.min(pair.getValue(), min);\n-            max = Math.max(pair.getValue(), max);\n-            valueSum.addNextValue(pair.getValue());\n-            weightSum.addNextValue(pair.getWeight());\n-            \n-            if (numPairs <= MAX_MEDIAN_COUNT)\n-                pairs.add(pair);\n-        }\n-        numPairs = Math.max(1, numPairs);\n-        \n-        String average = String.format(\"%1.4f\", valueSum.getSum() / (double) numPairs);\n-        \n-        ColumnVisibility columnVisibility = new ColumnVisibility(key.getColumnVisibility());\n-        Text columnFamily = key.getColumnFamily();\n-        Mutation m = new Mutation(key.getRow());\n-        m.put(columnFamily, MIN_TEXT, columnVisibility, new Value(Long.toString(min).getBytes()));\n-        m.put(columnFamily, MAX_TEXT, columnVisibility, new Value(Long.toString(max).getBytes()));\n-        m.put(columnFamily, AVERAGE_TEXT, columnVisibility, new Value(average.getBytes()));\n-        if (numPairs <= MAX_MEDIAN_COUNT) {\n-            Collections.sort(pairs);\n-            String median = \"\" + pairs.get(pairs.size() / 2).getValue();\n-            m.put(columnFamily, MEDIAN_TEXT, columnVisibility, new Value(median.getBytes()));\n-            \n-            // Figure out the position in the list where the sum of the weights up to that point is\n-            // at the 95% percentile. We'll then take the value at that position. Go through the\n-            // list backwards in hope that the weights are mostly even and therefore the 95% weight\n-            // will be somewhere around 95% of the way through the list.\n-            long percentileWeight = (long) Math.ceil(weightSum.getSum() * 0.95);\n-            long positionWeight = weightSum.getSum();\n-            for (int i = pairs.size() - 1; i >= 0; --i) {\n-                WeightedPair pair = pairs.get(i);\n-                positionWeight -= pair.getWeight();\n-                if (positionWeight < percentileWeight) { // this pair's weight contribution took us to or over the 95th percentile weight...\n-                    String percentile = \"\" + pair.getValue();\n-                    m.put(columnFamily, PERCENTILE_TEXT, columnVisibility, new Value(percentile.getBytes()));\n-                    break;\n-                }\n-            }\n-        }\n-        return m;\n+    numLongs = Math.max(1, numLongs);\n+\n+    String average = String.format(\"%1.4f\", sum.getSum() / (double) numLongs);\n+\n+    ColumnVisibility columnVisibility = new ColumnVisibility(key.getColumnVisibility());\n+    Text columnFamily = key.getColumnFamily();\n+    Mutation m = new Mutation(key.getRow());\n+    m.put(columnFamily, MIN_TEXT, columnVisibility, new Value(Long.toString(min).getBytes()));\n+    m.put(columnFamily, MAX_TEXT, columnVisibility, new Value(Long.toString(max).getBytes()));\n+    m.put(columnFamily, AVERAGE_TEXT, columnVisibility, new Value(average.getBytes()));\n+    if (numLongs <= MAX_MEDIAN_COUNT) {\n+      Collections.sort(longs);\n+      String median = \"\" + longs.get(longs.size() / 2);\n+      m.put(columnFamily, MEDIAN_TEXT, columnVisibility, new Value(median.getBytes()));\n     }\n-    \n-    public static void configureJob(Job job, int numDays, String instance, String zookeepers, String userName, String password, String outputTable) {\n-        job.setNumReduceTasks(Math.min(numDays, 100)); // Cap the number of reducers at 100, just in case we have a large day range (shouldn't really happen\n-                                                       // though)\n-        job.setReducerClass(MetricsDailySummaryReducer.class);\n-        job.setOutputFormatClass(AccumuloOutputFormat.class);\n-        // @formatter:off\n-        AccumuloOutputFormat.configure()\n-                .clientProperties(Accumulo.newClientProperties().to(instance,zookeepers).as(userName, password).build())\n-                .createTables(true)\n-                .defaultTable(outputTable)\n-                .store(job);\n-        // @formatter:on\n+    return m;\n+  }\n+\n+  /**\n+   * Computes a \"percentile stats\" metric value. Each incoming value in {@code values} is assumed to be a unique value. We calculate min, max, median, and\n+   * average values and include those in the output mutation. Note that median will only be calculated if there are not more than {@code MAX_MEDIAN_COUNT}\n+   * values. This restriction prevents us from using too much memory in the task tracker. In this variant, each value is assumed to be a serialized\n+   * {@link WeightedPair} object. If the median can be calculated, then the 95% percentile weighted value is also emitted as a statistic. The weights are\n+   * summed, and the value at the 95th percentile of the weights is returned. (e.g., for event latencies, each pair's value is the latency and the weight is\n+   * the number of events at that latency, so we return the latency (value) from the list that represents 95% of the events (weights).\n+   */\n+  private Mutation statsPercentileMutation(Key key, Iterable<Value> values) {\n+    long numPairs = 0;\n+    long min = Long.MAX_VALUE;\n+    long max = Long.MIN_VALUE;\n+    pairs.clear();\n+    LongValueSum valueSum = new LongValueSum();\n+    LongValueSum weightSum = new LongValueSum();\n+    for (Value v : values) {\n+      ++numPairs;\n+      WeightedPair pair = WeightedPair.parseValue(v);\n+      min = Math.min(pair.getValue(), min);\n+      max = Math.max(pair.getValue(), max);\n+      valueSum.addNextValue(pair.getValue());\n+      weightSum.addNextValue(pair.getWeight());\n+\n+      if (numPairs <= MAX_MEDIAN_COUNT) {\n+        pairs.add(pair);\n+      }\n     }\n-    \n-    public static class WeightedPair implements Writable, Comparable<WeightedPair> {\n-        private long value;\n-        private long weight;\n-        \n-        public WeightedPair() {}\n-        \n-        public WeightedPair(long value, long weight) {\n-            this.value = value;\n-            this.weight = weight;\n-        }\n-        \n-        public long getValue() {\n-            return value;\n-        }\n-        \n-        public long getWeight() {\n-            return weight;\n-        }\n-        \n-        public Value toValue() {\n-            ByteArrayDataOutput out = ByteStreams.newDataOutput();\n-            try {\n-                write(out);\n-            } catch (IOException e) {\n-                // can't happen - it's a byte array stream\n-            }\n-            return new Value(out.toByteArray());\n-        }\n-        \n-        @Override\n-        public int compareTo(WeightedPair o) {\n-            return Longs.compare(value, o.value);\n-        }\n-        \n-        @Override\n-        public void write(DataOutput out) throws IOException {\n-            out.writeLong(value);\n-            out.writeLong(weight);\n-        }\n-        \n-        @Override\n-        public void readFields(DataInput in) throws IOException {\n-            value = in.readLong();\n-            weight = in.readLong();\n-        }\n-        \n-        public static WeightedPair parseValue(Value value) {\n-            WeightedPair p = new WeightedPair();\n-            try {\n-                p.readFields(ByteStreams.newDataInput(value.get()));\n-            } catch (IOException e) {\n-                // can't happen - it's a byte array stream\n-            }\n-            return p;\n+    numPairs = Math.max(1, numPairs);\n+\n+    String average = String.format(\"%1.4f\", valueSum.getSum() / (double) numPairs);\n+\n+    ColumnVisibility columnVisibility = new ColumnVisibility(key.getColumnVisibility());\n+    Text columnFamily = key.getColumnFamily();\n+    Mutation m = new Mutation(key.getRow());\n+    m.put(columnFamily, MIN_TEXT, columnVisibility, new Value(Long.toString(min).getBytes()));\n+    m.put(columnFamily, MAX_TEXT, columnVisibility, new Value(Long.toString(max).getBytes()));\n+    m.put(columnFamily, AVERAGE_TEXT, columnVisibility, new Value(average.getBytes()));\n+    if (numPairs <= MAX_MEDIAN_COUNT) {\n+      Collections.sort(pairs);\n+      String median = \"\" + pairs.get(pairs.size() / 2).getValue();\n+      m.put(columnFamily, MEDIAN_TEXT, columnVisibility, new Value(median.getBytes()));\n+\n+      // Figure out the position in the list where the sum of the weights up to that point is\n+      // at the 95% percentile. We'll then take the value at that position. Go through the\n+      // list backwards in hope that the weights are mostly even and therefore the 95% weight\n+      // will be somewhere around 95% of the way through the list.\n+      long percentileWeight = (long) Math.ceil(weightSum.getSum() * 0.95);\n+      long positionWeight = weightSum.getSum();\n+      for (int i = pairs.size() - 1; i >= 0; --i) {\n+        WeightedPair pair = pairs.get(i);\n+        positionWeight -= pair.getWeight();\n+        if (positionWeight <\n+            percentileWeight) { // this pair's weight contribution took us to or over the 95th percentile weight...\n+          String percentile = \"\" + pair.getValue();\n+          m.put(columnFamily, PERCENTILE_TEXT, columnVisibility, new Value(percentile.getBytes()));\n+          break;\n         }\n+      }\n+    }\n+    return m;\n+  }\n+\n+  public static void configureJob(Job job, int numDays, String instance, String zookeepers, String userName,\n+                                  String password, String outputTable) {\n+    job.setNumReduceTasks(Math.min(numDays,\n+        100)); // Cap the number of reducers at 100, just in case we have a large day range (shouldn't really happen\n+    // though)\n+    job.setReducerClass(MetricsDailySummaryReducer.class);\n+    job.setOutputFormatClass(AccumuloOutputFormat.class);\n+    // @formatter:off\n+    AccumuloOutputFormat.configure()\n+        .clientProperties(Accumulo.newClientProperties().to(instance, zookeepers).as(userName, password).build())\n+        .createTables(true)\n+        .defaultTable(outputTable)\n+        .store(job);\n+    // @formatter:on\n+  }\n+\n+  public static class WeightedPair implements Writable, Comparable<WeightedPair> {\n+    private long value;\n+    private long weight;\n+\n+    public WeightedPair() {\n+    }\n+\n+    public WeightedPair(long value, long weight) {\n+      this.value = value;\n+      this.weight = weight;\n+    }\n+\n+    public long getValue() {\n+      return value;\n+    }\n+\n+    public long getWeight() {\n+      return weight;\n+    }\n+\n+    public Value toValue() {\n+      ByteArrayDataOutput out = ByteStreams.newDataOutput();\n+      try {\n+        write(out);\n+      } catch (IOException e) {\n+        // can't happen - it's a byte array stream\n+      }\n+      return new Value(out.toByteArray());\n+    }\n+\n+    @Override\n+    public int compareTo(WeightedPair o) {\n+      return Longs.compare(value, o.value);\n+    }\n+\n+    @Override\n+    public void write(DataOutput out) throws IOException {\n+      out.writeLong(value);\n+      out.writeLong(weight);\n+    }\n+\n+    @Override\n+    public void readFields(DataInput in) throws IOException {\n+      value = in.readLong();\n+      weight = in.readLong();\n+    }\n+\n+    public static WeightedPair parseValue(Value value) {\n+      WeightedPair p = new WeightedPair();\n+      try {\n+        p.readFields(ByteStreams.newDataInput(value.get()));\n+      } catch (IOException e) {\n+        // can't happen - it's a byte array stream\n+      }\n+      return p;\n     }\n+  }\n }\n",
            "diff_size": 299
        },
        {
            "tool": "naturalize",
            "errors": [
                {
                    "line": "11",
                    "severity": "error",
                    "message": "Accumulo non-public classes imported",
                    "source": "com.puppycrawl.tools.checkstyle.checks.regexp.RegexpSinglelineJavaCheck"
                }
            ],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/NationalSecurityAgency-datawave/errored/1/85/MetricsDailySummaryReducer.java b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/NationalSecurityAgency-datawave/naturalize/85/MetricsDailySummaryReducer.java\nindex 450da89169c..78fe998d8ce 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/NationalSecurityAgency-datawave/errored/1/85/MetricsDailySummaryReducer.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/NationalSecurityAgency-datawave/naturalize/85/MetricsDailySummaryReducer.java\n@@ -238,4 +238,4 @@ public class MetricsDailySummaryReducer extends Reducer<Key,Value,Text,Mutation>\n             return p;\n         }\n     }\n-}\n+}\n\\ No newline at end of file\n",
            "diff_size": 1
        },
        {
            "tool": "codebuff",
            "errors": null,
            "diff": null
        },
        {
            "tool": "styler_random",
            "errors": [
                {
                    "line": "11",
                    "severity": "error",
                    "message": "Accumulo non-public classes imported",
                    "source": "com.puppycrawl.tools.checkstyle.checks.regexp.RegexpSinglelineJavaCheck"
                }
            ],
            "diff": "",
            "diff_size": 0
        },
        {
            "tool": "styler_three_grams",
            "errors": [
                {
                    "line": "11",
                    "severity": "error",
                    "message": "Accumulo non-public classes imported",
                    "source": "com.puppycrawl.tools.checkstyle.checks.regexp.RegexpSinglelineJavaCheck"
                }
            ],
            "diff": "",
            "diff_size": 0
        }
    ],
    "repaired_by": [],
    "not_repaired_by": [
        "styler",
        "intellij",
        "naturalize",
        "codebuff",
        "styler_random",
        "styler_three_grams"
    ]
}