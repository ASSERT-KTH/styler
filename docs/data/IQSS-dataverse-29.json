{
    "project_name": "IQSS-dataverse",
    "error_id": "29",
    "information": {
        "errors": [
            {
                "line": "161",
                "column": "13",
                "severity": "error",
                "message": "File contains tab characters (this is the first instance).",
                "source": "com.puppycrawl.tools.checkstyle.checks.whitespace.FileTabCharacterCheck"
            }
        ]
    },
    "source_code": "\n            Registry<ConnectionSocketFactory> registry = RegistryBuilder.<ConnectionSocketFactory>create()\n            \t\t.register(\"http\", PlainConnectionSocketFactory.getSocketFactory())\n                    .register(\"https\", sslConnectionFactory).build();\n            cm = new PoolingHttpClientConnectionManager(registry);\n",
    "results": [
        {
            "tool": "styler",
            "errors": [],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/IQSS-dataverse/errored/1/29/BagGenerator.java b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/IQSS-dataverse/styler/29/BagGenerator.java\nindex 7c3db485e47..24eaec574d7 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/IQSS-dataverse/errored/1/29/BagGenerator.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/IQSS-dataverse/styler/29/BagGenerator.java\n@@ -158,7 +158,7 @@ public class BagGenerator {\n             SSLConnectionSocketFactory sslConnectionFactory = new SSLConnectionSocketFactory(builder.build(), NoopHostnameVerifier.INSTANCE);\r\n \r\n             Registry<ConnectionSocketFactory> registry = RegistryBuilder.<ConnectionSocketFactory>create()\r\n-            \t\t.register(\"http\", PlainConnectionSocketFactory.getSocketFactory())\r\n+    .register(\"http\", PlainConnectionSocketFactory.getSocketFactory())\r\n                     .register(\"https\", sslConnectionFactory).build();\r\n             cm = new PoolingHttpClientConnectionManager(registry);\r\n \r\n",
            "diff_size": 1
        },
        {
            "tool": "intellij",
            "errors": [],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/IQSS-dataverse/errored/1/29/BagGenerator.java b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/IQSS-dataverse/intellij/29/BagGenerator.java\nindex 7c3db485e47..6dbb7e78058 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/IQSS-dataverse/errored/1/29/BagGenerator.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/IQSS-dataverse/intellij/29/BagGenerator.java\n@@ -79,990 +79,994 @@ import edu.harvard.iq.dataverse.util.json.JsonLDTerm;\n \r\n public class BagGenerator {\r\n \r\n-    private static final Logger logger = Logger.getLogger(BagGenerator.class.getCanonicalName());\r\n-\r\n-    private ParallelScatterZipCreator scatterZipCreator = null;\r\n-    private ScatterZipOutputStream dirs = null;\r\n-\r\n-    private JsonArray aggregates = null;\r\n-    private ArrayList<String> resourceIndex = null;\r\n-    private Boolean[] resourceUsed = null;\r\n-    private HashMap<String, String> pidMap = new LinkedHashMap<String, String>();\r\n-    private HashMap<String, String> checksumMap = new LinkedHashMap<String, String>();\r\n-\r\n-    private int timeout = 60;\r\n-    private RequestConfig config = RequestConfig.custom().setConnectTimeout(timeout * 1000)\r\n-            .setConnectionRequestTimeout(timeout * 1000).setSocketTimeout(timeout * 1000).build();\r\n-    protected CloseableHttpClient client;\r\n-    private PoolingHttpClientConnectionManager cm = null;\r\n-\r\n-    private ChecksumType hashtype = null;\r\n-    private boolean ignorehashes = false;\r\n-\r\n-    private long dataCount = 0l;\r\n-    private long totalDataSize = 0l;\r\n-    private long maxFileSize = 0l;\r\n-    private Set<String> mimetypes = new TreeSet<String>();\r\n-\r\n-    private String bagID = null;\r\n-    private String bagPath = \"/tmp\";\r\n-    String bagName = null;\r\n-\r\n-    private String apiKey = null;\r\n-\r\n-    private javax.json.JsonObject oremapObject;\r\n-    private JsonObject aggregation;\r\n-\r\n-    private String dataciteXml;\r\n-\r\n-    private boolean usetemp = false;\r\n-\r\n-    private int numConnections = 8;\r\n-\r\n-    private OREMap oremap;\r\n-\r\n-    static PrintWriter pw = null;\r\n-\r\n-    /**\r\n-     * This BagGenerator creates a BagIt version 1.0\r\n-     * (https://tools.ietf.org/html/draft-kunze-bagit-16) compliant bag that is also\r\n-     * minimally compatible with the Research Data Repository Interoperability WG\r\n-     * Final Recommendations (DOI: 10.15497/RDA00025). It works by parsing the\r\n-     * submitted OAI-ORE Map file, using the metadata therein to create required\r\n-     * BagIt metadata, and using the schema.org/sameAs entries for\r\n-     * AggregatedResources as a way to retrieve these files and store them in the\r\n-     * /data directory within the BagIt structure. The Bag is zipped. File retrieval\r\n-     * and zipping are done in parallel, using a connection pool. The required space\r\n-     * on disk is ~ n+1/n of the final bag size, e.g. 125% of the bag size for a\r\n-     * 4-way parallel zip operation.\r\n-     * @throws Exception \r\n-     * @throws JsonSyntaxException \r\n-     */\r\n-\r\n-    public BagGenerator(OREMap oreMap, String dataciteXml) throws JsonSyntaxException, Exception {\r\n-        this.oremap = oreMap;\r\n-        this.oremapObject = oreMap.getOREMap();\r\n-                //(JsonObject) new JsonParser().parse(oreMap.getOREMap().toString());\r\n-        this.dataciteXml = dataciteXml;\r\n-\r\n-        try {\r\n-            // Using Dataverse, all the URLs to be retrieved should be on the current server, so allowing self-signed certs and not verifying hostnames are useful in testing and \r\n-            // shouldn't be a significant security issue. This should not be allowed for arbitrary OREMap sources.\r\n-            SSLContextBuilder builder = new SSLContextBuilder();\r\n-            try {\r\n-                builder.loadTrustMaterial(null, new TrustSelfSignedStrategy());\r\n-            } catch (KeyStoreException e) {\r\n-                e.printStackTrace();\r\n-            }\r\n-\r\n-            SSLConnectionSocketFactory sslConnectionFactory = new SSLConnectionSocketFactory(builder.build(), NoopHostnameVerifier.INSTANCE);\r\n-\r\n-            Registry<ConnectionSocketFactory> registry = RegistryBuilder.<ConnectionSocketFactory>create()\r\n-            \t\t.register(\"http\", PlainConnectionSocketFactory.getSocketFactory())\r\n-                    .register(\"https\", sslConnectionFactory).build();\r\n-            cm = new PoolingHttpClientConnectionManager(registry);\r\n-\r\n-            cm.setDefaultMaxPerRoute(numConnections);\r\n-            cm.setMaxTotal(numConnections > 20 ? numConnections : 20);\r\n+  private static final Logger logger = Logger.getLogger(BagGenerator.class.getCanonicalName());\r\n+\r\n+  private ParallelScatterZipCreator scatterZipCreator = null;\r\n+  private ScatterZipOutputStream dirs = null;\r\n+\r\n+  private JsonArray aggregates = null;\r\n+  private ArrayList<String> resourceIndex = null;\r\n+  private Boolean[] resourceUsed = null;\r\n+  private HashMap<String, String> pidMap = new LinkedHashMap<String, String>();\r\n+  private HashMap<String, String> checksumMap = new LinkedHashMap<String, String>();\r\n+\r\n+  private int timeout = 60;\r\n+  private RequestConfig config = RequestConfig.custom().setConnectTimeout(timeout * 1000)\r\n+    .setConnectionRequestTimeout(timeout * 1000).setSocketTimeout(timeout * 1000).build();\r\n+  protected CloseableHttpClient client;\r\n+  private PoolingHttpClientConnectionManager cm = null;\r\n+\r\n+  private ChecksumType hashtype = null;\r\n+  private boolean ignorehashes = false;\r\n+\r\n+  private long dataCount = 0l;\r\n+  private long totalDataSize = 0l;\r\n+  private long maxFileSize = 0l;\r\n+  private Set<String> mimetypes = new TreeSet<String>();\r\n+\r\n+  private String bagID = null;\r\n+  private String bagPath = \"/tmp\";\r\n+  String bagName = null;\r\n+\r\n+  private String apiKey = null;\r\n+\r\n+  private javax.json.JsonObject oremapObject;\r\n+  private JsonObject aggregation;\r\n+\r\n+  private String dataciteXml;\r\n+\r\n+  private boolean usetemp = false;\r\n+\r\n+  private int numConnections = 8;\r\n+\r\n+  private OREMap oremap;\r\n+\r\n+  static PrintWriter pw = null;\r\n+\r\n+  /**\r\n+   * This BagGenerator creates a BagIt version 1.0\r\n+   * (https://tools.ietf.org/html/draft-kunze-bagit-16) compliant bag that is also\r\n+   * minimally compatible with the Research Data Repository Interoperability WG\r\n+   * Final Recommendations (DOI: 10.15497/RDA00025). It works by parsing the\r\n+   * submitted OAI-ORE Map file, using the metadata therein to create required\r\n+   * BagIt metadata, and using the schema.org/sameAs entries for\r\n+   * AggregatedResources as a way to retrieve these files and store them in the\r\n+   * /data directory within the BagIt structure. The Bag is zipped. File retrieval\r\n+   * and zipping are done in parallel, using a connection pool. The required space\r\n+   * on disk is ~ n+1/n of the final bag size, e.g. 125% of the bag size for a\r\n+   * 4-way parallel zip operation.\r\n+   *\r\n+   * @throws Exception\r\n+   * @throws JsonSyntaxException\r\n+   */\r\n+\r\n+  public BagGenerator(OREMap oreMap, String dataciteXml) throws JsonSyntaxException, Exception {\r\n+    this.oremap = oreMap;\r\n+    this.oremapObject = oreMap.getOREMap();\r\n+    //(JsonObject) new JsonParser().parse(oreMap.getOREMap().toString());\r\n+    this.dataciteXml = dataciteXml;\r\n+\r\n+    try {\r\n+      // Using Dataverse, all the URLs to be retrieved should be on the current server, so allowing self-signed certs and not verifying hostnames are useful in testing and\r\n+      // shouldn't be a significant security issue. This should not be allowed for arbitrary OREMap sources.\r\n+      SSLContextBuilder builder = new SSLContextBuilder();\r\n+      try {\r\n+        builder.loadTrustMaterial(null, new TrustSelfSignedStrategy());\r\n+      } catch (KeyStoreException e) {\r\n+        e.printStackTrace();\r\n+      }\r\n+\r\n+      SSLConnectionSocketFactory sslConnectionFactory =\r\n+        new SSLConnectionSocketFactory(builder.build(), NoopHostnameVerifier.INSTANCE);\r\n+\r\n+      Registry<ConnectionSocketFactory> registry = RegistryBuilder.<ConnectionSocketFactory>create()\r\n+        .register(\"http\", PlainConnectionSocketFactory.getSocketFactory())\r\n+        .register(\"https\", sslConnectionFactory).build();\r\n+      cm = new PoolingHttpClientConnectionManager(registry);\r\n+\r\n+      cm.setDefaultMaxPerRoute(numConnections);\r\n+      cm.setMaxTotal(numConnections > 20 ? numConnections : 20);\r\n+\r\n+      client = HttpClients.custom().setConnectionManager(cm).setDefaultRequestConfig(config).build();\r\n+\r\n+      scatterZipCreator = new ParallelScatterZipCreator(Executors.newFixedThreadPool(numConnections));\r\n+    } catch (NoSuchAlgorithmException | KeyManagementException e) {\r\n+      logger.warning(\"Aint gonna work\");\r\n+      e.printStackTrace();\r\n+    }\r\n+  }\r\n+\r\n+  public void setIgnoreHashes(boolean val) {\r\n+    ignorehashes = val;\r\n+  }\r\n+\r\n+  public static void println(String s) {\r\n+    System.out.println(s);\r\n+    System.out.flush();\r\n+    if (pw != null) {\r\n+      pw.println(s);\r\n+      pw.flush();\r\n+    }\r\n+    return;\r\n+  }\r\n+\r\n+  /*\r\n+   * Full workflow to generate new BagIt bag from ORE Map Url and to write the bag\r\n+   * to the provided output stream (Ex: File OS, FTP OS etc.).\r\n+   *\r\n+   * @return success true/false\r\n+   */\r\n+  public boolean generateBag(OutputStream outputStream) throws Exception {\r\n+    logger.info(\"Generating: Bag to the Future!\");\r\n+\r\n+    File tmp = File.createTempFile(\"qdr-scatter-dirs\", \"tmp\");\r\n+    dirs = ScatterZipOutputStream.fileBased(tmp);\r\n+    // The oremapObject is javax.json.JsonObject and we need com.google.gson.JsonObject for the aggregation object\r\n+    aggregation = (JsonObject) new JsonParser()\r\n+      .parse(oremapObject.getJsonObject(JsonLDTerm.ore(\"describes\").getLabel()).toString());\r\n+\r\n+    bagID = aggregation.get(\"@id\").getAsString() + \"v.\"\r\n+      + aggregation.get(JsonLDTerm.schemaOrg(\"version\").getLabel()).getAsString();\r\n+    try {\r\n+      // Create valid filename from identifier and extend path with\r\n+      // two levels of hash-based subdirs to help distribute files\r\n+      bagName = getValidName(bagID);\r\n+    } catch (Exception e) {\r\n+      logger.severe(\"Couldn't create valid filename: \" + e.getLocalizedMessage());\r\n+      return false;\r\n+    }\r\n+    // Create data dir in bag, also creates parent bagName dir\r\n+    String currentPath = \"data/\";\r\n+    createDir(currentPath);\r\n+\r\n+    aggregates = aggregation.getAsJsonArray(JsonLDTerm.ore(\"aggregates\").getLabel());\r\n+\r\n+    if (aggregates != null) {\r\n+      // Add container and data entries\r\n+      // Setup global index of the aggregation and all aggregated\r\n+      // resources by Identifier\r\n+      resourceIndex = indexResources(aggregation.get(\"@id\").getAsString(), aggregates);\r\n+      // Setup global list of succeed(true), fail(false), notused\r\n+      // (null) flags\r\n+      resourceUsed = new Boolean[aggregates.size() + 1];\r\n+      // Process current container (the aggregation itself) and its\r\n+      // children\r\n+      processContainer(aggregation, currentPath);\r\n+    }\r\n+    // Create manifest files\r\n+    // pid-mapping.txt - a DataOne recommendation to connect ids and\r\n+    // in-bag path/names\r\n+    StringBuffer pidStringBuffer = new StringBuffer();\r\n+    boolean first = true;\r\n+    for (Entry<String, String> pidEntry : pidMap.entrySet()) {\r\n+      if (!first) {\r\n+        pidStringBuffer.append(\"\\r\\n\");\r\n+      } else {\r\n+        first = false;\r\n+      }\r\n+      String path = pidEntry.getValue();\r\n+      pidStringBuffer.append(pidEntry.getKey() + \" \" + path);\r\n+    }\r\n+    createDir(\"metadata/\");\r\n+    createFileFromString(\"metadata/pid-mapping.txt\", pidStringBuffer.toString());\r\n+    // Hash manifest - a hash manifest is required\r\n+    // by Bagit spec\r\n+    StringBuffer sha1StringBuffer = new StringBuffer();\r\n+    first = true;\r\n+    for (Entry<String, String> sha1Entry : checksumMap.entrySet()) {\r\n+      if (!first) {\r\n+        sha1StringBuffer.append(\"\\r\\n\");\r\n+      } else {\r\n+        first = false;\r\n+      }\r\n+      String path = sha1Entry.getKey();\r\n+      sha1StringBuffer.append(sha1Entry.getValue() + \" \" + path);\r\n+    }\r\n+    if (!(hashtype == null)) {\r\n+      String manifestName = \"manifest-\";\r\n+      if (hashtype.equals(DataFile.ChecksumType.SHA1)) {\r\n+        manifestName = manifestName + \"sha1.txt\";\r\n+      } else if (hashtype.equals(DataFile.ChecksumType.SHA256)) {\r\n+        manifestName = manifestName + \"sha256.txt\";\r\n+      } else if (hashtype.equals(DataFile.ChecksumType.SHA512)) {\r\n+        manifestName = manifestName + \"sha512.txt\";\r\n+      } else if (hashtype.equals(DataFile.ChecksumType.MD5)) {\r\n+        manifestName = manifestName + \"md5.txt\";\r\n+      } else {\r\n+        logger.warning(\"Unsupported Hash type: \" + hashtype);\r\n+      }\r\n+      createFileFromString(manifestName, sha1StringBuffer.toString());\r\n+    } else {\r\n+      logger.warning(\"No Hash values sent - Bag File does not meet BagIT specification requirement\");\r\n+    }\r\n+    // bagit.txt - Required by spec\r\n+    createFileFromString(\"bagit.txt\", \"BagIt-Version: 1.0\\r\\nTag-File-Character-Encoding: UTF-8\");\r\n+\r\n+    aggregation.addProperty(JsonLDTerm.totalSize.getLabel(), totalDataSize);\r\n+    aggregation.addProperty(JsonLDTerm.fileCount.getLabel(), dataCount);\r\n+    JsonArray mTypes = new JsonArray();\r\n+    for (String mt : mimetypes) {\r\n+      mTypes.add(new JsonPrimitive(mt));\r\n+    }\r\n+    aggregation.add(JsonLDTerm.dcTerms(\"format\").getLabel(), mTypes);\r\n+    aggregation.addProperty(JsonLDTerm.maxFileSize.getLabel(), maxFileSize);\r\n+    // Serialize oremap itself\r\n+    // FixMe - add missing hash values if needed and update context\r\n+    // (read and cache files or read twice?)\r\n+    createFileFromString(\"metadata/oai-ore.jsonld\", oremapObject.toString());\r\n \r\n-            client = HttpClients.custom().setConnectionManager(cm).setDefaultRequestConfig(config).build();\r\n+    createFileFromString(\"metadata/datacite.xml\", dataciteXml);\r\n \r\n-            scatterZipCreator = new ParallelScatterZipCreator(Executors.newFixedThreadPool(numConnections));\r\n-        } catch (NoSuchAlgorithmException | KeyManagementException e) {\r\n-            logger.warning(\"Aint gonna work\");\r\n-            e.printStackTrace();\r\n-        }\r\n-    }\r\n+    // Add a bag-info file\r\n+    createFileFromString(\"bag-info.txt\", generateInfoFile());\r\n \r\n-    public void setIgnoreHashes(boolean val) {\r\n-        ignorehashes = val;\r\n-    }\r\n+    logger.fine(\"Creating bag: \" + bagName);\r\n \r\n-    public static void println(String s) {\r\n-        System.out.println(s);\r\n-        System.out.flush();\r\n-        if (pw != null) {\r\n-            pw.println(s);\r\n-            pw.flush();\r\n-        }\r\n-        return;\r\n-    }\r\n+    ZipArchiveOutputStream zipArchiveOutputStream = new ZipArchiveOutputStream(outputStream);\r\n \r\n     /*\r\n-     * Full workflow to generate new BagIt bag from ORE Map Url and to write the bag\r\n-     * to the provided output stream (Ex: File OS, FTP OS etc.).\r\n-     * \r\n-     * @return success true/false\r\n+     * Add all the waiting contents - dirs created first, then data files are\r\n+     * retrieved via URLs in parallel (defaults to one thread per processor)\r\n+     * directly to the zip file\r\n      */\r\n-    public boolean generateBag(OutputStream outputStream) throws Exception {\r\n-        logger.info(\"Generating: Bag to the Future!\");\r\n-\r\n-        File tmp = File.createTempFile(\"qdr-scatter-dirs\", \"tmp\");\r\n-        dirs = ScatterZipOutputStream.fileBased(tmp);\r\n-        // The oremapObject is javax.json.JsonObject and we need com.google.gson.JsonObject for the aggregation object\r\n-        aggregation = (JsonObject) new JsonParser().parse(oremapObject.getJsonObject(JsonLDTerm.ore(\"describes\").getLabel()).toString());\r\n-\r\n-        bagID = aggregation.get(\"@id\").getAsString() + \"v.\"\r\n-                + aggregation.get(JsonLDTerm.schemaOrg(\"version\").getLabel()).getAsString();\r\n-        try {\r\n-            // Create valid filename from identifier and extend path with\r\n-            // two levels of hash-based subdirs to help distribute files\r\n-            bagName = getValidName(bagID);\r\n-        } catch (Exception e) {\r\n-            logger.severe(\"Couldn't create valid filename: \" + e.getLocalizedMessage());\r\n-            return false;\r\n-        }\r\n-        // Create data dir in bag, also creates parent bagName dir\r\n-        String currentPath = \"data/\";\r\n-        createDir(currentPath);\r\n-\r\n-        aggregates = aggregation.getAsJsonArray(JsonLDTerm.ore(\"aggregates\").getLabel());\r\n-\r\n-        if (aggregates != null) {\r\n-            // Add container and data entries\r\n-            // Setup global index of the aggregation and all aggregated\r\n-            // resources by Identifier\r\n-            resourceIndex = indexResources(aggregation.get(\"@id\").getAsString(), aggregates);\r\n-            // Setup global list of succeed(true), fail(false), notused\r\n-            // (null) flags\r\n-            resourceUsed = new Boolean[aggregates.size() + 1];\r\n-            // Process current container (the aggregation itself) and its\r\n-            // children\r\n-            processContainer(aggregation, currentPath);\r\n-        }\r\n-        // Create manifest files\r\n-        // pid-mapping.txt - a DataOne recommendation to connect ids and\r\n-        // in-bag path/names\r\n-        StringBuffer pidStringBuffer = new StringBuffer();\r\n-        boolean first = true;\r\n-        for (Entry<String, String> pidEntry : pidMap.entrySet()) {\r\n-            if (!first) {\r\n-                pidStringBuffer.append(\"\\r\\n\");\r\n-            } else {\r\n-                first = false;\r\n+    logger.fine(\"Starting write\");\r\n+    writeTo(zipArchiveOutputStream);\r\n+    logger.fine(\"Zipfile Written\");\r\n+    // Finish\r\n+    zipArchiveOutputStream.close();\r\n+    logger.fine(\"Closed\");\r\n+\r\n+    // Validate oremap - all entries are part of the collection\r\n+    for (int i = 0; i < resourceUsed.length; i++) {\r\n+      Boolean b = resourceUsed[i];\r\n+      if (b == null) {\r\n+        logger.warning(\"Problem: \" + pidMap.get(resourceIndex.get(i)) + \" was not used\");\r\n+      } else if (!b) {\r\n+        logger.warning(\"Problem: \" + pidMap.get(resourceIndex.get(i)) + \" was not included successfully\");\r\n+      } else {\r\n+        // Successfully included - now check for hash value and\r\n+        // generate if needed\r\n+        if (i > 0) { // Not root container\r\n+          if (!checksumMap.containsKey(pidMap.get(resourceIndex.get(i)))) {\r\n+\r\n+            if (!childIsContainer(aggregates.get(i - 1).getAsJsonObject())) {\r\n+              logger.warning(\"Missing checksum hash for: \" + resourceIndex.get(i));\r\n             }\r\n-            String path = pidEntry.getValue();\r\n-            pidStringBuffer.append(pidEntry.getKey() + \" \" + path);\r\n+            // FixMe - actually generate it before adding the\r\n+            // oremap\r\n+            // to the zip\r\n+          }\r\n         }\r\n-        createDir(\"metadata/\");\r\n-        createFileFromString(\"metadata/pid-mapping.txt\", pidStringBuffer.toString());\r\n-        // Hash manifest - a hash manifest is required\r\n-        // by Bagit spec\r\n-        StringBuffer sha1StringBuffer = new StringBuffer();\r\n-        first = true;\r\n-        for (Entry<String, String> sha1Entry : checksumMap.entrySet()) {\r\n-            if (!first) {\r\n-                sha1StringBuffer.append(\"\\r\\n\");\r\n-            } else {\r\n-                first = false;\r\n-            }\r\n-            String path = sha1Entry.getKey();\r\n-            sha1StringBuffer.append(sha1Entry.getValue() + \" \" + path);\r\n-        }\r\n-        if (!(hashtype == null)) {\r\n-            String manifestName = \"manifest-\";\r\n-            if (hashtype.equals(DataFile.ChecksumType.SHA1)) {\r\n-                manifestName = manifestName + \"sha1.txt\";\r\n-            } else if (hashtype.equals(DataFile.ChecksumType.SHA256)) {\r\n-                manifestName = manifestName + \"sha256.txt\";\r\n-            } else if (hashtype.equals(DataFile.ChecksumType.SHA512)) {\r\n-                manifestName = manifestName + \"sha512.txt\";\r\n-            } else if (hashtype.equals(DataFile.ChecksumType.MD5)) {\r\n-                manifestName = manifestName + \"md5.txt\";\r\n-            } else {\r\n-                logger.warning(\"Unsupported Hash type: \" + hashtype);\r\n-            }\r\n-            createFileFromString(manifestName, sha1StringBuffer.toString());\r\n-        } else {\r\n-            logger.warning(\"No Hash values sent - Bag File does not meet BagIT specification requirement\");\r\n-        }\r\n-        // bagit.txt - Required by spec\r\n-        createFileFromString(\"bagit.txt\", \"BagIt-Version: 1.0\\r\\nTag-File-Character-Encoding: UTF-8\");\r\n-\r\n-        aggregation.addProperty(JsonLDTerm.totalSize.getLabel(), totalDataSize);\r\n-        aggregation.addProperty(JsonLDTerm.fileCount.getLabel(), dataCount);\r\n-        JsonArray mTypes = new JsonArray();\r\n-        for (String mt : mimetypes) {\r\n-            mTypes.add(new JsonPrimitive(mt));\r\n-        }\r\n-        aggregation.add(JsonLDTerm.dcTerms(\"format\").getLabel(), mTypes);\r\n-        aggregation.addProperty(JsonLDTerm.maxFileSize.getLabel(), maxFileSize);\r\n-        // Serialize oremap itself\r\n-        // FixMe - add missing hash values if needed and update context\r\n-        // (read and cache files or read twice?)\r\n-        createFileFromString(\"metadata/oai-ore.jsonld\", oremapObject.toString());\r\n-\r\n-        createFileFromString(\"metadata/datacite.xml\", dataciteXml);\r\n-\r\n-        // Add a bag-info file\r\n-        createFileFromString(\"bag-info.txt\", generateInfoFile());\r\n-\r\n-        logger.fine(\"Creating bag: \" + bagName);\r\n-\r\n-        ZipArchiveOutputStream zipArchiveOutputStream = new ZipArchiveOutputStream(outputStream);\r\n-\r\n-        /*\r\n-         * Add all the waiting contents - dirs created first, then data files are\r\n-         * retrieved via URLs in parallel (defaults to one thread per processor)\r\n-         * directly to the zip file\r\n-         */\r\n-        logger.fine(\"Starting write\");\r\n-        writeTo(zipArchiveOutputStream);\r\n-        logger.fine(\"Zipfile Written\");\r\n-        // Finish\r\n-        zipArchiveOutputStream.close();\r\n-        logger.fine(\"Closed\");\r\n-\r\n-        // Validate oremap - all entries are part of the collection\r\n-        for (int i = 0; i < resourceUsed.length; i++) {\r\n-            Boolean b = resourceUsed[i];\r\n-            if (b == null) {\r\n-                logger.warning(\"Problem: \" + pidMap.get(resourceIndex.get(i)) + \" was not used\");\r\n-            } else if (!b) {\r\n-                logger.warning(\"Problem: \" + pidMap.get(resourceIndex.get(i)) + \" was not included successfully\");\r\n-            } else {\r\n-                // Successfully included - now check for hash value and\r\n-                // generate if needed\r\n-                if (i > 0) { // Not root container\r\n-                    if (!checksumMap.containsKey(pidMap.get(resourceIndex.get(i)))) {\r\n-\r\n-                        if (!childIsContainer(aggregates.get(i - 1).getAsJsonObject()))\r\n-                            logger.warning(\"Missing checksum hash for: \" + resourceIndex.get(i));\r\n-                        // FixMe - actually generate it before adding the\r\n-                        // oremap\r\n-                        // to the zip\r\n-                    }\r\n-                }\r\n-            }\r\n-\r\n-        }\r\n-\r\n-        logger.info(\"Created bag: \" + bagName);\r\n-        client.close();\r\n-        return true;\r\n+      }\r\n \r\n     }\r\n \r\n-    public boolean generateBag(String bagName, boolean temp) {\r\n-        usetemp = temp;\r\n-        FileOutputStream bagFileOS = null;\r\n-        try {\r\n-            File origBagFile = getBagFile(bagName);\r\n-            File bagFile = origBagFile;\r\n-            if (usetemp) {\r\n-                bagFile = new File(bagFile.getAbsolutePath() + \".tmp\");\r\n-                logger.fine(\"Writing to: \" + bagFile.getAbsolutePath());\r\n-            }\r\n-            // Create an output stream backed by the file\r\n-            bagFileOS = new FileOutputStream(bagFile);\r\n-            if (generateBag(bagFileOS)) {\r\n-                validateBagFile(bagFile);\r\n-                if (usetemp) {\r\n-                    logger.fine(\"Moving tmp zip\");\r\n-                    origBagFile.delete();\r\n-                    bagFile.renameTo(origBagFile);\r\n-                }\r\n-                return true;\r\n-            } else {\r\n-                return false;\r\n-            }\r\n-        } catch (Exception e) {\r\n-            logger.log(Level.SEVERE,\"Bag Exception: \", e);\r\n-            e.printStackTrace();\r\n-            logger.warning(\"Failure: Processing failure during Bagit file creation\");\r\n-            return false;\r\n-        } finally {\r\n-            IOUtils.closeQuietly(bagFileOS);\r\n+    logger.info(\"Created bag: \" + bagName);\r\n+    client.close();\r\n+    return true;\r\n+\r\n+  }\r\n+\r\n+  public boolean generateBag(String bagName, boolean temp) {\r\n+    usetemp = temp;\r\n+    FileOutputStream bagFileOS = null;\r\n+    try {\r\n+      File origBagFile = getBagFile(bagName);\r\n+      File bagFile = origBagFile;\r\n+      if (usetemp) {\r\n+        bagFile = new File(bagFile.getAbsolutePath() + \".tmp\");\r\n+        logger.fine(\"Writing to: \" + bagFile.getAbsolutePath());\r\n+      }\r\n+      // Create an output stream backed by the file\r\n+      bagFileOS = new FileOutputStream(bagFile);\r\n+      if (generateBag(bagFileOS)) {\r\n+        validateBagFile(bagFile);\r\n+        if (usetemp) {\r\n+          logger.fine(\"Moving tmp zip\");\r\n+          origBagFile.delete();\r\n+          bagFile.renameTo(origBagFile);\r\n         }\r\n+        return true;\r\n+      } else {\r\n+        return false;\r\n+      }\r\n+    } catch (Exception e) {\r\n+      logger.log(Level.SEVERE, \"Bag Exception: \", e);\r\n+      e.printStackTrace();\r\n+      logger.warning(\"Failure: Processing failure during Bagit file creation\");\r\n+      return false;\r\n+    } finally {\r\n+      IOUtils.closeQuietly(bagFileOS);\r\n     }\r\n-\r\n-    public void validateBag(String bagId) {\r\n-        logger.info(\"Validating Bag\");\r\n-        ZipFile zf = null;\r\n-        InputStream is = null;\r\n-        try {\r\n-            zf = new ZipFile(getBagFile(bagId));\r\n-            ZipArchiveEntry entry = zf.getEntry(getValidName(bagId) + \"/manifest-sha1.txt\");\r\n+  }\r\n+\r\n+  public void validateBag(String bagId) {\r\n+    logger.info(\"Validating Bag\");\r\n+    ZipFile zf = null;\r\n+    InputStream is = null;\r\n+    try {\r\n+      zf = new ZipFile(getBagFile(bagId));\r\n+      ZipArchiveEntry entry = zf.getEntry(getValidName(bagId) + \"/manifest-sha1.txt\");\r\n+      if (entry != null) {\r\n+        logger.info(\"SHA1 hashes used\");\r\n+        hashtype = DataFile.ChecksumType.SHA1;\r\n+      } else {\r\n+        entry = zf.getEntry(getValidName(bagId) + \"/manifest-sha512.txt\");\r\n+        if (entry != null) {\r\n+          logger.info(\"SHA512 hashes used\");\r\n+          hashtype = DataFile.ChecksumType.SHA512;\r\n+        } else {\r\n+          entry = zf.getEntry(getValidName(bagId) + \"/manifest-sha256.txt\");\r\n+          if (entry != null) {\r\n+            logger.info(\"SHA256 hashes used\");\r\n+            hashtype = DataFile.ChecksumType.SHA256;\r\n+          } else {\r\n+            entry = zf.getEntry(getValidName(bagId) + \"/manifest-md5.txt\");\r\n             if (entry != null) {\r\n-                logger.info(\"SHA1 hashes used\");\r\n-                hashtype = DataFile.ChecksumType.SHA1;\r\n-            } else {\r\n-                entry = zf.getEntry(getValidName(bagId) + \"/manifest-sha512.txt\");\r\n-                if (entry != null) {\r\n-                    logger.info(\"SHA512 hashes used\");\r\n-                    hashtype = DataFile.ChecksumType.SHA512;\r\n-                } else {\r\n-                    entry = zf.getEntry(getValidName(bagId) + \"/manifest-sha256.txt\");\r\n-                    if (entry != null) {\r\n-                        logger.info(\"SHA256 hashes used\");\r\n-                        hashtype = DataFile.ChecksumType.SHA256;\r\n-                    } else {\r\n-                        entry = zf.getEntry(getValidName(bagId) + \"/manifest-md5.txt\");\r\n-                        if (entry != null) {\r\n-                            logger.info(\"MD5 hashes used\");\r\n-                            hashtype = DataFile.ChecksumType.MD5;\r\n-                        }\r\n-                    }\r\n-                }\r\n+              logger.info(\"MD5 hashes used\");\r\n+              hashtype = DataFile.ChecksumType.MD5;\r\n             }\r\n-            if (entry == null)\r\n-                throw new IOException(\"No manifest file found\");\r\n-            is = zf.getInputStream(entry);\r\n-            BufferedReader br = new BufferedReader(new InputStreamReader(is));\r\n-            String line = br.readLine();\r\n-            while (line != null) {\r\n-                logger.fine(\"Hash entry: \" + line);\r\n-                int breakIndex = line.indexOf(' ');\r\n-                String hash = line.substring(0, breakIndex);\r\n-                String path = line.substring(breakIndex + 1);\r\n-                logger.fine(\"Adding: \" + path + \" with hash: \" + hash);\r\n-                checksumMap.put(path, hash);\r\n-                line = br.readLine();\r\n-            }\r\n-            IOUtils.closeQuietly(is);\r\n-            logger.info(\"HashMap Map contains: \" + checksumMap.size() + \" entries\");\r\n-            checkFiles(checksumMap, zf);\r\n-        } catch (IOException io) {\r\n-            logger.log(Level.SEVERE,\"Could not validate Hashes\", io);\r\n-        } catch (Exception e) {\r\n-            logger.log(Level.SEVERE,\"Could not validate Hashes\", e);\r\n-        } finally {\r\n-            IOUtils.closeQuietly(zf);\r\n+          }\r\n         }\r\n-        return;\r\n+      }\r\n+      if (entry == null) {\r\n+        throw new IOException(\"No manifest file found\");\r\n+      }\r\n+      is = zf.getInputStream(entry);\r\n+      BufferedReader br = new BufferedReader(new InputStreamReader(is));\r\n+      String line = br.readLine();\r\n+      while (line != null) {\r\n+        logger.fine(\"Hash entry: \" + line);\r\n+        int breakIndex = line.indexOf(' ');\r\n+        String hash = line.substring(0, breakIndex);\r\n+        String path = line.substring(breakIndex + 1);\r\n+        logger.fine(\"Adding: \" + path + \" with hash: \" + hash);\r\n+        checksumMap.put(path, hash);\r\n+        line = br.readLine();\r\n+      }\r\n+      IOUtils.closeQuietly(is);\r\n+      logger.info(\"HashMap Map contains: \" + checksumMap.size() + \" entries\");\r\n+      checkFiles(checksumMap, zf);\r\n+    } catch (IOException io) {\r\n+      logger.log(Level.SEVERE, \"Could not validate Hashes\", io);\r\n+    } catch (Exception e) {\r\n+      logger.log(Level.SEVERE, \"Could not validate Hashes\", e);\r\n+    } finally {\r\n+      IOUtils.closeQuietly(zf);\r\n     }\r\n+    return;\r\n+  }\r\n \r\n-    public File getBagFile(String bagID) throws Exception {\r\n+  public File getBagFile(String bagID) throws Exception {\r\n \r\n-        String bagPath = Paths.get(getBagPath()).toString();\r\n-        // Create the bag file on disk\r\n-        File parent = new File(bagPath);\r\n-        if (!parent.exists()) {\r\n-            parent.mkdirs();\r\n-        }\r\n-        // Create known-good filename\r\n-        bagName = getValidName(bagID);\r\n-        File bagFile = new File(bagPath, bagName + \".zip\");\r\n-        logger.fine(\"BagPath: \" + bagFile.getAbsolutePath());\r\n-        // Create an output stream backed by the file\r\n-        return bagFile;\r\n+    String bagPath = Paths.get(getBagPath()).toString();\r\n+    // Create the bag file on disk\r\n+    File parent = new File(bagPath);\r\n+    if (!parent.exists()) {\r\n+      parent.mkdirs();\r\n     }\r\n-\r\n-    private void validateBagFile(File bagFile) throws IOException {\r\n-        // Run a confirmation test - should verify all files and hashes\r\n-        ZipFile zf = new ZipFile(bagFile);\r\n-        // Check files calculates the hashes and file sizes and reports on\r\n-        // whether hashes are correct\r\n-        checkFiles(checksumMap, zf);\r\n-\r\n-        logger.info(\"Data Count: \" + dataCount);\r\n-        logger.info(\"Data Size: \" + totalDataSize);\r\n-        zf.close();\r\n+    // Create known-good filename\r\n+    bagName = getValidName(bagID);\r\n+    File bagFile = new File(bagPath, bagName + \".zip\");\r\n+    logger.fine(\"BagPath: \" + bagFile.getAbsolutePath());\r\n+    // Create an output stream backed by the file\r\n+    return bagFile;\r\n+  }\r\n+\r\n+  private void validateBagFile(File bagFile) throws IOException {\r\n+    // Run a confirmation test - should verify all files and hashes\r\n+    ZipFile zf = new ZipFile(bagFile);\r\n+    // Check files calculates the hashes and file sizes and reports on\r\n+    // whether hashes are correct\r\n+    checkFiles(checksumMap, zf);\r\n+\r\n+    logger.info(\"Data Count: \" + dataCount);\r\n+    logger.info(\"Data Size: \" + totalDataSize);\r\n+    zf.close();\r\n+  }\r\n+\r\n+  public static String getValidName(String bagName) {\r\n+    // Create known-good filename - no spaces, no file-system separators.\r\n+    return bagName.replaceAll(\"\\\\W\", \"-\");\r\n+  }\r\n+\r\n+  private void processContainer(JsonObject item, String currentPath) throws IOException {\r\n+    JsonArray children = getChildren(item);\r\n+    HashSet<String> titles = new HashSet<String>();\r\n+    String title = null;\r\n+    if (item.has(JsonLDTerm.dcTerms(\"Title\").getLabel())) {\r\n+      title = item.get(\"Title\").getAsString();\r\n+    } else if (item.has(JsonLDTerm.schemaOrg(\"name\").getLabel())) {\r\n+      title = item.get(JsonLDTerm.schemaOrg(\"name\").getLabel()).getAsString();\r\n     }\r\n \r\n-    public static String getValidName(String bagName) {\r\n-        // Create known-good filename - no spaces, no file-system separators.\r\n-        return bagName.replaceAll(\"\\\\W\", \"-\");\r\n-    }\r\n+    currentPath = currentPath + title + \"/\";\r\n+    int containerIndex = -1;\r\n+    try {\r\n+      createDir(currentPath);\r\n+      // Add containers to pid map and mark as 'used', but no sha1 hash\r\n+      // value\r\n+      containerIndex = getUnusedIndexOf(item.get(\"@id\").getAsString());\r\n+      resourceUsed[containerIndex] = true;\r\n+      pidMap.put(item.get(\"@id\").getAsString(), currentPath);\r\n+\r\n+    } catch (InterruptedException | IOException | ExecutionException e) {\r\n+      e.printStackTrace();\r\n+      logger.severe(e.getMessage());\r\n+      if (containerIndex != -1) {\r\n+        resourceUsed[containerIndex] = false;\r\n+      }\r\n+      throw new IOException(\"Unable to create bag\");\r\n \r\n-    private void processContainer(JsonObject item, String currentPath) throws IOException {\r\n-        JsonArray children = getChildren(item);\r\n-        HashSet<String> titles = new HashSet<String>();\r\n-        String title = null;\r\n-        if (item.has(JsonLDTerm.dcTerms(\"Title\").getLabel())) {\r\n-            title = item.get(\"Title\").getAsString();\r\n-        } else if (item.has(JsonLDTerm.schemaOrg(\"name\").getLabel())) {\r\n-            title = item.get(JsonLDTerm.schemaOrg(\"name\").getLabel()).getAsString();\r\n+    }\r\n+    for (int i = 0; i < children.size(); i++) {\r\n+\r\n+      // Find the ith child in the overall array of aggregated\r\n+      // resources\r\n+      String childId = children.get(i).getAsString();\r\n+      logger.fine(\"Processing: \" + childId);\r\n+      int index = getUnusedIndexOf(childId);\r\n+      if (resourceUsed[index] != null) {\r\n+        System.out.println(\"Warning: reusing resource \" + index);\r\n+      }\r\n+\r\n+      // Aggregation is at index 0, so need to shift by 1 for aggregates\r\n+      // entries\r\n+      JsonObject child = aggregates.get(index - 1).getAsJsonObject();\r\n+      if (childIsContainer(child)) {\r\n+        // create dir and process children\r\n+        // processContainer will mark this item as used\r\n+        processContainer(child, currentPath);\r\n+      } else {\r\n+        resourceUsed[index] = true;\r\n+        // add item\r\n+        // ToDo\r\n+        String dataUrl = child.get(JsonLDTerm.schemaOrg(\"sameAs\").getLabel()).getAsString();\r\n+        logger.fine(\"File url: \" + dataUrl);\r\n+        String childTitle = child.get(JsonLDTerm.schemaOrg(\"name\").getLabel()).getAsString();\r\n+        if (titles.contains(childTitle)) {\r\n+          logger.warning(\"**** Multiple items with the same title in: \" + currentPath);\r\n+          logger.warning(\"**** Will cause failure in hash and size validation.\");\r\n+        } else {\r\n+          titles.add(childTitle);\r\n+        }\r\n+        String childPath = currentPath + childTitle;\r\n+\r\n+        String childHash = null;\r\n+        if (child.has(JsonLDTerm.checksum.getLabel())) {\r\n+          ChecksumType childHashType = ChecksumType.fromString(\r\n+            child.getAsJsonObject(JsonLDTerm.checksum.getLabel()).get(\"@type\").getAsString());\r\n+          if (hashtype != null && !hashtype.equals(childHashType)) {\r\n+            logger.warning(\"Multiple hash values in use - not supported\");\r\n+          }\r\n+          if (hashtype == null) {\r\n+            hashtype = childHashType;\r\n+          }\r\n+          childHash = child.getAsJsonObject(JsonLDTerm.checksum.getLabel()).get(\"@value\").getAsString();\r\n+          if (checksumMap.containsValue(childHash)) {\r\n+            // Something else has this hash\r\n+            logger.warning(\"Duplicate/Collision: \" + child.get(\"@id\").getAsString() + \" has SHA1 Hash: \"\r\n+              + childHash);\r\n+          }\r\n+          checksumMap.put(childPath, childHash);\r\n+        }\r\n+        if ((hashtype == null) | ignorehashes) {\r\n+          // Pick sha512 when ignoring hashes or none exist\r\n+          hashtype = DataFile.ChecksumType.SHA512;\r\n         }\r\n-\r\n-        currentPath = currentPath + title + \"/\";\r\n-        int containerIndex = -1;\r\n         try {\r\n-            createDir(currentPath);\r\n-            // Add containers to pid map and mark as 'used', but no sha1 hash\r\n-            // value\r\n-            containerIndex = getUnusedIndexOf(item.get(\"@id\").getAsString());\r\n-            resourceUsed[containerIndex] = true;\r\n-            pidMap.put(item.get(\"@id\").getAsString(), currentPath);\r\n-\r\n-        } catch (InterruptedException | IOException | ExecutionException e) {\r\n-            e.printStackTrace();\r\n-            logger.severe(e.getMessage());\r\n-            if (containerIndex != -1) {\r\n-                resourceUsed[containerIndex] = false;\r\n-            }\r\n-            throw new IOException(\"Unable to create bag\");\r\n+          if ((childHash == null) | ignorehashes) {\r\n+            // Generate missing hashInputStream inputStream = null;\r\n+            InputStream inputStream = null;\r\n+            try {\r\n+              inputStream = getInputStreamSupplier(dataUrl).get();\r\n+\r\n+              if (hashtype != null) {\r\n+                if (hashtype.equals(DataFile.ChecksumType.SHA1)) {\r\n+                  childHash = DigestUtils.sha1Hex(inputStream);\r\n+                } else if (hashtype.equals(DataFile.ChecksumType.SHA256)) {\r\n+                  childHash = DigestUtils.sha256Hex(inputStream);\r\n+                } else if (hashtype.equals(DataFile.ChecksumType.SHA512)) {\r\n+                  childHash = DigestUtils.sha512Hex(inputStream);\r\n+                } else if (hashtype.equals(DataFile.ChecksumType.MD5)) {\r\n+                  childHash = DigestUtils.md5Hex(inputStream);\r\n+                }\r\n+              }\r\n \r\n-        }\r\n-        for (int i = 0; i < children.size(); i++) {\r\n-\r\n-            // Find the ith child in the overall array of aggregated\r\n-            // resources\r\n-            String childId = children.get(i).getAsString();\r\n-            logger.fine(\"Processing: \" + childId);\r\n-            int index = getUnusedIndexOf(childId);\r\n-            if (resourceUsed[index] != null) {\r\n-                System.out.println(\"Warning: reusing resource \" + index);\r\n+            } catch (IOException e) {\r\n+              logger.severe(\"Failed to read \" + childPath);\r\n+              throw e;\r\n+            } finally {\r\n+              IOUtils.closeQuietly(inputStream);\r\n             }\r\n+            if (childHash != null) {\r\n+              JsonObject childHashObject = new JsonObject();\r\n+              childHashObject.addProperty(\"@type\", hashtype.toString());\r\n+              childHashObject.addProperty(\"@value\", childHash);\r\n+              child.add(JsonLDTerm.checksum.getLabel(), (JsonElement) childHashObject);\r\n \r\n-            // Aggregation is at index 0, so need to shift by 1 for aggregates\r\n-            // entries\r\n-            JsonObject child = aggregates.get(index - 1).getAsJsonObject();\r\n-            if (childIsContainer(child)) {\r\n-                // create dir and process children\r\n-                // processContainer will mark this item as used\r\n-                processContainer(child, currentPath);\r\n+              checksumMap.put(childPath, childHash);\r\n             } else {\r\n-                resourceUsed[index] = true;\r\n-                // add item\r\n-                // ToDo\r\n-                String dataUrl = child.get(JsonLDTerm.schemaOrg(\"sameAs\").getLabel()).getAsString();\r\n-                logger.fine(\"File url: \" + dataUrl);\r\n-                String childTitle = child.get(JsonLDTerm.schemaOrg(\"name\").getLabel()).getAsString();\r\n-                if (titles.contains(childTitle)) {\r\n-                    logger.warning(\"**** Multiple items with the same title in: \" + currentPath);\r\n-                    logger.warning(\"**** Will cause failure in hash and size validation.\");\r\n-                } else {\r\n-                    titles.add(childTitle);\r\n-                }\r\n-                String childPath = currentPath + childTitle;\r\n-\r\n-                String childHash = null;\r\n-                if (child.has(JsonLDTerm.checksum.getLabel())) {\r\n-                    ChecksumType childHashType = ChecksumType.fromString(\r\n-                            child.getAsJsonObject(JsonLDTerm.checksum.getLabel()).get(\"@type\").getAsString());\r\n-                    if (hashtype != null && !hashtype.equals(childHashType)) {\r\n-                        logger.warning(\"Multiple hash values in use - not supported\");\r\n-                    }\r\n-                    if (hashtype == null)\r\n-                        hashtype = childHashType;\r\n-                    childHash = child.getAsJsonObject(JsonLDTerm.checksum.getLabel()).get(\"@value\").getAsString();\r\n-                    if (checksumMap.containsValue(childHash)) {\r\n-                        // Something else has this hash\r\n-                        logger.warning(\"Duplicate/Collision: \" + child.get(\"@id\").getAsString() + \" has SHA1 Hash: \"\r\n-                                + childHash);\r\n-                    }\r\n-                    checksumMap.put(childPath, childHash);\r\n-                }\r\n-                if ((hashtype == null) | ignorehashes) {\r\n-                    // Pick sha512 when ignoring hashes or none exist\r\n-                    hashtype = DataFile.ChecksumType.SHA512;\r\n-                }\r\n-                try {\r\n-                    if ((childHash == null) | ignorehashes) {\r\n-                        // Generate missing hashInputStream inputStream = null;\r\n-                        InputStream inputStream = null;\r\n-                        try {\r\n-                            inputStream = getInputStreamSupplier(dataUrl).get();\r\n-\r\n-                            if (hashtype != null) {\r\n-                                if (hashtype.equals(DataFile.ChecksumType.SHA1)) {\r\n-                                    childHash = DigestUtils.sha1Hex(inputStream);\r\n-                                } else if (hashtype.equals(DataFile.ChecksumType.SHA256)) {\r\n-                                    childHash = DigestUtils.sha256Hex(inputStream);\r\n-                                } else if (hashtype.equals(DataFile.ChecksumType.SHA512)) {\r\n-                                    childHash = DigestUtils.sha512Hex(inputStream);\r\n-                                } else if (hashtype.equals(DataFile.ChecksumType.MD5)) {\r\n-                                    childHash = DigestUtils.md5Hex(inputStream);\r\n-                                }\r\n-                            }\r\n-\r\n-                        } catch (IOException e) {\r\n-                            logger.severe(\"Failed to read \" + childPath);\r\n-                            throw e;\r\n-                        } finally {\r\n-                            IOUtils.closeQuietly(inputStream);\r\n-                        }\r\n-                        if (childHash != null) {\r\n-                            JsonObject childHashObject = new JsonObject();\r\n-                            childHashObject.addProperty(\"@type\", hashtype.toString());\r\n-                            childHashObject.addProperty(\"@value\", childHash);\r\n-                            child.add(JsonLDTerm.checksum.getLabel(), (JsonElement) childHashObject);\r\n-\r\n-                            checksumMap.put(childPath, childHash);\r\n-                        } else {\r\n-                            logger.warning(\"Unable to calculate a \" + hashtype + \" for \" + dataUrl);\r\n-                        }\r\n-                    }\r\n-                    logger.fine(\"Requesting: \" + childPath + \" from \" + dataUrl);\r\n-                    createFileFromURL(childPath, dataUrl);\r\n-                    dataCount++;\r\n-                    if (dataCount % 1000 == 0) {\r\n-                        logger.info(\"Retrieval in progress: \" + dataCount + \" files retrieved\");\r\n-                    }\r\n-                    if (child.has(JsonLDTerm.filesize.getLabel())) {\r\n-                        Long size = child.get(JsonLDTerm.filesize.getLabel()).getAsLong();\r\n-                        totalDataSize += size;\r\n-                        if (size > maxFileSize) {\r\n-                            maxFileSize = size;\r\n-                        }\r\n-                    }\r\n-                    if (child.has(JsonLDTerm.schemaOrg(\"fileFormat\").getLabel())) {\r\n-                        mimetypes.add(child.get(JsonLDTerm.schemaOrg(\"fileFormat\").getLabel()).getAsString());\r\n-                    }\r\n-\r\n-                } catch (Exception e) {\r\n-                    resourceUsed[index] = false;\r\n-                    e.printStackTrace();\r\n-                    throw new IOException(\"Unable to create bag\");\r\n-                }\r\n-\r\n-                // Check for nulls!\r\n-                pidMap.put(child.get(\"@id\").getAsString(), childPath);\r\n-\r\n+              logger.warning(\"Unable to calculate a \" + hashtype + \" for \" + dataUrl);\r\n             }\r\n-        }\r\n-    }\r\n-\r\n-    private int getUnusedIndexOf(String childId) {\r\n-        int index = resourceIndex.indexOf(childId);\r\n-        if (resourceUsed[index] != null) {\r\n-            System.out.println(\"Warning: reusing resource \" + index);\r\n-        }\r\n+          }\r\n+          logger.fine(\"Requesting: \" + childPath + \" from \" + dataUrl);\r\n+          createFileFromURL(childPath, dataUrl);\r\n+          dataCount++;\r\n+          if (dataCount % 1000 == 0) {\r\n+            logger.info(\"Retrieval in progress: \" + dataCount + \" files retrieved\");\r\n+          }\r\n+          if (child.has(JsonLDTerm.filesize.getLabel())) {\r\n+            Long size = child.get(JsonLDTerm.filesize.getLabel()).getAsLong();\r\n+            totalDataSize += size;\r\n+            if (size > maxFileSize) {\r\n+              maxFileSize = size;\r\n+            }\r\n+          }\r\n+          if (child.has(JsonLDTerm.schemaOrg(\"fileFormat\").getLabel())) {\r\n+            mimetypes.add(child.get(JsonLDTerm.schemaOrg(\"fileFormat\").getLabel()).getAsString());\r\n+          }\r\n \r\n-        while (resourceUsed[index] != null) {\r\n-            int offset = index;\r\n-            index = offset + 1 + resourceIndex.subList(offset + 1, resourceIndex.size()).indexOf(childId);\r\n-        }\r\n-        System.out.println(\"Using index: \" + index);\r\n-        if (index == -1) {\r\n-            logger.severe(\"Reused ID: \" + childId + \" not found enough times in resource list\");\r\n+        } catch (Exception e) {\r\n+          resourceUsed[index] = false;\r\n+          e.printStackTrace();\r\n+          throw new IOException(\"Unable to create bag\");\r\n         }\r\n-        return index;\r\n-    }\r\n \r\n-    private ArrayList<String> indexResources(String aggId, JsonArray aggregates) {\r\n+        // Check for nulls!\r\n+        pidMap.put(child.get(\"@id\").getAsString(), childPath);\r\n \r\n-        ArrayList<String> l = new ArrayList<String>(aggregates.size() + 1);\r\n-        l.add(aggId);\r\n-        for (int i = 0; i < aggregates.size(); i++) {\r\n-            logger.fine(\"Indexing : \" + i + \" \" + aggregates.get(i).getAsJsonObject().get(\"@id\").getAsString());\r\n-            l.add(aggregates.get(i).getAsJsonObject().get(\"@id\").getAsString());\r\n-        }\r\n-        logger.fine(\"Index created for \" + aggregates.size() + \" entries\");\r\n-        return l;\r\n+      }\r\n     }\r\n+  }\r\n \r\n-    private void createDir(final String name) throws IOException, ExecutionException, InterruptedException {\r\n-\r\n-        ZipArchiveEntry archiveEntry = new ZipArchiveEntry(bagName + \"/\" + name);\r\n-        archiveEntry.setMethod(ZipEntry.DEFLATED);\r\n-        InputStreamSupplier supp = new InputStreamSupplier() {\r\n-            public InputStream get() {\r\n-                return new ByteArrayInputStream((\"\").getBytes());\r\n-            }\r\n-        };\r\n-\r\n-        addEntry(archiveEntry, supp);\r\n+  private int getUnusedIndexOf(String childId) {\r\n+    int index = resourceIndex.indexOf(childId);\r\n+    if (resourceUsed[index] != null) {\r\n+      System.out.println(\"Warning: reusing resource \" + index);\r\n     }\r\n \r\n-    private void createFileFromString(final String relPath, final String content)\r\n-            throws IOException, ExecutionException, InterruptedException {\r\n-\r\n-        ZipArchiveEntry archiveEntry = new ZipArchiveEntry(bagName + \"/\" + relPath);\r\n-        archiveEntry.setMethod(ZipEntry.DEFLATED);\r\n-        InputStreamSupplier supp = new InputStreamSupplier() {\r\n-            public InputStream get() {\r\n-                try {\r\n-                    return new ByteArrayInputStream(content.getBytes(\"UTF-8\"));\r\n-                } catch (UnsupportedEncodingException e) {\r\n-                    e.printStackTrace();\r\n-                }\r\n-                return null;\r\n-            }\r\n-        };\r\n-\r\n-        addEntry(archiveEntry, supp);\r\n+    while (resourceUsed[index] != null) {\r\n+      int offset = index;\r\n+      index = offset + 1 + resourceIndex.subList(offset + 1, resourceIndex.size()).indexOf(childId);\r\n     }\r\n-\r\n-    private void createFileFromURL(final String relPath, final String uri)\r\n-            throws IOException, ExecutionException, InterruptedException {\r\n-\r\n-        ZipArchiveEntry archiveEntry = new ZipArchiveEntry(bagName + \"/\" + relPath);\r\n-        archiveEntry.setMethod(ZipEntry.DEFLATED);\r\n-        InputStreamSupplier supp = getInputStreamSupplier(uri);\r\n-        addEntry(archiveEntry, supp);\r\n+    System.out.println(\"Using index: \" + index);\r\n+    if (index == -1) {\r\n+      logger.severe(\"Reused ID: \" + childId + \" not found enough times in resource list\");\r\n     }\r\n+    return index;\r\n+  }\r\n \r\n-    private void checkFiles(HashMap<String, String> shaMap, ZipFile zf) {\r\n-        ExecutorService executor = Executors.newFixedThreadPool(numConnections);\r\n-        BagValidationJob.setZipFile(zf);\r\n-        BagValidationJob.setBagGenerator(this);\r\n-        logger.fine(\"Validating hashes for zipped data files\");\r\n-        int i = 0;\r\n-        for (Entry<String, String> entry : shaMap.entrySet()) {\r\n-            BagValidationJob vj = new BagValidationJob(entry.getValue(), entry.getKey());\r\n-            executor.execute(vj);\r\n-            i++;\r\n-            if (i % 1000 == 0) {\r\n-                logger.info(\"Queuing Hash Validations: \" + i);\r\n-            }\r\n-        }\r\n-        logger.fine(\"All Hash Validations Queued: \" + i);\r\n+  private ArrayList<String> indexResources(String aggId, JsonArray aggregates) {\r\n \r\n-        executor.shutdown();\r\n+    ArrayList<String> l = new ArrayList<String>(aggregates.size() + 1);\r\n+    l.add(aggId);\r\n+    for (int i = 0; i < aggregates.size(); i++) {\r\n+      logger.fine(\"Indexing : \" + i + \" \" + aggregates.get(i).getAsJsonObject().get(\"@id\").getAsString());\r\n+      l.add(aggregates.get(i).getAsJsonObject().get(\"@id\").getAsString());\r\n+    }\r\n+    logger.fine(\"Index created for \" + aggregates.size() + \" entries\");\r\n+    return l;\r\n+  }\r\n+\r\n+  private void createDir(final String name) throws IOException, ExecutionException, InterruptedException {\r\n+\r\n+    ZipArchiveEntry archiveEntry = new ZipArchiveEntry(bagName + \"/\" + name);\r\n+    archiveEntry.setMethod(ZipEntry.DEFLATED);\r\n+    InputStreamSupplier supp = new InputStreamSupplier() {\r\n+      public InputStream get() {\r\n+        return new ByteArrayInputStream((\"\").getBytes());\r\n+      }\r\n+    };\r\n+\r\n+    addEntry(archiveEntry, supp);\r\n+  }\r\n+\r\n+  private void createFileFromString(final String relPath, final String content)\r\n+    throws IOException, ExecutionException, InterruptedException {\r\n+\r\n+    ZipArchiveEntry archiveEntry = new ZipArchiveEntry(bagName + \"/\" + relPath);\r\n+    archiveEntry.setMethod(ZipEntry.DEFLATED);\r\n+    InputStreamSupplier supp = new InputStreamSupplier() {\r\n+      public InputStream get() {\r\n         try {\r\n-            while (!executor.awaitTermination(10, TimeUnit.MINUTES)) {\r\n-                logger.fine(\"Awaiting completion of hash calculations.\");\r\n-            }\r\n-        } catch (InterruptedException e) {\r\n-            logger.log(Level.SEVERE,\"Hash Calculations interrupted\", e);\r\n+          return new ByteArrayInputStream(content.getBytes(\"UTF-8\"));\r\n+        } catch (UnsupportedEncodingException e) {\r\n+          e.printStackTrace();\r\n         }\r\n-        logger.fine(\"Hash Validations Completed\");\r\n-\r\n+        return null;\r\n+      }\r\n+    };\r\n+\r\n+    addEntry(archiveEntry, supp);\r\n+  }\r\n+\r\n+  private void createFileFromURL(final String relPath, final String uri)\r\n+    throws IOException, ExecutionException, InterruptedException {\r\n+\r\n+    ZipArchiveEntry archiveEntry = new ZipArchiveEntry(bagName + \"/\" + relPath);\r\n+    archiveEntry.setMethod(ZipEntry.DEFLATED);\r\n+    InputStreamSupplier supp = getInputStreamSupplier(uri);\r\n+    addEntry(archiveEntry, supp);\r\n+  }\r\n+\r\n+  private void checkFiles(HashMap<String, String> shaMap, ZipFile zf) {\r\n+    ExecutorService executor = Executors.newFixedThreadPool(numConnections);\r\n+    BagValidationJob.setZipFile(zf);\r\n+    BagValidationJob.setBagGenerator(this);\r\n+    logger.fine(\"Validating hashes for zipped data files\");\r\n+    int i = 0;\r\n+    for (Entry<String, String> entry : shaMap.entrySet()) {\r\n+      BagValidationJob vj = new BagValidationJob(entry.getValue(), entry.getKey());\r\n+      executor.execute(vj);\r\n+      i++;\r\n+      if (i % 1000 == 0) {\r\n+        logger.info(\"Queuing Hash Validations: \" + i);\r\n+      }\r\n     }\r\n-\r\n-    public void addEntry(ZipArchiveEntry zipArchiveEntry, InputStreamSupplier streamSupplier) throws IOException {\r\n-        if (zipArchiveEntry.isDirectory() && !zipArchiveEntry.isUnixSymlink())\r\n-            dirs.addArchiveEntry(ZipArchiveEntryRequest.createZipArchiveEntryRequest(zipArchiveEntry, streamSupplier));\r\n-        else\r\n-            scatterZipCreator.addArchiveEntry(zipArchiveEntry, streamSupplier);\r\n+    logger.fine(\"All Hash Validations Queued: \" + i);\r\n+\r\n+    executor.shutdown();\r\n+    try {\r\n+      while (!executor.awaitTermination(10, TimeUnit.MINUTES)) {\r\n+        logger.fine(\"Awaiting completion of hash calculations.\");\r\n+      }\r\n+    } catch (InterruptedException e) {\r\n+      logger.log(Level.SEVERE, \"Hash Calculations interrupted\", e);\r\n     }\r\n+    logger.fine(\"Hash Validations Completed\");\r\n \r\n-    public void writeTo(ZipArchiveOutputStream zipArchiveOutputStream)\r\n-            throws IOException, ExecutionException, InterruptedException {\r\n-        logger.fine(\"Writing dirs\");\r\n-        dirs.writeTo(zipArchiveOutputStream);\r\n-        dirs.close();\r\n-        logger.fine(\"Dirs written\");\r\n-        scatterZipCreator.writeTo(zipArchiveOutputStream);\r\n-        logger.fine(\"Files written\");\r\n-    }\r\n+  }\r\n \r\n-    static final String CRLF = \"\\r\\n\";\r\n-\r\n-    private String generateInfoFile() {\r\n-        logger.fine(\"Generating info file\");\r\n-        StringBuffer info = new StringBuffer();\r\n-\r\n-        JsonArray contactsArray = new JsonArray();\r\n-        /* Contact, and it's subfields, are terms from citation.tsv whose mapping to a formal vocabulary and label in the oremap may change\r\n-         * so we need to find the labels used.\r\n-         */ \r\n-        JsonLDTerm contactTerm = oremap.getContactTerm();\r\n-        if ((contactTerm != null) && aggregation.has(contactTerm.getLabel())) {\r\n-\r\n-            JsonElement contacts = aggregation.get(contactTerm.getLabel());\r\n-            JsonLDTerm contactNameTerm = oremap.getContactNameTerm();\r\n-            JsonLDTerm contactEmailTerm = oremap.getContactEmailTerm();\r\n-            \r\n-            if (contacts.isJsonArray()) {\r\n-                for (int i = 0; i < contactsArray.size(); i++) {\r\n-                    info.append(\"Contact-Name: \");\r\n-                    JsonElement person = contactsArray.get(i);\r\n-                    if (person.isJsonPrimitive()) {\r\n-                        info.append(person.getAsString());\r\n-                        info.append(CRLF);\r\n-\r\n-                    } else {\r\n-                        if(contactNameTerm != null) {\r\n-                          info.append(((JsonObject) person).get(contactNameTerm.getLabel()).getAsString());\r\n-                          info.append(CRLF);\r\n-                        }\r\n-                        if ((contactEmailTerm!=null) &&((JsonObject) person).has(contactEmailTerm.getLabel())) {\r\n-                            info.append(\"Contact-Email: \");\r\n-                            info.append(((JsonObject) person).get(contactEmailTerm.getLabel()).getAsString());\r\n-                            info.append(CRLF);\r\n-                        }\r\n-                    }\r\n-                }\r\n-            } else {\r\n-                info.append(\"Contact-Name: \");\r\n-\r\n-                if (contacts.isJsonPrimitive()) {\r\n-                    info.append((String) contacts.getAsString());\r\n-                    info.append(CRLF);\r\n-\r\n-                } else {\r\n-                    JsonObject person = contacts.getAsJsonObject();\r\n-                    if(contactNameTerm != null) {\r\n-                      info.append(person.get(contactNameTerm.getLabel()).getAsString());\r\n-                      info.append(CRLF);\r\n-                    }\r\n-                    if ((contactEmailTerm!=null) && (person.has(contactEmailTerm.getLabel()))) {\r\n-                        info.append(\"Contact-Email: \");\r\n-                        info.append(person.get(contactEmailTerm.getLabel()).getAsString());\r\n-                        info.append(CRLF);\r\n-                    }\r\n-                }\r\n+  public void addEntry(ZipArchiveEntry zipArchiveEntry, InputStreamSupplier streamSupplier) throws IOException {\r\n+    if (zipArchiveEntry.isDirectory() && !zipArchiveEntry.isUnixSymlink()) {\r\n+      dirs.addArchiveEntry(ZipArchiveEntryRequest.createZipArchiveEntryRequest(zipArchiveEntry, streamSupplier));\r\n+    } else {\r\n+      scatterZipCreator.addArchiveEntry(zipArchiveEntry, streamSupplier);\r\n+    }\r\n+  }\r\n+\r\n+  public void writeTo(ZipArchiveOutputStream zipArchiveOutputStream)\r\n+    throws IOException, ExecutionException, InterruptedException {\r\n+    logger.fine(\"Writing dirs\");\r\n+    dirs.writeTo(zipArchiveOutputStream);\r\n+    dirs.close();\r\n+    logger.fine(\"Dirs written\");\r\n+    scatterZipCreator.writeTo(zipArchiveOutputStream);\r\n+    logger.fine(\"Files written\");\r\n+  }\r\n+\r\n+  static final String CRLF = \"\\r\\n\";\r\n+\r\n+  private String generateInfoFile() {\r\n+    logger.fine(\"Generating info file\");\r\n+    StringBuffer info = new StringBuffer();\r\n+\r\n+    JsonArray contactsArray = new JsonArray();\r\n+    /* Contact, and it's subfields, are terms from citation.tsv whose mapping to a formal vocabulary and label in the oremap may change\r\n+     * so we need to find the labels used.\r\n+     */\r\n+    JsonLDTerm contactTerm = oremap.getContactTerm();\r\n+    if ((contactTerm != null) && aggregation.has(contactTerm.getLabel())) {\r\n+\r\n+      JsonElement contacts = aggregation.get(contactTerm.getLabel());\r\n+      JsonLDTerm contactNameTerm = oremap.getContactNameTerm();\r\n+      JsonLDTerm contactEmailTerm = oremap.getContactEmailTerm();\r\n+\r\n+      if (contacts.isJsonArray()) {\r\n+        for (int i = 0; i < contactsArray.size(); i++) {\r\n+          info.append(\"Contact-Name: \");\r\n+          JsonElement person = contactsArray.get(i);\r\n+          if (person.isJsonPrimitive()) {\r\n+            info.append(person.getAsString());\r\n+            info.append(CRLF);\r\n \r\n+          } else {\r\n+            if (contactNameTerm != null) {\r\n+              info.append(((JsonObject) person).get(contactNameTerm.getLabel()).getAsString());\r\n+              info.append(CRLF);\r\n             }\r\n-        } else {\r\n-            logger.warning(\"No contact info available for BagIt Info file\");\r\n+            if ((contactEmailTerm != null) && ((JsonObject) person).has(contactEmailTerm.getLabel())) {\r\n+              info.append(\"Contact-Email: \");\r\n+              info.append(((JsonObject) person).get(contactEmailTerm.getLabel()).getAsString());\r\n+              info.append(CRLF);\r\n+            }\r\n+          }\r\n         }\r\n+      } else {\r\n+        info.append(\"Contact-Name: \");\r\n \r\n-        info.append(\"Source-Organization: \" + BundleUtil.getStringFromBundle(\"bagit.sourceOrganization\"));\r\n-        // ToDo - make configurable\r\n-        info.append(CRLF);\r\n-\r\n-        info.append(\"Organization-Address: \" + WordUtils.wrap(\r\n-                BundleUtil.getStringFromBundle(\"bagit.sourceOrganizationAddress\"), 78, CRLF + \" \", true));\r\n-        info.append(CRLF);\r\n-\r\n-        // Not a BagIt standard name\r\n-        info.append(\r\n-                \"Organization-Email: \" + BundleUtil.getStringFromBundle(\"bagit.sourceOrganizationEmail\"));\r\n-        info.append(CRLF);\r\n-\r\n-        info.append(\"External-Description: \");\r\n-        \r\n-        /* Description, and it's subfields, are terms from citation.tsv whose mapping to a formal vocabulary and label in the oremap may change\r\n-         * so we need to find the labels used.\r\n-         */\r\n-        JsonLDTerm descriptionTerm = oremap.getDescriptionTerm();\r\n-        JsonLDTerm descriptionTextTerm = oremap.getDescriptionTextTerm();\r\n-        if (descriptionTerm == null) {\r\n-            logger.warning(\"No description available for BagIt Info file\");\r\n-        } else {\r\n-            info.append(\r\n-                    // FixMe - handle description having subfields better\r\n-                    WordUtils.wrap(getSingleValue(aggregation.getAsJsonObject(descriptionTerm.getLabel()),\r\n-                            descriptionTextTerm.getLabel()), 78, CRLF + \" \", true));\r\n+        if (contacts.isJsonPrimitive()) {\r\n+          info.append((String) contacts.getAsString());\r\n+          info.append(CRLF);\r\n \r\n+        } else {\r\n+          JsonObject person = contacts.getAsJsonObject();\r\n+          if (contactNameTerm != null) {\r\n+            info.append(person.get(contactNameTerm.getLabel()).getAsString());\r\n             info.append(CRLF);\r\n+          }\r\n+          if ((contactEmailTerm != null) && (person.has(contactEmailTerm.getLabel()))) {\r\n+            info.append(\"Contact-Email: \");\r\n+            info.append(person.get(contactEmailTerm.getLabel()).getAsString());\r\n+            info.append(CRLF);\r\n+          }\r\n         }\r\n-        info.append(\"Bagging-Date: \");\r\n-        info.append((new SimpleDateFormat(\"yyyy-MM-dd\").format(Calendar.getInstance().getTime())));\r\n-        info.append(CRLF);\r\n-\r\n-        info.append(\"External-Identifier: \");\r\n-        info.append(aggregation.get(\"@id\").getAsString());\r\n-        info.append(CRLF);\r\n-\r\n-        info.append(\"Bag-Size: \");\r\n-        info.append(byteCountToDisplaySize(totalDataSize));\r\n-        info.append(CRLF);\r\n-\r\n-        info.append(\"Payload-Oxum: \");\r\n-        info.append(Long.toString(totalDataSize));\r\n-        info.append(\".\");\r\n-        info.append(Long.toString(dataCount));\r\n-        info.append(CRLF);\r\n-\r\n-        info.append(\"Internal-Sender-Identifier: \");\r\n-        String catalog = BundleUtil.getStringFromBundle(\"bagit.sourceOrganization\") + \" Catalog\";\r\n-        if (aggregation.has(JsonLDTerm.schemaOrg(\"includedInDataCatalog\").getLabel())) {\r\n-            catalog = aggregation.get(JsonLDTerm.schemaOrg(\"includedInDataCatalog\").getLabel()).getAsString();\r\n-        }\r\n-        info.append(catalog + \":\" + aggregation.get(JsonLDTerm.schemaOrg(\"name\").getLabel()).getAsString());\r\n-        info.append(CRLF);\r\n-\r\n-        return info.toString();\r\n \r\n+      }\r\n+    } else {\r\n+      logger.warning(\"No contact info available for BagIt Info file\");\r\n     }\r\n \r\n-    /**\r\n-     * Kludge - handle when a single string is sent as an array of 1 string and, for\r\n-     * cases where multiple values are sent when only one is expected, create a\r\n-     * concatenated string so that information is not lost.\r\n-     * \r\n-     * @param jsonObject\r\n-     *            - the root json object\r\n-     * @param key\r\n-     *            - the key to find a value(s) for\r\n-     * @return - a single string\r\n-     */\r\n-    String getSingleValue(JsonObject jsonObject, String key) {\r\n-        String val = \"\";\r\n-        if (jsonObject.get(key).isJsonPrimitive()) {\r\n-            val = jsonObject.get(key).getAsString();\r\n-        } else if (jsonObject.get(key).isJsonArray()) {\r\n-            Iterator<JsonElement> iter = jsonObject.getAsJsonArray(key).iterator();\r\n-            ArrayList<String> stringArray = new ArrayList<String>();\r\n-            while (iter.hasNext()) {\r\n-                stringArray.add(iter.next().getAsString());\r\n-            }\r\n-            if (stringArray.size() > 1) {\r\n-                val = StringUtils.join((String[]) stringArray.toArray(), \",\");\r\n-            } else {\r\n-                val = stringArray.get(0);\r\n-            }\r\n-            logger.warning(\"Multiple values found for: \" + key + \": \" + val);\r\n-        }\r\n-        return val;\r\n-    }\r\n+    info.append(\"Source-Organization: \" + BundleUtil.getStringFromBundle(\"bagit.sourceOrganization\"));\r\n+    // ToDo - make configurable\r\n+    info.append(CRLF);\r\n \r\n-    // Used in validation\r\n+    info.append(\"Organization-Address: \" + WordUtils.wrap(\r\n+      BundleUtil.getStringFromBundle(\"bagit.sourceOrganizationAddress\"), 78, CRLF + \" \", true));\r\n+    info.append(CRLF);\r\n \r\n-    public void incrementTotalDataSize(long inc) {\r\n-        totalDataSize += inc;\r\n-    }\r\n+    // Not a BagIt standard name\r\n+    info.append(\r\n+      \"Organization-Email: \" + BundleUtil.getStringFromBundle(\"bagit.sourceOrganizationEmail\"));\r\n+    info.append(CRLF);\r\n \r\n-    public String getHashtype() {\r\n-        return hashtype.toString();\r\n-    }\r\n+    info.append(\"External-Description: \");\r\n \r\n-    // Get's all \"Has Part\" children, standardized to send an array with 0,1, or\r\n-    // more elements\r\n-    private static JsonArray getChildren(JsonObject parent) {\r\n-        JsonElement o = null;\r\n-        o = parent.get(JsonLDTerm.schemaOrg(\"hasPart\").getLabel());\r\n-        if (o == null) {\r\n-            return new JsonArray();\r\n-        } else {\r\n-            if (o.isJsonArray()) {\r\n-                return (JsonArray) o;\r\n-            } else if (o.isJsonPrimitive()) {\r\n-                JsonArray children = new JsonArray();\r\n-                children.add(o);\r\n-                return (children);\r\n-            }\r\n-            logger.severe(\"Error finding children: \" + o.toString());\r\n-            return new JsonArray();\r\n-        }\r\n+    /* Description, and it's subfields, are terms from citation.tsv whose mapping to a formal vocabulary and label in the oremap may change\r\n+     * so we need to find the labels used.\r\n+     */\r\n+    JsonLDTerm descriptionTerm = oremap.getDescriptionTerm();\r\n+    JsonLDTerm descriptionTextTerm = oremap.getDescriptionTextTerm();\r\n+    if (descriptionTerm == null) {\r\n+      logger.warning(\"No description available for BagIt Info file\");\r\n+    } else {\r\n+      info.append(\r\n+        // FixMe - handle description having subfields better\r\n+        WordUtils.wrap(getSingleValue(aggregation.getAsJsonObject(descriptionTerm.getLabel()),\r\n+          descriptionTextTerm.getLabel()), 78, CRLF + \" \", true));\r\n+\r\n+      info.append(CRLF);\r\n     }\r\n+    info.append(\"Bagging-Date: \");\r\n+    info.append((new SimpleDateFormat(\"yyyy-MM-dd\").format(Calendar.getInstance().getTime())));\r\n+    info.append(CRLF);\r\n+\r\n+    info.append(\"External-Identifier: \");\r\n+    info.append(aggregation.get(\"@id\").getAsString());\r\n+    info.append(CRLF);\r\n+\r\n+    info.append(\"Bag-Size: \");\r\n+    info.append(byteCountToDisplaySize(totalDataSize));\r\n+    info.append(CRLF);\r\n+\r\n+    info.append(\"Payload-Oxum: \");\r\n+    info.append(Long.toString(totalDataSize));\r\n+    info.append(\".\");\r\n+    info.append(Long.toString(dataCount));\r\n+    info.append(CRLF);\r\n+\r\n+    info.append(\"Internal-Sender-Identifier: \");\r\n+    String catalog = BundleUtil.getStringFromBundle(\"bagit.sourceOrganization\") + \" Catalog\";\r\n+    if (aggregation.has(JsonLDTerm.schemaOrg(\"includedInDataCatalog\").getLabel())) {\r\n+      catalog = aggregation.get(JsonLDTerm.schemaOrg(\"includedInDataCatalog\").getLabel()).getAsString();\r\n+    }\r\n+    info.append(catalog + \":\" + aggregation.get(JsonLDTerm.schemaOrg(\"name\").getLabel()).getAsString());\r\n+    info.append(CRLF);\r\n+\r\n+    return info.toString();\r\n+\r\n+  }\r\n+\r\n+  /**\r\n+   * Kludge - handle when a single string is sent as an array of 1 string and, for\r\n+   * cases where multiple values are sent when only one is expected, create a\r\n+   * concatenated string so that information is not lost.\r\n+   *\r\n+   * @param jsonObject - the root json object\r\n+   * @param key        - the key to find a value(s) for\r\n+   * @return - a single string\r\n+   */\r\n+  String getSingleValue(JsonObject jsonObject, String key) {\r\n+    String val = \"\";\r\n+    if (jsonObject.get(key).isJsonPrimitive()) {\r\n+      val = jsonObject.get(key).getAsString();\r\n+    } else if (jsonObject.get(key).isJsonArray()) {\r\n+      Iterator<JsonElement> iter = jsonObject.getAsJsonArray(key).iterator();\r\n+      ArrayList<String> stringArray = new ArrayList<String>();\r\n+      while (iter.hasNext()) {\r\n+        stringArray.add(iter.next().getAsString());\r\n+      }\r\n+      if (stringArray.size() > 1) {\r\n+        val = StringUtils.join((String[]) stringArray.toArray(), \",\");\r\n+      } else {\r\n+        val = stringArray.get(0);\r\n+      }\r\n+      logger.warning(\"Multiple values found for: \" + key + \": \" + val);\r\n+    }\r\n+    return val;\r\n+  }\r\n+\r\n+  // Used in validation\r\n+\r\n+  public void incrementTotalDataSize(long inc) {\r\n+    totalDataSize += inc;\r\n+  }\r\n+\r\n+  public String getHashtype() {\r\n+    return hashtype.toString();\r\n+  }\r\n+\r\n+  // Get's all \"Has Part\" children, standardized to send an array with 0,1, or\r\n+  // more elements\r\n+  private static JsonArray getChildren(JsonObject parent) {\r\n+    JsonElement o = null;\r\n+    o = parent.get(JsonLDTerm.schemaOrg(\"hasPart\").getLabel());\r\n+    if (o == null) {\r\n+      return new JsonArray();\r\n+    } else {\r\n+      if (o.isJsonArray()) {\r\n+        return (JsonArray) o;\r\n+      } else if (o.isJsonPrimitive()) {\r\n+        JsonArray children = new JsonArray();\r\n+        children.add(o);\r\n+        return (children);\r\n+      }\r\n+      logger.severe(\"Error finding children: \" + o.toString());\r\n+      return new JsonArray();\r\n+    }\r\n+  }\r\n \r\n-    // Logic to decide if this is a container -\r\n-    // first check for children, then check for source-specific type indicators\r\n-    private static boolean childIsContainer(JsonObject item) {\r\n-        if (getChildren(item).size() != 0) {\r\n+  // Logic to decide if this is a container -\r\n+  // first check for children, then check for source-specific type indicators\r\n+  private static boolean childIsContainer(JsonObject item) {\r\n+    if (getChildren(item).size() != 0) {\r\n+      return true;\r\n+    }\r\n+    // Also check for any indicative type\r\n+    Object o = item.get(\"@type\");\r\n+    if (o != null) {\r\n+      if (o instanceof JSONArray) {\r\n+        // As part of an array\r\n+        for (int i = 0; i < ((JSONArray) o).length(); i++) {\r\n+          String type = ((JSONArray) o).getString(i).trim();\r\n+          if (\"http://cet.ncsa.uiuc.edu/2016/Folder\".equals(type)) {\r\n             return true;\r\n+          }\r\n         }\r\n-        // Also check for any indicative type\r\n-        Object o = item.get(\"@type\");\r\n-        if (o != null) {\r\n-            if (o instanceof JSONArray) {\r\n-                // As part of an array\r\n-                for (int i = 0; i < ((JSONArray) o).length(); i++) {\r\n-                    String type = ((JSONArray) o).getString(i).trim();\r\n-                    if (\"http://cet.ncsa.uiuc.edu/2016/Folder\".equals(type)) {\r\n-                        return true;\r\n-                    }\r\n-                }\r\n-            } else if (o instanceof String) {\r\n-                // Or as the only type\r\n-                String type = ((String) o).trim();\r\n-                if (\"http://cet.ncsa.uiuc.edu/2016/Folder\".equals(type)) {\r\n-                    return true;\r\n-                }\r\n-            }\r\n+      } else if (o instanceof String) {\r\n+        // Or as the only type\r\n+        String type = ((String) o).trim();\r\n+        if (\"http://cet.ncsa.uiuc.edu/2016/Folder\".equals(type)) {\r\n+          return true;\r\n         }\r\n-        return false;\r\n+      }\r\n     }\r\n-\r\n-    public String getBagPath() {\r\n-        return bagPath;\r\n+    return false;\r\n+  }\r\n+\r\n+  public String getBagPath() {\r\n+    return bagPath;\r\n+  }\r\n+\r\n+  public void setBagPath(String bagPath) {\r\n+    this.bagPath = bagPath;\r\n+  }\r\n+\r\n+  private HttpGet createNewGetRequest(URI url, String returnType) {\r\n+\r\n+    HttpGet request = null;\r\n+\r\n+    if (apiKey != null) {\r\n+      try {\r\n+        String urlString = url.toURL().toString();\r\n+        // Add key as param - check whether it is the only param or not\r\n+        urlString = urlString + ((urlString.indexOf('?') != -1) ? \"&key=\" : \"?key=\") + apiKey;\r\n+        request = new HttpGet(new URI(urlString));\r\n+      } catch (MalformedURLException e) {\r\n+        // TODO Auto-generated catch block\r\n+        e.printStackTrace();\r\n+      } catch (URISyntaxException e) {\r\n+        // TODO Auto-generated catch block\r\n+        e.printStackTrace();\r\n+      }\r\n+    } else {\r\n+      request = new HttpGet(url);\r\n     }\r\n-\r\n-    public void setBagPath(String bagPath) {\r\n-        this.bagPath = bagPath;\r\n+    if (returnType != null) {\r\n+      request.addHeader(\"accept\", returnType);\r\n     }\r\n-\r\n-    private HttpGet createNewGetRequest(URI url, String returnType) {\r\n-\r\n-        HttpGet request = null;\r\n-\r\n-        if (apiKey != null) {\r\n-            try {\r\n-                String urlString = url.toURL().toString();\r\n-                // Add key as param - check whether it is the only param or not\r\n-                urlString = urlString + ((urlString.indexOf('?') != -1) ? \"&key=\" : \"?key=\") + apiKey;\r\n-                request = new HttpGet(new URI(urlString));\r\n-            } catch (MalformedURLException e) {\r\n-                // TODO Auto-generated catch block\r\n-                e.printStackTrace();\r\n-            } catch (URISyntaxException e) {\r\n-                // TODO Auto-generated catch block\r\n-                e.printStackTrace();\r\n+    return request;\r\n+  }\r\n+\r\n+  InputStreamSupplier getInputStreamSupplier(final String uri) {\r\n+\r\n+    return new InputStreamSupplier() {\r\n+      public InputStream get() {\r\n+        int tries = 0;\r\n+        while (tries < 5) {\r\n+          try {\r\n+            logger.fine(\"Get # \" + tries + \" for \" + uri);\r\n+            HttpGet getMap = createNewGetRequest(new URI(uri), null);\r\n+            logger.finest(\"Retrieving \" + tries + \": \" + uri);\r\n+            CloseableHttpResponse response;\r\n+            //Note - if we ever need to pass an HttpClientContext, we need a new one per thread.\r\n+            response = client.execute(getMap);\r\n+            if (response.getStatusLine().getStatusCode() == 200) {\r\n+              logger.finest(\"Retrieved: \" + uri);\r\n+              return response.getEntity().getContent();\r\n             }\r\n-        } else {\r\n-            request = new HttpGet(url);\r\n-        }\r\n-        if (returnType != null) {\r\n-            request.addHeader(\"accept\", returnType);\r\n-        }\r\n-        return request;\r\n-    }\r\n+            logger.fine(\"Status: \" + response.getStatusLine().getStatusCode());\r\n+            tries++;\r\n \r\n-    InputStreamSupplier getInputStreamSupplier(final String uri) {\r\n-\r\n-        return new InputStreamSupplier() {\r\n-            public InputStream get() {\r\n-                int tries = 0;\r\n-                while (tries < 5) {\r\n-                    try {\r\n-                        logger.fine(\"Get # \" + tries + \" for \" + uri);\r\n-                        HttpGet getMap = createNewGetRequest(new URI(uri), null);\r\n-                        logger.finest(\"Retrieving \" + tries + \": \" + uri);\r\n-                        CloseableHttpResponse response;\r\n-                        //Note - if we ever need to pass an HttpClientContext, we need a new one per thread.\r\n-                        response = client.execute(getMap);\r\n-                        if (response.getStatusLine().getStatusCode() == 200) {\r\n-                            logger.finest(\"Retrieved: \" + uri);\r\n-                            return response.getEntity().getContent();\r\n-                        }\r\n-                        logger.fine(\"Status: \" + response.getStatusLine().getStatusCode());\r\n-                        tries++;\r\n-\r\n-                    } catch (ClientProtocolException e) {\r\n-                        tries += 5;\r\n-                        // TODO Auto-generated catch block\r\n-                        e.printStackTrace();\r\n-                    } catch (IOException e) {\r\n-                        // Retry if this is a potentially temporary error such\r\n-                        // as a timeout\r\n-                        tries++;\r\n-                        logger.log(Level.WARNING,\"Attempt# \" + tries + \" : Unable to retrieve file: \" + uri, e);\r\n-                        if (tries == 5) {\r\n-                            logger.severe(\"Final attempt failed for \" + uri);\r\n-                        }\r\n-                        e.printStackTrace();\r\n-                    } catch (URISyntaxException e) {\r\n-                        tries += 5;\r\n-                        // TODO Auto-generated catch block\r\n-                        e.printStackTrace();\r\n-                    }\r\n-                }\r\n-                logger.severe(\"Could not read: \" + uri);\r\n-                return null;\r\n+          } catch (ClientProtocolException e) {\r\n+            tries += 5;\r\n+            // TODO Auto-generated catch block\r\n+            e.printStackTrace();\r\n+          } catch (IOException e) {\r\n+            // Retry if this is a potentially temporary error such\r\n+            // as a timeout\r\n+            tries++;\r\n+            logger.log(Level.WARNING, \"Attempt# \" + tries + \" : Unable to retrieve file: \" + uri, e);\r\n+            if (tries == 5) {\r\n+              logger.severe(\"Final attempt failed for \" + uri);\r\n             }\r\n-        };\r\n-    }\r\n-\r\n-    /**\r\n-     * Adapted from org/apache/commons/io/FileUtils.java change to SI - add 2 digits\r\n-     * of precision\r\n-     */\r\n-    /**\r\n-     * The number of bytes in a kilobyte.\r\n-     */\r\n-    public static final long ONE_KB = 1000;\r\n-\r\n-    /**\r\n-     * The number of bytes in a megabyte.\r\n-     */\r\n-    public static final long ONE_MB = ONE_KB * ONE_KB;\r\n-\r\n-    /**\r\n-     * The number of bytes in a gigabyte.\r\n-     */\r\n-    public static final long ONE_GB = ONE_KB * ONE_MB;\r\n-\r\n-    /**\r\n-     * Returns a human-readable version of the file size, where the input represents\r\n-     * a specific number of bytes.\r\n-     *\r\n-     * @param size\r\n-     *            the number of bytes\r\n-     * @return a human-readable display value (includes units)\r\n-     */\r\n-    public static String byteCountToDisplaySize(long size) {\r\n-        String displaySize;\r\n-\r\n-        if (size / ONE_GB > 0) {\r\n-            displaySize = String.valueOf(Math.round(size / (ONE_GB / 100.0d)) / 100.0) + \" GB\";\r\n-        } else if (size / ONE_MB > 0) {\r\n-            displaySize = String.valueOf(Math.round(size / (ONE_MB / 100.0d)) / 100.0) + \" MB\";\r\n-        } else if (size / ONE_KB > 0) {\r\n-            displaySize = String.valueOf(Math.round(size / (ONE_KB / 100.0d)) / 100.0) + \" KB\";\r\n-        } else {\r\n-            displaySize = String.valueOf(size) + \" bytes\";\r\n+            e.printStackTrace();\r\n+          } catch (URISyntaxException e) {\r\n+            tries += 5;\r\n+            // TODO Auto-generated catch block\r\n+            e.printStackTrace();\r\n+          }\r\n         }\r\n-        return displaySize;\r\n+        logger.severe(\"Could not read: \" + uri);\r\n+        return null;\r\n+      }\r\n+    };\r\n+  }\r\n+\r\n+  /**\r\n+   * Adapted from org/apache/commons/io/FileUtils.java change to SI - add 2 digits\r\n+   * of precision\r\n+   */\r\n+  /**\r\n+   * The number of bytes in a kilobyte.\r\n+   */\r\n+  public static final long ONE_KB = 1000;\r\n+\r\n+  /**\r\n+   * The number of bytes in a megabyte.\r\n+   */\r\n+  public static final long ONE_MB = ONE_KB * ONE_KB;\r\n+\r\n+  /**\r\n+   * The number of bytes in a gigabyte.\r\n+   */\r\n+  public static final long ONE_GB = ONE_KB * ONE_MB;\r\n+\r\n+  /**\r\n+   * Returns a human-readable version of the file size, where the input represents\r\n+   * a specific number of bytes.\r\n+   *\r\n+   * @param size the number of bytes\r\n+   * @return a human-readable display value (includes units)\r\n+   */\r\n+  public static String byteCountToDisplaySize(long size) {\r\n+    String displaySize;\r\n+\r\n+    if (size / ONE_GB > 0) {\r\n+      displaySize = String.valueOf(Math.round(size / (ONE_GB / 100.0d)) / 100.0) + \" GB\";\r\n+    } else if (size / ONE_MB > 0) {\r\n+      displaySize = String.valueOf(Math.round(size / (ONE_MB / 100.0d)) / 100.0) + \" MB\";\r\n+    } else if (size / ONE_KB > 0) {\r\n+      displaySize = String.valueOf(Math.round(size / (ONE_KB / 100.0d)) / 100.0) + \" KB\";\r\n+    } else {\r\n+      displaySize = String.valueOf(size) + \" bytes\";\r\n     }\r\n+    return displaySize;\r\n+  }\r\n \r\n-    public void setAuthenticationKey(String tokenString) {\r\n-        apiKey = tokenString;\r\n-    }\r\n+  public void setAuthenticationKey(String tokenString) {\r\n+    apiKey = tokenString;\r\n+  }\r\n \r\n }\n\\ No newline at end of file\n",
            "diff_size": 1454
        },
        {
            "tool": "naturalize",
            "errors": null,
            "diff": null
        },
        {
            "tool": "codebuff",
            "errors": null,
            "diff": null
        },
        {
            "tool": "styler_random",
            "errors": [],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/IQSS-dataverse/errored/1/29/BagGenerator.java b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/IQSS-dataverse/styler_random/29/BagGenerator.java\nindex 7c3db485e47..24eaec574d7 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/IQSS-dataverse/errored/1/29/BagGenerator.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/IQSS-dataverse/styler_random/29/BagGenerator.java\n@@ -158,7 +158,7 @@ public class BagGenerator {\n             SSLConnectionSocketFactory sslConnectionFactory = new SSLConnectionSocketFactory(builder.build(), NoopHostnameVerifier.INSTANCE);\r\n \r\n             Registry<ConnectionSocketFactory> registry = RegistryBuilder.<ConnectionSocketFactory>create()\r\n-            \t\t.register(\"http\", PlainConnectionSocketFactory.getSocketFactory())\r\n+    .register(\"http\", PlainConnectionSocketFactory.getSocketFactory())\r\n                     .register(\"https\", sslConnectionFactory).build();\r\n             cm = new PoolingHttpClientConnectionManager(registry);\r\n \r\n",
            "diff_size": 1
        },
        {
            "tool": "styler_three_grams",
            "errors": [],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/IQSS-dataverse/errored/1/29/BagGenerator.java b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/IQSS-dataverse/styler_three_grams/29/BagGenerator.java\nindex 7c3db485e47..4617c34f598 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/IQSS-dataverse/errored/1/29/BagGenerator.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/IQSS-dataverse/styler_three_grams/29/BagGenerator.java\n@@ -157,8 +157,7 @@ public class BagGenerator {\n \r\n             SSLConnectionSocketFactory sslConnectionFactory = new SSLConnectionSocketFactory(builder.build(), NoopHostnameVerifier.INSTANCE);\r\n \r\n-            Registry<ConnectionSocketFactory> registry = RegistryBuilder.<ConnectionSocketFactory>create()\r\n-            \t\t.register(\"http\", PlainConnectionSocketFactory.getSocketFactory())\r\n+            Registry<ConnectionSocketFactory> registry = RegistryBuilder.<ConnectionSocketFactory>create().register(\"http\", PlainConnectionSocketFactory.getSocketFactory())\r\n                     .register(\"https\", sslConnectionFactory).build();\r\n             cm = new PoolingHttpClientConnectionManager(registry);\r\n \r\n",
            "diff_size": 2
        }
    ],
    "repaired_by": [
        "styler",
        "intellij",
        "styler_random",
        "styler_three_grams"
    ],
    "not_repaired_by": [
        "naturalize",
        "codebuff"
    ]
}