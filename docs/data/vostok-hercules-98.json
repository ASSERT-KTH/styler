{
    "project_name": "vostok-hercules",
    "error_id": "98",
    "information": {
        "errors": [
            {
                "line": "177",
                "column": "52",
                "severity": "warning",
                "message": "'{' is not followed by whitespace.",
                "source": "com.puppycrawl.tools.checkstyle.checks.whitespace.WhitespaceAroundCheck"
            }
        ]
    },
    "source_code": "                            for (ConsumerRecord<UUID, Event> record : records) {\n                                Event event = record.value();\n                                if (event == null) {// Received non-deserializable data, should be ignored\n                                    droppedEvents++;\n                                    continue;\n                                }",
    "results": [
        {
            "tool": "styler",
            "errors": [],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/vostok-hercules/errored/1/98/Sink.java b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/vostok-hercules/styler/98/Sink.java\nindex 5007f1b9644..59719d2ee57 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/vostok-hercules/errored/1/98/Sink.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/vostok-hercules/styler/98/Sink.java\n@@ -174,7 +174,7 @@ public class Sink {\n                             List<ConsumerRecord<UUID, Event>> records = pollResult.records(partition);\n                             for (ConsumerRecord<UUID, Event> record : records) {\n                                 Event event = record.value();\n-                                if (event == null) {// Received non-deserializable data, should be ignored\n+                                if (event == null) { // Received non-deserializable data, should be ignored\n                                     droppedEvents++;\n                                     continue;\n                                 }\n",
            "diff_size": 1
        },
        {
            "tool": "intellij",
            "errors": [
                {
                    "line": "177",
                    "column": "36",
                    "severity": "warning",
                    "message": "'{' is not followed by whitespace.",
                    "source": "com.puppycrawl.tools.checkstyle.checks.whitespace.WhitespaceAroundCheck"
                }
            ],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/vostok-hercules/errored/1/98/Sink.java b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/vostok-hercules/intellij/98/Sink.java\nindex 5007f1b9644..8c666791e70 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/vostok-hercules/errored/1/98/Sink.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/vostok-hercules/intellij/98/Sink.java\n@@ -36,253 +36,253 @@ import java.util.regex.Pattern;\n  * @author Gregory Koshelev\n  */\n public class Sink {\n-    private static final Logger LOGGER = LoggerFactory.getLogger(Sink.class);\n-\n-    private volatile boolean running = false;\n-\n-    private final ExecutorService executor;\n-    private final Processor processor;\n-\n-    private final List<EventFilter> filters;\n-\n-    private final Duration pollTimeout;\n-    private final int batchSize;\n-    private final long availabilityTimeoutMs;\n-\n-    private final Pattern pattern;\n-    private final KafkaConsumer<UUID, Event> consumer;\n-\n-    private final Meter droppedEventsMeter;\n-    private final Meter filteredEventsMeter;\n-    private final Meter processedEventsMeter;\n-    private final Meter rejectedEventsMeter;\n-    private final Meter totalEventsMeter;\n-\n-    public Sink(\n-            ExecutorService executor,\n-            String applicationId,\n-            Properties properties,\n-            Processor processor,\n-            List<PatternMatcher> patternMatchers,\n-            EventDeserializer deserializer,\n-            MetricsCollector metricsCollector) {\n-        this.executor = executor;\n-        this.processor = processor;\n-\n-        this.filters = EventFilter.from(PropertiesUtil.ofScope(properties, \"filter\"));\n-\n-        this.pollTimeout = Duration.ofMillis(PropertiesUtil.get(Props.POLL_TIMEOUT_MS, properties).get());\n-        this.batchSize = PropertiesUtil.get(Props.BATCH_SIZE, properties).get();\n-        this.availabilityTimeoutMs = PropertiesUtil.get(Props.AVAILABILITY_TIMEOUT_MS, properties).get();\n-\n-        String consumerGroupId =\n-                PropertiesUtil.get(Props.GROUP_ID, properties).\n-                        orEmpty(ConsumerUtil.toGroupId(applicationId, patternMatchers));\n-\n-        this.pattern = PatternMatcher.matcherListToRegexp(patternMatchers);\n-\n-        Properties consumerProperties = PropertiesUtil.ofScope(properties, Scopes.CONSUMER);\n-        consumerProperties.put(ConsumerConfig.GROUP_ID_CONFIG, consumerGroupId);\n-        consumerProperties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);\n-        consumerProperties.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, batchSize);\n-        consumerProperties.put(KafkaConfigs.METRICS_COLLECTOR_INSTANCE_CONFIG, metricsCollector);\n-\n-        UuidDeserializer keyDeserializer = new UuidDeserializer();\n-        EventDeserializer valueDeserializer = deserializer;\n-\n-        this.consumer = new KafkaConsumer<>(consumerProperties, keyDeserializer, valueDeserializer);\n-\n-        droppedEventsMeter = metricsCollector.meter(\"droppedEvents\");\n-        filteredEventsMeter = metricsCollector.meter(\"filteredEvents\");\n-        processedEventsMeter = metricsCollector.meter(\"processedEvents\");\n-        rejectedEventsMeter = metricsCollector.meter(\"rejectedEvents\");\n-        totalEventsMeter = metricsCollector.meter(\"totalEvents\");\n+  private static final Logger LOGGER = LoggerFactory.getLogger(Sink.class);\n+\n+  private volatile boolean running = false;\n+\n+  private final ExecutorService executor;\n+  private final Processor processor;\n+\n+  private final List<EventFilter> filters;\n+\n+  private final Duration pollTimeout;\n+  private final int batchSize;\n+  private final long availabilityTimeoutMs;\n+\n+  private final Pattern pattern;\n+  private final KafkaConsumer<UUID, Event> consumer;\n+\n+  private final Meter droppedEventsMeter;\n+  private final Meter filteredEventsMeter;\n+  private final Meter processedEventsMeter;\n+  private final Meter rejectedEventsMeter;\n+  private final Meter totalEventsMeter;\n+\n+  public Sink(\n+    ExecutorService executor,\n+    String applicationId,\n+    Properties properties,\n+    Processor processor,\n+    List<PatternMatcher> patternMatchers,\n+    EventDeserializer deserializer,\n+    MetricsCollector metricsCollector) {\n+    this.executor = executor;\n+    this.processor = processor;\n+\n+    this.filters = EventFilter.from(PropertiesUtil.ofScope(properties, \"filter\"));\n+\n+    this.pollTimeout = Duration.ofMillis(PropertiesUtil.get(Props.POLL_TIMEOUT_MS, properties).get());\n+    this.batchSize = PropertiesUtil.get(Props.BATCH_SIZE, properties).get();\n+    this.availabilityTimeoutMs = PropertiesUtil.get(Props.AVAILABILITY_TIMEOUT_MS, properties).get();\n+\n+    String consumerGroupId =\n+      PropertiesUtil.get(Props.GROUP_ID, properties).\n+        orEmpty(ConsumerUtil.toGroupId(applicationId, patternMatchers));\n+\n+    this.pattern = PatternMatcher.matcherListToRegexp(patternMatchers);\n+\n+    Properties consumerProperties = PropertiesUtil.ofScope(properties, Scopes.CONSUMER);\n+    consumerProperties.put(ConsumerConfig.GROUP_ID_CONFIG, consumerGroupId);\n+    consumerProperties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);\n+    consumerProperties.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, batchSize);\n+    consumerProperties.put(KafkaConfigs.METRICS_COLLECTOR_INSTANCE_CONFIG, metricsCollector);\n+\n+    UuidDeserializer keyDeserializer = new UuidDeserializer();\n+    EventDeserializer valueDeserializer = deserializer;\n+\n+    this.consumer = new KafkaConsumer<>(consumerProperties, keyDeserializer, valueDeserializer);\n+\n+    droppedEventsMeter = metricsCollector.meter(\"droppedEvents\");\n+    filteredEventsMeter = metricsCollector.meter(\"filteredEvents\");\n+    processedEventsMeter = metricsCollector.meter(\"processedEvents\");\n+    rejectedEventsMeter = metricsCollector.meter(\"rejectedEvents\");\n+    totalEventsMeter = metricsCollector.meter(\"totalEvents\");\n+  }\n+\n+  /**\n+   * Start sink.\n+   */\n+  public final void start() {\n+    running = true;\n+\n+    executor.execute(this::run);\n+  }\n+\n+  /**\n+   * Stop Sink.\n+   */\n+  public final void stop() {\n+    running = false;\n+\n+    try {\n+      consumer.wakeup();\n+    } catch (Exception ex) {\n+      /* ignore */\n     }\n \n-    /**\n-     * Start sink.\n-     */\n-    public final void start() {\n-        running = true;\n-\n-        executor.execute(this::run);\n+    try {\n+      consumer.close();\n+    } catch (Exception ex) {\n+      /* ignore */\n     }\n \n-    /**\n-     * Stop Sink.\n-     */\n-    public final void stop() {\n-        running = false;\n-\n+    postStop();\n+  }\n+\n+  /**\n+   * Check Sink running status.\n+   *\n+   * @return {@code true} if Sink is running and {@code false} if Sink is stopping\n+   */\n+  public final boolean isRunning() {\n+    return running;\n+  }\n+\n+  /**\n+   * Main Sink logic. Sink poll events from Kafka and processes them using {@link Processor} if possible.\n+   * <p>\n+   * Sink awaits availability of {@link Processor}. Also, it controls {@link #isRunning()} during operations.\n+   */\n+  public final void run() {\n+    while (isRunning()) {\n+      if (processor.isAvailable()) {\n         try {\n-            consumer.wakeup();\n-        } catch (Exception ex) {\n-            /* ignore */\n-        }\n-\n-        try {\n-            consumer.close();\n-        } catch (Exception ex) {\n-            /* ignore */\n-        }\n \n-        postStop();\n-    }\n-\n-    /**\n-     * Check Sink running status.\n-     *\n-     * @return {@code true} if Sink is running and {@code false} if Sink is stopping\n-     */\n-    public final boolean isRunning() {\n-        return running;\n-    }\n-\n-    /**\n-     * Main Sink logic. Sink poll events from Kafka and processes them using {@link Processor} if possible.\n-     * <p>\n-     * Sink awaits availability of {@link Processor}. Also, it controls {@link #isRunning()} during operations.\n-     */\n-    public final void run() {\n-        while (isRunning()) {\n-            if (processor.isAvailable()) {\n-                try {\n-\n-                    subscribe();\n-\n-                    while (processor.isAvailable()) {\n-                        ConsumerRecords<UUID, Event> pollResult;\n-                        try {\n-                            pollResult = poll();\n-                        } catch (WakeupException ex) {\n-                            /*\n-                             * WakeupException is used to terminate polling\n-                             */\n-                            return;\n-                        }\n-\n-                        Set<TopicPartition> partitions = pollResult.partitions();\n-\n-                        // ConsumerRecords::count works for O(n), where n is partition count\n-                        int eventCount = pollResult.count();\n-                        List<Event> events = new ArrayList<>(eventCount);\n-\n-                        int droppedEvents = 0;\n-                        int filteredEvents = 0;\n-\n-                        for (TopicPartition partition : partitions) {\n-                            List<ConsumerRecord<UUID, Event>> records = pollResult.records(partition);\n-                            for (ConsumerRecord<UUID, Event> record : records) {\n-                                Event event = record.value();\n-                                if (event == null) {// Received non-deserializable data, should be ignored\n-                                    droppedEvents++;\n-                                    continue;\n-                                }\n-                                if (!filter(event)) {\n-                                    filteredEvents++;\n-                                    continue;\n-                                }\n-                                events.add(event);\n-                            }\n-                        }\n-\n-                        ProcessorResult result = processor.process(events);\n-                        if (result.isSuccess()) {\n-                            try {\n-                                commit();\n-                                droppedEventsMeter.mark(droppedEvents);\n-                                filteredEventsMeter.mark(filteredEvents);\n-                                processedEventsMeter.mark(result.getProcessedEvents());\n-                                rejectedEventsMeter.mark(result.getRejectedEvents());\n-                                totalEventsMeter.mark(events.size());\n-                            } catch (CommitFailedException ex) {\n-                                LOGGER.warn(\"Commit failed due to rebalancing\", ex);\n-                                continue;\n-                            }\n-                        }\n-                    }\n-                } catch (Exception ex) {\n-                    LOGGER.error(\"Unspecified exception has been acquired\", ex);\n-                } finally {\n-                    unsubscribe();\n-                }\n+          subscribe();\n+\n+          while (processor.isAvailable()) {\n+            ConsumerRecords<UUID, Event> pollResult;\n+            try {\n+              pollResult = poll();\n+            } catch (WakeupException ex) {\n+              /*\n+               * WakeupException is used to terminate polling\n+               */\n+              return;\n             }\n \n-            processor.awaitAvailability(availabilityTimeoutMs);\n-        }\n-    }\n+            Set<TopicPartition> partitions = pollResult.partitions();\n \n-    /**\n-     * Perform additional stop operations when Event consuming was terminated.\n-     */\n-    protected void postStop() {\n+            // ConsumerRecords::count works for O(n), where n is partition count\n+            int eventCount = pollResult.count();\n+            List<Event> events = new ArrayList<>(eventCount);\n \n-    }\n+            int droppedEvents = 0;\n+            int filteredEvents = 0;\n \n-    /**\n-     * Subscribe Sink. Should be called before polling\n-     */\n-    protected final void subscribe() {\n-        consumer.subscribe(pattern);\n-    }\n+            for (TopicPartition partition : partitions) {\n+              List<ConsumerRecord<UUID, Event>> records = pollResult.records(partition);\n+              for (ConsumerRecord<UUID, Event> record : records) {\n+                Event event = record.value();\n+                if (event == null) {// Received non-deserializable data, should be ignored\n+                  droppedEvents++;\n+                  continue;\n+                }\n+                if (!filter(event)) {\n+                  filteredEvents++;\n+                  continue;\n+                }\n+                events.add(event);\n+              }\n+            }\n \n-    /**\n-     * Unsubscribe Sink. Should be called if Sink cannot process Events.\n-     */\n-    protected final void unsubscribe() {\n-        LOGGER.debug(\"Sink unsubscribe if any\");\n-        try {\n-            consumer.unsubscribe();\n+            ProcessorResult result = processor.process(events);\n+            if (result.isSuccess()) {\n+              try {\n+                commit();\n+                droppedEventsMeter.mark(droppedEvents);\n+                filteredEventsMeter.mark(filteredEvents);\n+                processedEventsMeter.mark(result.getProcessedEvents());\n+                rejectedEventsMeter.mark(result.getRejectedEvents());\n+                totalEventsMeter.mark(events.size());\n+              } catch (CommitFailedException ex) {\n+                LOGGER.warn(\"Commit failed due to rebalancing\", ex);\n+                continue;\n+              }\n+            }\n+          }\n         } catch (Exception ex) {\n-            /* ignore */\n+          LOGGER.error(\"Unspecified exception has been acquired\", ex);\n+        } finally {\n+          unsubscribe();\n         }\n-    }\n+      }\n \n-    /**\n-     * Poll Events from Kafka. Should be called when Sink subscribed.\n-     *\n-     * @return polled Events\n-     * @throws WakeupException if poll terminated due to shutdown\n-     */\n-    protected final ConsumerRecords<UUID, Event> poll() throws WakeupException {\n-        return consumer.poll(pollTimeout);\n+      processor.awaitAvailability(availabilityTimeoutMs);\n     }\n-\n-    protected final void commit() {\n-        consumer.commitSync();\n-    }\n-\n-    protected final void commit(Map<TopicPartition, OffsetAndMetadata> offsets) {\n-        consumer.commitSync(offsets);\n+  }\n+\n+  /**\n+   * Perform additional stop operations when Event consuming was terminated.\n+   */\n+  protected void postStop() {\n+\n+  }\n+\n+  /**\n+   * Subscribe Sink. Should be called before polling\n+   */\n+  protected final void subscribe() {\n+    consumer.subscribe(pattern);\n+  }\n+\n+  /**\n+   * Unsubscribe Sink. Should be called if Sink cannot process Events.\n+   */\n+  protected final void unsubscribe() {\n+    LOGGER.debug(\"Sink unsubscribe if any\");\n+    try {\n+      consumer.unsubscribe();\n+    } catch (Exception ex) {\n+      /* ignore */\n     }\n-\n-    private boolean filter(Event event) {\n-        for (EventFilter filter : filters) {\n-            if (!filter.test(event)) {\n-                return false;\n-            }\n-        }\n-        return true;\n-    }\n-\n-    private static class Props {\n-        static final Parameter<Long> POLL_TIMEOUT_MS =\n-                Parameter.longParameter(\"pollTimeoutMs\").\n-                        withDefault(6_000L).\n-                        build();\n-\n-        static final Parameter<Integer> BATCH_SIZE =\n-                Parameter.integerParameter(\"batchSize\").\n-                        withDefault(1000).\n-                        build();\n-\n-        static final Parameter<String> GROUP_ID =\n-                Parameter.stringParameter(\"groupId\").\n-                        build();\n-\n-        static final Parameter<Long> AVAILABILITY_TIMEOUT_MS =\n-                Parameter.longParameter(\"availabilityTimeoutMs\").\n-                        withDefault(2_000L).\n-                        build();\n+  }\n+\n+  /**\n+   * Poll Events from Kafka. Should be called when Sink subscribed.\n+   *\n+   * @return polled Events\n+   * @throws WakeupException if poll terminated due to shutdown\n+   */\n+  protected final ConsumerRecords<UUID, Event> poll() throws WakeupException {\n+    return consumer.poll(pollTimeout);\n+  }\n+\n+  protected final void commit() {\n+    consumer.commitSync();\n+  }\n+\n+  protected final void commit(Map<TopicPartition, OffsetAndMetadata> offsets) {\n+    consumer.commitSync(offsets);\n+  }\n+\n+  private boolean filter(Event event) {\n+    for (EventFilter filter : filters) {\n+      if (!filter.test(event)) {\n+        return false;\n+      }\n     }\n+    return true;\n+  }\n+\n+  private static class Props {\n+    static final Parameter<Long> POLL_TIMEOUT_MS =\n+      Parameter.longParameter(\"pollTimeoutMs\").\n+        withDefault(6_000L).\n+        build();\n+\n+    static final Parameter<Integer> BATCH_SIZE =\n+      Parameter.integerParameter(\"batchSize\").\n+        withDefault(1000).\n+        build();\n+\n+    static final Parameter<String> GROUP_ID =\n+      Parameter.stringParameter(\"groupId\").\n+        build();\n+\n+    static final Parameter<Long> AVAILABILITY_TIMEOUT_MS =\n+      Parameter.longParameter(\"availabilityTimeoutMs\").\n+        withDefault(2_000L).\n+        build();\n+  }\n }\n",
            "diff_size": 327
        },
        {
            "tool": "naturalize",
            "errors": [],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/vostok-hercules/errored/1/98/Sink.java b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/vostok-hercules/naturalize/98/Sink.java\nindex 5007f1b9644..945f6d4d003 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/vostok-hercules/errored/1/98/Sink.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/vostok-hercules/naturalize/98/Sink.java\n@@ -66,7 +66,7 @@ public class Sink {\n             List<PatternMatcher> patternMatchers,\n             EventDeserializer deserializer,\n             MetricsCollector metricsCollector) {\n-        this.executor = executor;\n+    this.executor = executor;\n         this.processor = processor;\n \n         this.filters = EventFilter.from(PropertiesUtil.ofScope(properties, \"filter\"));\n@@ -76,10 +76,8 @@ public class Sink {\n         this.availabilityTimeoutMs = PropertiesUtil.get(Props.AVAILABILITY_TIMEOUT_MS, properties).get();\n \n         String consumerGroupId =\n-                PropertiesUtil.get(Props.GROUP_ID, properties).\n-                        orEmpty(ConsumerUtil.toGroupId(applicationId, patternMatchers));\n-\n-        this.pattern = PatternMatcher.matcherListToRegexp(patternMatchers);\n+                PropertiesUtil.get(Props.GROUP_ID, properties).orEmpty(ConsumerUtil.toGroupId(applicationId, patternMatchers));\n+this.pattern = PatternMatcher.matcherListToRegexp(patternMatchers);\n \n         Properties consumerProperties = PropertiesUtil.ofScope(properties, Scopes.CONSUMER);\n         consumerProperties.put(ConsumerConfig.GROUP_ID_CONFIG, consumerGroupId);\n@@ -147,8 +145,7 @@ public class Sink {\n         while (isRunning()) {\n             if (processor.isAvailable()) {\n                 try {\n-\n-                    subscribe();\n+    subscribe();\n \n                     while (processor.isAvailable()) {\n                         ConsumerRecords<UUID, Event> pollResult;\n@@ -174,7 +171,7 @@ public class Sink {\n                             List<ConsumerRecord<UUID, Event>> records = pollResult.records(partition);\n                             for (ConsumerRecord<UUID, Event> record : records) {\n                                 Event event = record.value();\n-                                if (event == null) {// Received non-deserializable data, should be ignored\n+                                if (event == null) { // Received non-deserializable data, should be ignored\n                                     droppedEvents++;\n                                     continue;\n                                 }\n@@ -267,22 +264,15 @@ public class Sink {\n \n     private static class Props {\n         static final Parameter<Long> POLL_TIMEOUT_MS =\n-                Parameter.longParameter(\"pollTimeoutMs\").\n-                        withDefault(6_000L).\n-                        build();\n+                Parameter.longParameter(\"pollTimeoutMs\").withDefault(6_000L).build();\n \n         static final Parameter<Integer> BATCH_SIZE =\n-                Parameter.integerParameter(\"batchSize\").\n-                        withDefault(1000).\n-                        build();\n+                Parameter.integerParameter(\"batchSize\").withDefault(1000).build();\n \n         static final Parameter<String> GROUP_ID =\n-                Parameter.stringParameter(\"groupId\").\n-                        build();\n+                Parameter.stringParameter(\"groupId\").build();\n \n         static final Parameter<Long> AVAILABILITY_TIMEOUT_MS =\n-                Parameter.longParameter(\"availabilityTimeoutMs\").\n-                        withDefault(2_000L).\n-                        build();\n+                Parameter.longParameter(\"availabilityTimeoutMs\").withDefault(2_000L).build();\n     }\n-}\n+}\n\\ No newline at end of file\n",
            "diff_size": 20
        },
        {
            "tool": "codebuff",
            "errors": [
                {
                    "line": "172",
                    "column": "52",
                    "severity": "warning",
                    "message": "'{' is not followed by whitespace.",
                    "source": "com.puppycrawl.tools.checkstyle.checks.whitespace.WhitespaceAroundCheck"
                }
            ],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/vostok-hercules/errored/1/98/Sink.java b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/vostok-hercules/codebuff/98/Sink.java\nindex 5007f1b9644..e85fb40c566 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/vostok-hercules/errored/1/98/Sink.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/vostok-hercules/codebuff/98/Sink.java\n@@ -21,7 +21,6 @@ import ru.kontur.vostok.hercules.sink.filter.EventFilter;\n import ru.kontur.vostok.hercules.util.PatternMatcher;\n import ru.kontur.vostok.hercules.util.parameter.Parameter;\n import ru.kontur.vostok.hercules.util.properties.PropertiesUtil;\n-\n import java.time.Duration;\n import java.util.ArrayList;\n import java.util.List;\n@@ -35,23 +34,20 @@ import java.util.regex.Pattern;\n /**\n  * @author Gregory Koshelev\n  */\n+\n+\n public class Sink {\n-    private static final Logger LOGGER = LoggerFactory.getLogger(Sink.class);\n \n+    private static final Logger LOGGER = LoggerFactory.getLogger(Sink.class);\n     private volatile boolean running = false;\n-\n     private final ExecutorService executor;\n     private final Processor processor;\n-\n     private final List<EventFilter> filters;\n-\n     private final Duration pollTimeout;\n     private final int batchSize;\n     private final long availabilityTimeoutMs;\n-\n     private final Pattern pattern;\n     private final KafkaConsumer<UUID, Event> consumer;\n-\n     private final Meter droppedEventsMeter;\n     private final Meter filteredEventsMeter;\n     private final Meter processedEventsMeter;\n@@ -59,26 +55,25 @@ public class Sink {\n     private final Meter totalEventsMeter;\n \n     public Sink(\n-            ExecutorService executor,\n-            String applicationId,\n-            Properties properties,\n-            Processor processor,\n-            List<PatternMatcher> patternMatchers,\n-            EventDeserializer deserializer,\n-            MetricsCollector metricsCollector) {\n+        ExecutorService executor,\n+        String applicationId,\n+        Properties properties,\n+        Processor processor,\n+        List<PatternMatcher> patternMatchers,\n+        EventDeserializer deserializer, MetricsCollector metricsCollector\n+    ) {\n         this.executor = executor;\n         this.processor = processor;\n-\n         this.filters = EventFilter.from(PropertiesUtil.ofScope(properties, \"filter\"));\n-\n-        this.pollTimeout = Duration.ofMillis(PropertiesUtil.get(Props.POLL_TIMEOUT_MS, properties).get());\n-        this.batchSize = PropertiesUtil.get(Props.BATCH_SIZE, properties).get();\n-        this.availabilityTimeoutMs = PropertiesUtil.get(Props.AVAILABILITY_TIMEOUT_MS, properties).get();\n-\n-        String consumerGroupId =\n-                PropertiesUtil.get(Props.GROUP_ID, properties).\n-                        orEmpty(ConsumerUtil.toGroupId(applicationId, patternMatchers));\n-\n+        this.pollTimeout = Duration.ofMillis(PropertiesUtil.get(Props.POLL_TIMEOUT_MS, properties)\n+        .get());\n+        this.batchSize = PropertiesUtil.get(Props.BATCH_SIZE, properties)\n+        .get();\n+        this.availabilityTimeoutMs = PropertiesUtil.get(Props.AVAILABILITY_TIMEOUT_MS, properties)\n+        .get();\n+\n+        String consumerGroupId = PropertiesUtil.get(Props.GROUP_ID, properties)\n+        .orEmpty(ConsumerUtil.toGroupId(applicationId, patternMatchers));\n         this.pattern = PatternMatcher.matcherListToRegexp(patternMatchers);\n \n         Properties consumerProperties = PropertiesUtil.ofScope(properties, Scopes.CONSUMER);\n@@ -89,9 +84,7 @@ public class Sink {\n \n         UuidDeserializer keyDeserializer = new UuidDeserializer();\n         EventDeserializer valueDeserializer = deserializer;\n-\n         this.consumer = new KafkaConsumer<>(consumerProperties, keyDeserializer, valueDeserializer);\n-\n         droppedEventsMeter = metricsCollector.meter(\"droppedEvents\");\n         filteredEventsMeter = metricsCollector.meter(\"filteredEvents\");\n         processedEventsMeter = metricsCollector.meter(\"processedEvents\");\n@@ -102,15 +95,16 @@ public class Sink {\n     /**\n      * Start sink.\n      */\n+\n     public final void start() {\n         running = true;\n-\n         executor.execute(this::run);\n     }\n \n     /**\n      * Stop Sink.\n      */\n+\n     public final void stop() {\n         running = false;\n \n@@ -118,12 +112,14 @@ public class Sink {\n             consumer.wakeup();\n         } catch (Exception ex) {\n             /* ignore */\n+\n         }\n \n         try {\n             consumer.close();\n         } catch (Exception ex) {\n             /* ignore */\n+\n         }\n \n         postStop();\n@@ -134,6 +130,7 @@ public class Sink {\n      *\n      * @return {@code true} if Sink is running and {@code false} if Sink is stopping\n      */\n+\n     public final boolean isRunning() {\n         return running;\n     }\n@@ -143,11 +140,11 @@ public class Sink {\n      * <p>\n      * Sink awaits availability of {@link Processor}. Also, it controls {@link #isRunning()} during operations.\n      */\n+\n     public final void run() {\n         while (isRunning()) {\n             if (processor.isAvailable()) {\n                 try {\n-\n                     subscribe();\n \n                     while (processor.isAvailable()) {\n@@ -166,10 +163,8 @@ public class Sink {\n                         // ConsumerRecords::count works for O(n), where n is partition count\n                         int eventCount = pollResult.count();\n                         List<Event> events = new ArrayList<>(eventCount);\n-\n                         int droppedEvents = 0;\n                         int filteredEvents = 0;\n-\n                         for (TopicPartition partition : partitions) {\n                             List<ConsumerRecord<UUID, Event>> records = pollResult.records(partition);\n                             for (ConsumerRecord<UUID, Event> record : records) {\n@@ -182,6 +177,7 @@ public class Sink {\n                                     filteredEvents++;\n                                     continue;\n                                 }\n+\n                                 events.add(event);\n                             }\n                         }\n@@ -215,6 +211,7 @@ public class Sink {\n     /**\n      * Perform additional stop operations when Event consuming was terminated.\n      */\n+\n     protected void postStop() {\n \n     }\n@@ -222,6 +219,7 @@ public class Sink {\n     /**\n      * Subscribe Sink. Should be called before polling\n      */\n+\n     protected final void subscribe() {\n         consumer.subscribe(pattern);\n     }\n@@ -229,12 +227,15 @@ public class Sink {\n     /**\n      * Unsubscribe Sink. Should be called if Sink cannot process Events.\n      */\n+\n     protected final void unsubscribe() {\n         LOGGER.debug(\"Sink unsubscribe if any\");\n+\n         try {\n             consumer.unsubscribe();\n         } catch (Exception ex) {\n             /* ignore */\n+\n         }\n     }\n \n@@ -244,6 +245,7 @@ public class Sink {\n      * @return polled Events\n      * @throws WakeupException if poll terminated due to shutdown\n      */\n+\n     protected final ConsumerRecords<UUID, Event> poll() throws WakeupException {\n         return consumer.poll(pollTimeout);\n     }\n@@ -266,23 +268,19 @@ public class Sink {\n     }\n \n     private static class Props {\n-        static final Parameter<Long> POLL_TIMEOUT_MS =\n-                Parameter.longParameter(\"pollTimeoutMs\").\n-                        withDefault(6_000L).\n-                        build();\n-\n-        static final Parameter<Integer> BATCH_SIZE =\n-                Parameter.integerParameter(\"batchSize\").\n-                        withDefault(1000).\n-                        build();\n-\n-        static final Parameter<String> GROUP_ID =\n-                Parameter.stringParameter(\"groupId\").\n-                        build();\n-\n-        static final Parameter<Long> AVAILABILITY_TIMEOUT_MS =\n-                Parameter.longParameter(\"availabilityTimeoutMs\").\n-                        withDefault(2_000L).\n-                        build();\n+        static final Parameter<Long> POLL_TIMEOUT_MS = Parameter.longParameter(\"pollTimeoutMs\")\n+        .withDefault(6_000L)\n+        .build();\n+\n+        static final Parameter<Integer> BATCH_SIZE = Parameter.integerParameter(\"batchSize\")\n+        .withDefault(1000)\n+        .build();\n+\n+        static final Parameter<String> GROUP_ID = Parameter.stringParameter(\"groupId\")\n+        .build();\n+\n+        static final Parameter<Long> AVAILABILITY_TIMEOUT_MS = Parameter.longParameter(\"availabilityTimeoutMs\")\n+        .withDefault(2_000L)\n+        .build();\n     }\n-}\n+}\n\\ No newline at end of file\n",
            "diff_size": 65
        },
        {
            "tool": "styler_random",
            "errors": [],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/vostok-hercules/errored/1/98/Sink.java b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/vostok-hercules/styler_random/98/Sink.java\nindex 5007f1b9644..59719d2ee57 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/vostok-hercules/errored/1/98/Sink.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/vostok-hercules/styler_random/98/Sink.java\n@@ -174,7 +174,7 @@ public class Sink {\n                             List<ConsumerRecord<UUID, Event>> records = pollResult.records(partition);\n                             for (ConsumerRecord<UUID, Event> record : records) {\n                                 Event event = record.value();\n-                                if (event == null) {// Received non-deserializable data, should be ignored\n+                                if (event == null) { // Received non-deserializable data, should be ignored\n                                     droppedEvents++;\n                                     continue;\n                                 }\n",
            "diff_size": 1
        },
        {
            "tool": "styler_three_grams",
            "errors": [],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/vostok-hercules/errored/1/98/Sink.java b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/vostok-hercules/styler_three_grams/98/Sink.java\nindex 5007f1b9644..59719d2ee57 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/vostok-hercules/errored/1/98/Sink.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/vostok-hercules/styler_three_grams/98/Sink.java\n@@ -174,7 +174,7 @@ public class Sink {\n                             List<ConsumerRecord<UUID, Event>> records = pollResult.records(partition);\n                             for (ConsumerRecord<UUID, Event> record : records) {\n                                 Event event = record.value();\n-                                if (event == null) {// Received non-deserializable data, should be ignored\n+                                if (event == null) { // Received non-deserializable data, should be ignored\n                                     droppedEvents++;\n                                     continue;\n                                 }\n",
            "diff_size": 1
        }
    ],
    "repaired_by": [
        "styler",
        "naturalize",
        "styler_random",
        "styler_three_grams"
    ],
    "not_repaired_by": [
        "intellij",
        "codebuff"
    ]
}