{
    "project_name": "IQSS-dataverse",
    "error_id": "21",
    "information": {
        "errors": [
            {
                "line": "1006",
                "column": "1",
                "severity": "error",
                "message": "File contains tab characters (this is the first instance).",
                "source": "com.puppycrawl.tools.checkstyle.checks.whitespace.FileTabCharacterCheck"
            }
        ]
    },
    "source_code": "    \n    public void deleteFromVersion( DatasetVersion d, DataFile f ) {\n\t\tem.createNamedQuery(\"DataFile.removeFromDatasetVersion\")\n\t\t\t.setParameter(\"versionId\", d.getId()).setParameter(\"fileId\", f.getId())\n\t\t\t\t.executeUpdate();\n    }",
    "results": [
        {
            "tool": "styler",
            "errors": [
                {
                    "line": "1007",
                    "column": "1",
                    "severity": "error",
                    "message": "File contains tab characters (this is the first instance).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.whitespace.FileTabCharacterCheck"
                }
            ],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/IQSS-dataverse/errored/1/21/DataFileServiceBean.java b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/IQSS-dataverse/styler/21/DataFileServiceBean.java\nindex 706b8d9f4e5..937859d485b 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/IQSS-dataverse/errored/1/21/DataFileServiceBean.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/IQSS-dataverse/styler/21/DataFileServiceBean.java\n@@ -1003,7 +1003,7 @@ public class DataFileServiceBean implements java.io.Serializable {\n     }\n     \n     public void deleteFromVersion( DatasetVersion d, DataFile f ) {\n-\t\tem.createNamedQuery(\"DataFile.removeFromDatasetVersion\")\n+      em.createNamedQuery(\"DataFile.removeFromDatasetVersion\")\n \t\t\t.setParameter(\"versionId\", d.getId()).setParameter(\"fileId\", f.getId())\n \t\t\t\t.executeUpdate();\n     }\n",
            "diff_size": 1
        },
        {
            "tool": "intellij",
            "errors": [],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/IQSS-dataverse/errored/1/21/DataFileServiceBean.java b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/IQSS-dataverse/intellij/21/DataFileServiceBean.java\nindex 706b8d9f4e5..dc0dc7578db 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/IQSS-dataverse/errored/1/21/DataFileServiceBean.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/IQSS-dataverse/intellij/21/DataFileServiceBean.java\n@@ -41,106 +41,105 @@ import javax.persistence.TypedQuery;\n import org.apache.commons.lang.RandomStringUtils;\n \n /**\n- *\n  * @author Leonid Andreev\n- * \n+ * <p>\n  * Basic skeleton of the new DataFile service for DVN 4.0\n- * \n  */\n \n @Stateless\n @Named\n public class DataFileServiceBean implements java.io.Serializable {\n-    \n-    private static final Logger logger = Logger.getLogger(DataFileServiceBean.class.getCanonicalName());\n-    @EJB\n-    DvObjectServiceBean dvObjectService;\n-    @EJB\n-    PermissionServiceBean permissionService;\n-    @EJB\n-    UserServiceBean userService; \n-    @EJB\n-    SettingsServiceBean settingsService;\n-    \n-    @EJB \n-    IngestServiceBean ingestService;\n-    \n-    @PersistenceContext(unitName = \"VDCNet-ejbPU\")\n-    private EntityManager em;\n-    \n-    // Assorted useful mime types:\n-    \n-    // 3rd-party and/or proprietary tabular data formasts that we know\n-    // how to ingest: \n-    \n-    private static final String MIME_TYPE_STATA = \"application/x-stata\";\n-    private static final String MIME_TYPE_STATA13 = \"application/x-stata-13\";\n-    private static final String MIME_TYPE_RDATA = \"application/x-rlang-transport\";\n-    private static final String MIME_TYPE_CSV   = \"text/csv\";\n-    private static final String MIME_TYPE_CSV_ALT = \"text/comma-separated-values\";\n-    private static final String MIME_TYPE_TSV   = \"text/tsv\";\n-    public static final String MIME_TYPE_TSV_ALT   = \"text/tab-separated-values\";\n-    private static final String MIME_TYPE_XLSX  = \"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\";\n-    private static final String MIME_TYPE_SPSS_SAV = \"application/x-spss-sav\";\n-    private static final String MIME_TYPE_SPSS_POR = \"application/x-spss-por\";\n-    \n-    // Tabular data formats we don't know how to ingets, but still recognize\n-    // as \"tabular data\":\n-    // TODO: - add more to this list? -- L.A. 4.0 beta13\n-    \n-    private static final String MIME_TYPE_FIXED_FIELD = \"text/x-fixed-field\";\n-    private static final String MIME_TYPE_SAS_TRANSPORT = \"application/x-sas-transport\";\n-    private static final String MIME_TYPE_SAS_SYSTEM = \"application/x-sas-system\";\n-    \n-    // The following are the \"control card/syntax\" formats that we recognize \n-    // as \"code\":\n-    \n-    private static final String MIME_TYPE_R_SYNTAX = \"application/x-r-syntax\";\n-    private static final String MIME_TYPE_STATA_SYNTAX = \"text/x-stata-syntax\";\n-    private static final String MIME_TYPE_SPSS_CCARD = \"text/x-spss-syntax\";\n-    private static final String MIME_TYPE_SAS_SYNTAX = \"text/x-sas-syntax\";\n-\n-    // The types recognized as \"documents\":\n-    // TODO: there has to be more! -- L.A. 4.0 beta13\n-    \n-    private static final String MIME_TYPE_PLAIN_TEXT = \"text/plain\";\n-    private static final String MIME_TYPE_DOCUMENT_PDF = \"application/pdf\";\n-    private static final String MIME_TYPE_DOCUMENT_MSWORD = \"application/msword\";\n-    private static final String MIME_TYPE_DOCUMENT_MSEXCEL = \"application/vnd.ms-excel\";\n-    private static final String MIME_TYPE_DOCUMENT_MSWORD_OPENXML = \"application/vnd.openxmlformats-officedocument.wordprocessingml.document\";\n-    \n-    // Supported Astrophysics formats: \n-    // (only FITS at this point)\n-    \n-    private static final String MIME_TYPE_FITS  = \"application/fits\";\n \n-    // Network Data files: \n-    // (only GRAPHML at this point): \n-    \n-    private static final String MIME_TYPE_NETWORK_GRAPHML = \"text/xml-graphml\";\n-   \n-    // SHAPE file type: \n-    // this is the only supported file type in the GEO DATA class:\n-        \n-    private static final String MIME_TYPE_ZIP   = \"application/zip\";\n-    \n-    private static final String MIME_TYPE_UNDETERMINED_DEFAULT = \"application/octet-stream\";\n-    private static final String MIME_TYPE_UNDETERMINED_BINARY = \"application/binary\";\n-\n-    /**\n-     * Per https://en.wikipedia.org/wiki/Media_type#Vendor_tree just \"dataverse\"\n-     * should be fine.\n-     *\n-     * @todo Consider registering this at http://www.iana.org/form/media-types\n-     * or switch to \"prs\" which \"includes media types created experimentally or\n-     * as part of products that are not distributed commercially\" according to\n-     * the page URL above.\n-     */\n-    public static final String MIME_TYPE_PACKAGE_FILE = \"application/vnd.dataverse.file-package\";\n-    \n-    public DataFile find(Object pk) {\n-        return em.find(DataFile.class, pk);\n-    }   \n+  private static final Logger logger = Logger.getLogger(DataFileServiceBean.class.getCanonicalName());\n+  @EJB\n+  DvObjectServiceBean dvObjectService;\n+  @EJB\n+  PermissionServiceBean permissionService;\n+  @EJB\n+  UserServiceBean userService;\n+  @EJB\n+  SettingsServiceBean settingsService;\n+\n+  @EJB\n+  IngestServiceBean ingestService;\n+\n+  @PersistenceContext(unitName = \"VDCNet-ejbPU\")\n+  private EntityManager em;\n+\n+  // Assorted useful mime types:\n+\n+  // 3rd-party and/or proprietary tabular data formasts that we know\n+  // how to ingest:\n+\n+  private static final String MIME_TYPE_STATA = \"application/x-stata\";\n+  private static final String MIME_TYPE_STATA13 = \"application/x-stata-13\";\n+  private static final String MIME_TYPE_RDATA = \"application/x-rlang-transport\";\n+  private static final String MIME_TYPE_CSV = \"text/csv\";\n+  private static final String MIME_TYPE_CSV_ALT = \"text/comma-separated-values\";\n+  private static final String MIME_TYPE_TSV = \"text/tsv\";\n+  public static final String MIME_TYPE_TSV_ALT = \"text/tab-separated-values\";\n+  private static final String MIME_TYPE_XLSX = \"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\";\n+  private static final String MIME_TYPE_SPSS_SAV = \"application/x-spss-sav\";\n+  private static final String MIME_TYPE_SPSS_POR = \"application/x-spss-por\";\n+\n+  // Tabular data formats we don't know how to ingets, but still recognize\n+  // as \"tabular data\":\n+  // TODO: - add more to this list? -- L.A. 4.0 beta13\n+\n+  private static final String MIME_TYPE_FIXED_FIELD = \"text/x-fixed-field\";\n+  private static final String MIME_TYPE_SAS_TRANSPORT = \"application/x-sas-transport\";\n+  private static final String MIME_TYPE_SAS_SYSTEM = \"application/x-sas-system\";\n+\n+  // The following are the \"control card/syntax\" formats that we recognize\n+  // as \"code\":\n+\n+  private static final String MIME_TYPE_R_SYNTAX = \"application/x-r-syntax\";\n+  private static final String MIME_TYPE_STATA_SYNTAX = \"text/x-stata-syntax\";\n+  private static final String MIME_TYPE_SPSS_CCARD = \"text/x-spss-syntax\";\n+  private static final String MIME_TYPE_SAS_SYNTAX = \"text/x-sas-syntax\";\n+\n+  // The types recognized as \"documents\":\n+  // TODO: there has to be more! -- L.A. 4.0 beta13\n+\n+  private static final String MIME_TYPE_PLAIN_TEXT = \"text/plain\";\n+  private static final String MIME_TYPE_DOCUMENT_PDF = \"application/pdf\";\n+  private static final String MIME_TYPE_DOCUMENT_MSWORD = \"application/msword\";\n+  private static final String MIME_TYPE_DOCUMENT_MSEXCEL = \"application/vnd.ms-excel\";\n+  private static final String MIME_TYPE_DOCUMENT_MSWORD_OPENXML =\n+    \"application/vnd.openxmlformats-officedocument.wordprocessingml.document\";\n+\n+  // Supported Astrophysics formats:\n+  // (only FITS at this point)\n+\n+  private static final String MIME_TYPE_FITS = \"application/fits\";\n+\n+  // Network Data files:\n+  // (only GRAPHML at this point):\n+\n+  private static final String MIME_TYPE_NETWORK_GRAPHML = \"text/xml-graphml\";\n+\n+  // SHAPE file type:\n+  // this is the only supported file type in the GEO DATA class:\n+\n+  private static final String MIME_TYPE_ZIP = \"application/zip\";\n+\n+  private static final String MIME_TYPE_UNDETERMINED_DEFAULT = \"application/octet-stream\";\n+  private static final String MIME_TYPE_UNDETERMINED_BINARY = \"application/binary\";\n+\n+  /**\n+   * Per https://en.wikipedia.org/wiki/Media_type#Vendor_tree just \"dataverse\"\n+   * should be fine.\n+   *\n+   * @todo Consider registering this at http://www.iana.org/form/media-types\n+   * or switch to \"prs\" which \"includes media types created experimentally or\n+   * as part of products that are not distributed commercially\" according to\n+   * the page URL above.\n+   */\n+  public static final String MIME_TYPE_PACKAGE_FILE = \"application/vnd.dataverse.file-package\";\n+\n+  public DataFile find(Object pk) {\n+    return em.find(DataFile.class, pk);\n+  }\n     \n     /*public DataFile findByMD5(String md5Value){\n         if (md5Value == null){\n@@ -151,242 +150,265 @@ public class DataFileServiceBean implements java.io.Serializable {\n         return (DataFile)query.getSingleResult();\n         \n     }*/\n-    \n-    public DataFile findByGlobalId(String globalId) {\n-            return (DataFile) dvObjectService.findByGlobalId(globalId, DataFile.DATAFILE_DTYPE_STRING);\n-    }\n \n-    public List<DataFile> findByCreatorId(Long creatorId) {\n-        return em.createNamedQuery(\"DataFile.findByCreatorId\").setParameter(\"creatorId\", creatorId).getResultList();\n-    }\n+  public DataFile findByGlobalId(String globalId) {\n+    return (DataFile) dvObjectService.findByGlobalId(globalId, DataFile.DATAFILE_DTYPE_STRING);\n+  }\n \n-    public List<DataFile> findByReleaseUserId(Long releaseUserId) {\n-        return em.createNamedQuery(\"DataFile.findByReleaseUserId\").setParameter(\"releaseUserId\", releaseUserId).getResultList();\n-    }\n+  public List<DataFile> findByCreatorId(Long creatorId) {\n+    return em.createNamedQuery(\"DataFile.findByCreatorId\").setParameter(\"creatorId\", creatorId).getResultList();\n+  }\n \n-    public DataFile findReplacementFile(Long previousFileId){\n-        Query query = em.createQuery(\"select object(o) from DataFile as o where o.previousDataFileId = :previousFileId\");\n-        query.setParameter(\"previousFileId\", previousFileId);\n-        try {\n-            DataFile retVal = (DataFile)query.getSingleResult();\n-            return retVal;\n-        } catch(Exception ex) {\n-            return null;\n-        }\n+  public List<DataFile> findByReleaseUserId(Long releaseUserId) {\n+    return em.createNamedQuery(\"DataFile.findByReleaseUserId\").setParameter(\"releaseUserId\", releaseUserId)\n+      .getResultList();\n+  }\n+\n+  public DataFile findReplacementFile(Long previousFileId) {\n+    Query query = em.createQuery(\"select object(o) from DataFile as o where o.previousDataFileId = :previousFileId\");\n+    query.setParameter(\"previousFileId\", previousFileId);\n+    try {\n+      DataFile retVal = (DataFile) query.getSingleResult();\n+      return retVal;\n+    } catch (Exception ex) {\n+      return null;\n     }\n+  }\n \n-    \n-    public DataFile findPreviousFile(DataFile df){\n-        TypedQuery<DataFile> query = em.createQuery(\"select o from DataFile o\" + \" WHERE o.id = :dataFileId\", DataFile.class);\n-        query.setParameter(\"dataFileId\", df.getPreviousDataFileId());\n-        try {\n-            DataFile retVal = query.getSingleResult();\n-            return retVal;\n-        } catch(Exception ex) {\n-            return null;\n-        }\n+\n+  public DataFile findPreviousFile(DataFile df) {\n+    TypedQuery<DataFile> query =\n+      em.createQuery(\"select o from DataFile o\" + \" WHERE o.id = :dataFileId\", DataFile.class);\n+    query.setParameter(\"dataFileId\", df.getPreviousDataFileId());\n+    try {\n+      DataFile retVal = query.getSingleResult();\n+      return retVal;\n+    } catch (Exception ex) {\n+      return null;\n     }\n-    \n-    public List<DataFile> findByDatasetId(Long studyId) {\n+  }\n+\n+  public List<DataFile> findByDatasetId(Long studyId) {\n         /* \n            Sure, we don't have *studies* any more, in 4.0; it's a tribute \n            to the past. -- L.A.\n         */\n-        String qr = \"select o from DataFile o where o.owner.id = :studyId order by o.id\";\n-        return em.createQuery(qr, DataFile.class)\n-                .setParameter(\"studyId\", studyId).getResultList();\n-    }\n-    \n-    public List<DataFile> findAllRelatedByRootDatafileId(Long datafileId) {\n+    String qr = \"select o from DataFile o where o.owner.id = :studyId order by o.id\";\n+    return em.createQuery(qr, DataFile.class)\n+      .setParameter(\"studyId\", studyId).getResultList();\n+  }\n+\n+  public List<DataFile> findAllRelatedByRootDatafileId(Long datafileId) {\n         /* \n          Get all files with the same root datafile id\n          the first file has its own id as root so only one query needed.\n         */\n-        String qr = \"select o from DataFile o where o.rootDataFileId = :datafileId order by o.id\";\n-        return em.createQuery(qr, DataFile.class)\n-                .setParameter(\"datafileId\", datafileId).getResultList();\n-    }\n-\n-    public DataFile findByStorageIdandDatasetVersion(String storageId, DatasetVersion dv) {\n-        try {\n-            Query query = em.createNativeQuery(\"select o.id from dvobject o, filemetadata m \" +\n-                    \"where o.storageidentifier = '\" + storageId + \"' and o.id = m.datafile_id and m.datasetversion_id = \" +\n-                    dv.getId() + \"\");\n-            query.setMaxResults(1);\n-            if (query.getResultList().size() < 1) {\n-                return null;\n-            } else {\n-                return findCheapAndEasy((Long) query.getSingleResult());\n-                //Pretty sure the above return will always error due to a conversion error\n-                //I \"reverted\" my change because I ended up not using this, but here is the fix below --MAD\n+    String qr = \"select o from DataFile o where o.rootDataFileId = :datafileId order by o.id\";\n+    return em.createQuery(qr, DataFile.class)\n+      .setParameter(\"datafileId\", datafileId).getResultList();\n+  }\n+\n+  public DataFile findByStorageIdandDatasetVersion(String storageId, DatasetVersion dv) {\n+    try {\n+      Query query = em.createNativeQuery(\"select o.id from dvobject o, filemetadata m \" +\n+        \"where o.storageidentifier = '\" + storageId + \"' and o.id = m.datafile_id and m.datasetversion_id = \" +\n+        dv.getId() + \"\");\n+      query.setMaxResults(1);\n+      if (query.getResultList().size() < 1) {\n+        return null;\n+      } else {\n+        return findCheapAndEasy((Long) query.getSingleResult());\n+        //Pretty sure the above return will always error due to a conversion error\n+        //I \"reverted\" my change because I ended up not using this, but here is the fix below --MAD\n //                Integer qr = (Integer) query.getSingleResult();\n //                return findCheapAndEasy(qr.longValue());\n-            }\n-        } catch (Exception e) {\n-            logger.log(Level.SEVERE, \"Error finding datafile by storageID and DataSetVersion: \" + e.getMessage());\n-            return null;\n-        }\n-    }\n-    \n-    public List<FileMetadata> findFileMetadataByDatasetVersionId(Long datasetVersionId, int maxResults, String userSuppliedSortField, String userSuppliedSortOrder) {\n-        FileSortFieldAndOrder sortFieldAndOrder = new FileSortFieldAndOrder(userSuppliedSortField, userSuppliedSortOrder);\n-        String sortField = sortFieldAndOrder.getSortField();\n-        String sortOrder = sortFieldAndOrder.getSortOrder();\n-        if (maxResults < 0) {\n-            // return all results if user asks for negative number of results\n-            maxResults = 0;\n-        }\n-        String qr = \"select o from FileMetadata o where o.datasetVersion.id = :datasetVersionId order by o.\" + sortField + \" \" + sortOrder;\n-        return em.createQuery(qr, FileMetadata.class)\n-                    .setParameter(\"datasetVersionId\", datasetVersionId)\n-                    .setMaxResults(maxResults)\n-                    .getResultList();\n-    }\n-    \n-    public List<FileMetadata> findFileMetadataByDatasetVersionIdLabelSearchTerm(Long datasetVersionId, String searchTerm, String userSuppliedSortField, String userSuppliedSortOrder){\n-        FileSortFieldAndOrder sortFieldAndOrder = new FileSortFieldAndOrder(userSuppliedSortField, userSuppliedSortOrder);\n-\n-        String sortField = sortFieldAndOrder.getSortField();\n-        String sortOrder = sortFieldAndOrder.getSortOrder();\n-        String searchClause = \"\";\n-        if(searchTerm != null && !searchTerm.isEmpty()){\n-            searchClause = \" and  (lower(o.label) like '%\" + searchTerm.toLowerCase() + \"%' or lower(o.description) like '%\" + searchTerm.toLowerCase() + \"%')\";\n-        }\n-        \n-        String queryString = \"select o from FileMetadata o where o.datasetVersion.id = :datasetVersionId\"\n-                + searchClause\n-                + \" order by o.\" + sortField + \" \" + sortOrder;\n-        return em.createQuery(queryString, FileMetadata.class) \n-            .setParameter(\"datasetVersionId\", datasetVersionId)\n-            .getResultList();\n-    }\n-    \n-    public List<Integer> findFileMetadataIdsByDatasetVersionIdLabelSearchTerm(Long datasetVersionId, String searchTerm, String userSuppliedSortField, String userSuppliedSortOrder){\n-        FileSortFieldAndOrder sortFieldAndOrder = new FileSortFieldAndOrder(userSuppliedSortField, userSuppliedSortOrder);\n-        \n-        searchTerm=searchTerm.trim();\n-        String sortField = sortFieldAndOrder.getSortField();\n-        String sortOrder = sortFieldAndOrder.getSortOrder();\n-        String searchClause = \"\";\n-        if(searchTerm != null && !searchTerm.isEmpty()){\n-            searchClause = \" and  (lower(o.label) like '%\" + searchTerm.toLowerCase() + \"%' or lower(o.description) like '%\" + searchTerm.toLowerCase() + \"%')\";\n-        }\n-        \n-        //the createNativeQuary takes persistant entities, which Integer.class is not,\n-        //which is causing the exception. Hence, this query does not need an Integer.class\n-        //as the second parameter. \n-        return em.createNativeQuery(\"select o.id from FileMetadata o where o.datasetVersion_id = \"  + datasetVersionId\n-                + searchClause\n-                + \" order by o.\" + sortField + \" \" + sortOrder)\n-                .getResultList();\n-    }\n-    \n-    public List<Long> findDataFileIdsByDatasetVersionIdLabelSearchTerm(Long datasetVersionId, String searchTerm, String userSuppliedSortField, String userSuppliedSortOrder){\n-        FileSortFieldAndOrder sortFieldAndOrder = new FileSortFieldAndOrder(userSuppliedSortField, userSuppliedSortOrder);\n-        \n-        searchTerm=searchTerm.trim();\n-        String sortField = sortFieldAndOrder.getSortField();\n-        String sortOrder = sortFieldAndOrder.getSortOrder();\n-        String searchClause = \"\";\n-        if(searchTerm != null && !searchTerm.isEmpty()){\n-            searchClause = \" and  (lower(o.label) like '%\" + searchTerm.toLowerCase() + \"%' or lower(o.description) like '%\" + searchTerm.toLowerCase() + \"%')\";\n-        }\n-        \n-        return em.createNativeQuery(\"select o.datafile_id from FileMetadata o where o.datasetVersion_id = \"  + datasetVersionId\n-                + searchClause\n-                + \" order by o.\" + sortField + \" \" + sortOrder)\n-                .getResultList();\n-    }\n-    \n-    public List<FileMetadata> findFileMetadataByDatasetVersionIdLazy(Long datasetVersionId, int maxResults, String userSuppliedSortField, String userSuppliedSortOrder, int firstResult) {\n-        FileSortFieldAndOrder sortFieldAndOrder = new FileSortFieldAndOrder(userSuppliedSortField, userSuppliedSortOrder);\n-        String sortField = sortFieldAndOrder.getSortField();\n-        String sortOrder = sortFieldAndOrder.getSortOrder();\n-\n-        if (maxResults < 0) {\n-            // return all results if user asks for negative number of results\n-            maxResults = 0;\n-        }\n-        return em.createQuery(\"select o from FileMetadata o where o.datasetVersion.id = :datasetVersionId order by o.\" + sortField + \" \" + sortOrder, FileMetadata.class)\n-                .setParameter(\"datasetVersionId\", datasetVersionId)\n-                .setMaxResults(maxResults)\n-                .setFirstResult(firstResult)\n-                .getResultList();\n-    }\n-    \n-    public Long findCountByDatasetVersionId(Long datasetVersionId){\n-        return (Long) em.createNativeQuery(\"select count(*)  from FileMetadata fmd \"\n-                + \" where fmd.datasetVersion_id = \" + datasetVersionId\n-                + \";\").getSingleResult();\n-    }\n-\n-    public FileMetadata findFileMetadata(Long fileMetadataId) {\n-        return em.find(FileMetadata.class, fileMetadataId);\n-    }\n-    \n-    public FileMetadata findFileMetadataByDatasetVersionIdAndDataFileId(Long datasetVersionId, Long dataFileId) {\n-\n-        Query query = em.createQuery(\"select o from FileMetadata o where o.datasetVersion.id = :datasetVersionId  and o.dataFile.id = :dataFileId\");\n-        query.setParameter(\"datasetVersionId\", datasetVersionId);\n-        query.setParameter(\"dataFileId\", dataFileId);\n-        try {\n-            FileMetadata retVal = (FileMetadata) query.getSingleResult();\n-            return retVal;\n-        } catch(Exception ex) {\n-            return null;\n-        }\n-    }\n-\n-    public FileMetadata findMostRecentVersionFileIsIn(DataFile file) {\n-        if (file == null) {\n-            return null;\n-        }\n-        List<FileMetadata> fileMetadatas = file.getFileMetadatas();\n-        if (fileMetadatas == null || fileMetadatas.isEmpty()) {\n-            return null;\n-        } else {\n-            return fileMetadatas.get(0);\n-        }\n-    }\n-\n-    public DataFile findCheapAndEasy(Long id) {\n-        DataFile dataFile;\n-\n-        Object[] result;\n-\n-        try {\n-            result = (Object[]) em.createNativeQuery(\"SELECT t0.ID, t0.CREATEDATE, t0.INDEXTIME, t0.MODIFICATIONTIME, t0.PERMISSIONINDEXTIME, t0.PERMISSIONMODIFICATIONTIME, t0.PUBLICATIONDATE, t0.CREATOR_ID, t0.RELEASEUSER_ID, t0.PREVIEWIMAGEAVAILABLE, t1.CONTENTTYPE, t0.STORAGEIDENTIFIER, t1.FILESIZE, t1.INGESTSTATUS, t1.CHECKSUMVALUE, t1.RESTRICTED, t3.ID, t2.AUTHORITY, t2.IDENTIFIER, t1.CHECKSUMTYPE, t1.PREVIOUSDATAFILEID, t1.ROOTDATAFILEID, t0.AUTHORITY, T0.PROTOCOL, T0.IDENTIFIER FROM DVOBJECT t0, DATAFILE t1, DVOBJECT t2, DATASET t3 WHERE ((t0.ID = \" + id + \") AND (t0.OWNER_ID = t2.ID) AND (t2.ID = t3.ID) AND (t1.ID = t0.ID))\").getSingleResult();\n-        } catch (Exception ex) {\n-            return null;\n-        }\n-\n-        if (result == null) {\n-            return null;\n-        }\n-\n-        Integer file_id = (Integer) result[0];\n-\n-        dataFile = new DataFile();\n-        dataFile.setMergeable(false);\n-\n-        dataFile.setId(file_id.longValue());\n-\n-        Timestamp createDate = (Timestamp) result[1];\n-        Timestamp indexTime = (Timestamp) result[2];\n-        Timestamp modificationTime = (Timestamp) result[3];\n-        Timestamp permissionIndexTime = (Timestamp) result[4];\n-        Timestamp permissionModificationTime = (Timestamp) result[5];\n-        Timestamp publicationDate = (Timestamp) result[6];\n-\n-        dataFile.setCreateDate(createDate);\n-        dataFile.setIndexTime(indexTime);\n-        dataFile.setModificationTime(modificationTime);\n-        dataFile.setPermissionIndexTime(permissionIndexTime);\n-        dataFile.setPermissionModificationTime(permissionModificationTime);\n-        dataFile.setPublicationDate(publicationDate);\n-\n-        // no support for users yet!\n-        // (no need to - so far? -- L.A. 4.2.2) \n+      }\n+    } catch (Exception e) {\n+      logger.log(Level.SEVERE, \"Error finding datafile by storageID and DataSetVersion: \" + e.getMessage());\n+      return null;\n+    }\n+  }\n+\n+  public List<FileMetadata> findFileMetadataByDatasetVersionId(Long datasetVersionId, int maxResults,\n+                                                               String userSuppliedSortField,\n+                                                               String userSuppliedSortOrder) {\n+    FileSortFieldAndOrder sortFieldAndOrder = new FileSortFieldAndOrder(userSuppliedSortField, userSuppliedSortOrder);\n+    String sortField = sortFieldAndOrder.getSortField();\n+    String sortOrder = sortFieldAndOrder.getSortOrder();\n+    if (maxResults < 0) {\n+      // return all results if user asks for negative number of results\n+      maxResults = 0;\n+    }\n+    String qr =\n+      \"select o from FileMetadata o where o.datasetVersion.id = :datasetVersionId order by o.\" + sortField + \" \" +\n+        sortOrder;\n+    return em.createQuery(qr, FileMetadata.class)\n+      .setParameter(\"datasetVersionId\", datasetVersionId)\n+      .setMaxResults(maxResults)\n+      .getResultList();\n+  }\n+\n+  public List<FileMetadata> findFileMetadataByDatasetVersionIdLabelSearchTerm(Long datasetVersionId, String searchTerm,\n+                                                                              String userSuppliedSortField,\n+                                                                              String userSuppliedSortOrder) {\n+    FileSortFieldAndOrder sortFieldAndOrder = new FileSortFieldAndOrder(userSuppliedSortField, userSuppliedSortOrder);\n+\n+    String sortField = sortFieldAndOrder.getSortField();\n+    String sortOrder = sortFieldAndOrder.getSortOrder();\n+    String searchClause = \"\";\n+    if (searchTerm != null && !searchTerm.isEmpty()) {\n+      searchClause = \" and  (lower(o.label) like '%\" + searchTerm.toLowerCase() + \"%' or lower(o.description) like '%\" +\n+        searchTerm.toLowerCase() + \"%')\";\n+    }\n+\n+    String queryString = \"select o from FileMetadata o where o.datasetVersion.id = :datasetVersionId\"\n+      + searchClause\n+      + \" order by o.\" + sortField + \" \" + sortOrder;\n+    return em.createQuery(queryString, FileMetadata.class)\n+      .setParameter(\"datasetVersionId\", datasetVersionId)\n+      .getResultList();\n+  }\n+\n+  public List<Integer> findFileMetadataIdsByDatasetVersionIdLabelSearchTerm(Long datasetVersionId, String searchTerm,\n+                                                                            String userSuppliedSortField,\n+                                                                            String userSuppliedSortOrder) {\n+    FileSortFieldAndOrder sortFieldAndOrder = new FileSortFieldAndOrder(userSuppliedSortField, userSuppliedSortOrder);\n+\n+    searchTerm = searchTerm.trim();\n+    String sortField = sortFieldAndOrder.getSortField();\n+    String sortOrder = sortFieldAndOrder.getSortOrder();\n+    String searchClause = \"\";\n+    if (searchTerm != null && !searchTerm.isEmpty()) {\n+      searchClause = \" and  (lower(o.label) like '%\" + searchTerm.toLowerCase() + \"%' or lower(o.description) like '%\" +\n+        searchTerm.toLowerCase() + \"%')\";\n+    }\n+\n+    //the createNativeQuary takes persistant entities, which Integer.class is not,\n+    //which is causing the exception. Hence, this query does not need an Integer.class\n+    //as the second parameter.\n+    return em.createNativeQuery(\"select o.id from FileMetadata o where o.datasetVersion_id = \" + datasetVersionId\n+      + searchClause\n+      + \" order by o.\" + sortField + \" \" + sortOrder)\n+      .getResultList();\n+  }\n+\n+  public List<Long> findDataFileIdsByDatasetVersionIdLabelSearchTerm(Long datasetVersionId, String searchTerm,\n+                                                                     String userSuppliedSortField,\n+                                                                     String userSuppliedSortOrder) {\n+    FileSortFieldAndOrder sortFieldAndOrder = new FileSortFieldAndOrder(userSuppliedSortField, userSuppliedSortOrder);\n+\n+    searchTerm = searchTerm.trim();\n+    String sortField = sortFieldAndOrder.getSortField();\n+    String sortOrder = sortFieldAndOrder.getSortOrder();\n+    String searchClause = \"\";\n+    if (searchTerm != null && !searchTerm.isEmpty()) {\n+      searchClause = \" and  (lower(o.label) like '%\" + searchTerm.toLowerCase() + \"%' or lower(o.description) like '%\" +\n+        searchTerm.toLowerCase() + \"%')\";\n+    }\n+\n+    return em\n+      .createNativeQuery(\"select o.datafile_id from FileMetadata o where o.datasetVersion_id = \" + datasetVersionId\n+        + searchClause\n+        + \" order by o.\" + sortField + \" \" + sortOrder)\n+      .getResultList();\n+  }\n+\n+  public List<FileMetadata> findFileMetadataByDatasetVersionIdLazy(Long datasetVersionId, int maxResults,\n+                                                                   String userSuppliedSortField,\n+                                                                   String userSuppliedSortOrder, int firstResult) {\n+    FileSortFieldAndOrder sortFieldAndOrder = new FileSortFieldAndOrder(userSuppliedSortField, userSuppliedSortOrder);\n+    String sortField = sortFieldAndOrder.getSortField();\n+    String sortOrder = sortFieldAndOrder.getSortOrder();\n+\n+    if (maxResults < 0) {\n+      // return all results if user asks for negative number of results\n+      maxResults = 0;\n+    }\n+    return em.createQuery(\n+      \"select o from FileMetadata o where o.datasetVersion.id = :datasetVersionId order by o.\" + sortField + \" \" +\n+        sortOrder, FileMetadata.class)\n+      .setParameter(\"datasetVersionId\", datasetVersionId)\n+      .setMaxResults(maxResults)\n+      .setFirstResult(firstResult)\n+      .getResultList();\n+  }\n+\n+  public Long findCountByDatasetVersionId(Long datasetVersionId) {\n+    return (Long) em.createNativeQuery(\"select count(*)  from FileMetadata fmd \"\n+      + \" where fmd.datasetVersion_id = \" + datasetVersionId\n+      + \";\").getSingleResult();\n+  }\n+\n+  public FileMetadata findFileMetadata(Long fileMetadataId) {\n+    return em.find(FileMetadata.class, fileMetadataId);\n+  }\n+\n+  public FileMetadata findFileMetadataByDatasetVersionIdAndDataFileId(Long datasetVersionId, Long dataFileId) {\n+\n+    Query query = em.createQuery(\n+      \"select o from FileMetadata o where o.datasetVersion.id = :datasetVersionId  and o.dataFile.id = :dataFileId\");\n+    query.setParameter(\"datasetVersionId\", datasetVersionId);\n+    query.setParameter(\"dataFileId\", dataFileId);\n+    try {\n+      FileMetadata retVal = (FileMetadata) query.getSingleResult();\n+      return retVal;\n+    } catch (Exception ex) {\n+      return null;\n+    }\n+  }\n+\n+  public FileMetadata findMostRecentVersionFileIsIn(DataFile file) {\n+    if (file == null) {\n+      return null;\n+    }\n+    List<FileMetadata> fileMetadatas = file.getFileMetadatas();\n+    if (fileMetadatas == null || fileMetadatas.isEmpty()) {\n+      return null;\n+    } else {\n+      return fileMetadatas.get(0);\n+    }\n+  }\n+\n+  public DataFile findCheapAndEasy(Long id) {\n+    DataFile dataFile;\n+\n+    Object[] result;\n+\n+    try {\n+      result = (Object[]) em.createNativeQuery(\n+        \"SELECT t0.ID, t0.CREATEDATE, t0.INDEXTIME, t0.MODIFICATIONTIME, t0.PERMISSIONINDEXTIME, t0.PERMISSIONMODIFICATIONTIME, t0.PUBLICATIONDATE, t0.CREATOR_ID, t0.RELEASEUSER_ID, t0.PREVIEWIMAGEAVAILABLE, t1.CONTENTTYPE, t0.STORAGEIDENTIFIER, t1.FILESIZE, t1.INGESTSTATUS, t1.CHECKSUMVALUE, t1.RESTRICTED, t3.ID, t2.AUTHORITY, t2.IDENTIFIER, t1.CHECKSUMTYPE, t1.PREVIOUSDATAFILEID, t1.ROOTDATAFILEID, t0.AUTHORITY, T0.PROTOCOL, T0.IDENTIFIER FROM DVOBJECT t0, DATAFILE t1, DVOBJECT t2, DATASET t3 WHERE ((t0.ID = \" +\n+          id + \") AND (t0.OWNER_ID = t2.ID) AND (t2.ID = t3.ID) AND (t1.ID = t0.ID))\").getSingleResult();\n+    } catch (Exception ex) {\n+      return null;\n+    }\n+\n+    if (result == null) {\n+      return null;\n+    }\n+\n+    Integer file_id = (Integer) result[0];\n+\n+    dataFile = new DataFile();\n+    dataFile.setMergeable(false);\n+\n+    dataFile.setId(file_id.longValue());\n+\n+    Timestamp createDate = (Timestamp) result[1];\n+    Timestamp indexTime = (Timestamp) result[2];\n+    Timestamp modificationTime = (Timestamp) result[3];\n+    Timestamp permissionIndexTime = (Timestamp) result[4];\n+    Timestamp permissionModificationTime = (Timestamp) result[5];\n+    Timestamp publicationDate = (Timestamp) result[6];\n+\n+    dataFile.setCreateDate(createDate);\n+    dataFile.setIndexTime(indexTime);\n+    dataFile.setModificationTime(modificationTime);\n+    dataFile.setPermissionIndexTime(permissionIndexTime);\n+    dataFile.setPermissionModificationTime(permissionModificationTime);\n+    dataFile.setPublicationDate(publicationDate);\n+\n+    // no support for users yet!\n+    // (no need to - so far? -- L.A. 4.2.2)\n         /*\n          Long creatorId = (Long) result[7];\n          if (creatorId != null) {\n@@ -416,480 +438,499 @@ public class DataFileServiceBean implements java.io.Serializable {\n          }\n          }\n          */\n-        Boolean previewAvailable = (Boolean) result[9];\n-        if (previewAvailable != null) {\n-            dataFile.setPreviewImageAvailable(previewAvailable);\n-        }\n-        \n-        String contentType = (String) result[10];\n-        \n-        if (contentType != null) {\n-            dataFile.setContentType(contentType);\n-        }\n+    Boolean previewAvailable = (Boolean) result[9];\n+    if (previewAvailable != null) {\n+      dataFile.setPreviewImageAvailable(previewAvailable);\n+    }\n \n-        String storageIdentifier = (String) result[11];\n+    String contentType = (String) result[10];\n \n-        if (storageIdentifier != null) {\n-            dataFile.setStorageIdentifier(storageIdentifier);\n-        }\n+    if (contentType != null) {\n+      dataFile.setContentType(contentType);\n+    }\n \n-        Long fileSize = (Long) result[12];\n+    String storageIdentifier = (String) result[11];\n \n-        if (fileSize != null) {\n-            dataFile.setFilesize(fileSize);\n-        }\n+    if (storageIdentifier != null) {\n+      dataFile.setStorageIdentifier(storageIdentifier);\n+    }\n \n-        if (result[13] != null) {\n-            String ingestStatusString = (String) result[13];\n-            dataFile.setIngestStatus(ingestStatusString.charAt(0));\n-        }\n+    Long fileSize = (Long) result[12];\n \n-        String md5 = (String) result[14];\n+    if (fileSize != null) {\n+      dataFile.setFilesize(fileSize);\n+    }\n \n-        if (md5 != null) {\n-            dataFile.setChecksumValue(md5);\n-        }\n+    if (result[13] != null) {\n+      String ingestStatusString = (String) result[13];\n+      dataFile.setIngestStatus(ingestStatusString.charAt(0));\n+    }\n \n-        Boolean restricted = (Boolean) result[15];\n-        if (restricted != null) {\n-            dataFile.setRestricted(restricted);\n-        }\n+    String md5 = (String) result[14];\n \n+    if (md5 != null) {\n+      dataFile.setChecksumValue(md5);\n+    }\n \n-        Dataset owner = new Dataset();\n+    Boolean restricted = (Boolean) result[15];\n+    if (restricted != null) {\n+      dataFile.setRestricted(restricted);\n+    }\n \n-        \n-        // TODO: check for nulls\n-        owner.setId((Long)result[16]);\n-        owner.setAuthority((String)result[17]);\n-        owner.setIdentifier((String)result[18]);\n-\n-        String checksumType = (String) result[19];\n-        if (checksumType != null) {\n-            try {\n-                // In the database we store \"SHA1\" rather than \"SHA-1\".\n-                DataFile.ChecksumType typeFromStringInDatabase = DataFile.ChecksumType.valueOf(checksumType);\n-                dataFile.setChecksumType(typeFromStringInDatabase);\n-            } catch (IllegalArgumentException ex) {\n-                logger.info(\"Exception trying to convert \" + checksumType + \" to enum: \" + ex);\n-            }\n-        }\n-        \n-        Long previousDataFileId = (Long) result[20];\n-        if (previousDataFileId != null){\n-            dataFile.setPreviousDataFileId(previousDataFileId);\n-        }\n-        \n-        Long rootDataFileId = (Long) result[21];\n-        if (rootDataFileId != null){\n-            dataFile.setRootDataFileId(rootDataFileId);\n-        } \n-        \n-        String authority = (String) result[22];\n-        if (authority != null) {\n-            dataFile.setAuthority(authority);\n-        }\n \n-        String protocol = (String) result[23];\n-        if (protocol != null) {\n-            dataFile.setProtocol(protocol);\n-        }\n+    Dataset owner = new Dataset();\n+\n+\n+    // TODO: check for nulls\n+    owner.setId((Long) result[16]);\n+    owner.setAuthority((String) result[17]);\n+    owner.setIdentifier((String) result[18]);\n+\n+    String checksumType = (String) result[19];\n+    if (checksumType != null) {\n+      try {\n+        // In the database we store \"SHA1\" rather than \"SHA-1\".\n+        DataFile.ChecksumType typeFromStringInDatabase = DataFile.ChecksumType.valueOf(checksumType);\n+        dataFile.setChecksumType(typeFromStringInDatabase);\n+      } catch (IllegalArgumentException ex) {\n+        logger.info(\"Exception trying to convert \" + checksumType + \" to enum: \" + ex);\n+      }\n+    }\n+\n+    Long previousDataFileId = (Long) result[20];\n+    if (previousDataFileId != null) {\n+      dataFile.setPreviousDataFileId(previousDataFileId);\n+    }\n \n-        String identifier = (String) result[24];\n-        if (identifier != null) {\n-            dataFile.setIdentifier(identifier);\n+    Long rootDataFileId = (Long) result[21];\n+    if (rootDataFileId != null) {\n+      dataFile.setRootDataFileId(rootDataFileId);\n+    }\n+\n+    String authority = (String) result[22];\n+    if (authority != null) {\n+      dataFile.setAuthority(authority);\n+    }\n+\n+    String protocol = (String) result[23];\n+    if (protocol != null) {\n+      dataFile.setProtocol(protocol);\n+    }\n+\n+    String identifier = (String) result[24];\n+    if (identifier != null) {\n+      dataFile.setIdentifier(identifier);\n+    }\n+\n+    dataFile.setOwner(owner);\n+\n+    // If content type indicates it's tabular data, spend 2 extra queries\n+    // looking up the data table and tabular tags objects:\n+\n+    if (MIME_TYPE_TSV.equalsIgnoreCase(contentType) || MIME_TYPE_TSV_ALT.equalsIgnoreCase(contentType)) {\n+      Object[] dtResult;\n+      try {\n+        dtResult = (Object[]) em.createNativeQuery(\n+          \"SELECT ID, UNF, CASEQUANTITY, VARQUANTITY, ORIGINALFILEFORMAT, ORIGINALFILESIZE FROM dataTable WHERE DATAFILE_ID = \" +\n+            id).getSingleResult();\n+      } catch (Exception ex) {\n+        dtResult = null;\n+      }\n+\n+      if (dtResult != null) {\n+        DataTable dataTable = new DataTable();\n+\n+        dataTable.setId(((Integer) dtResult[0]).longValue());\n+\n+        dataTable.setUnf((String) dtResult[1]);\n+\n+        dataTable.setCaseQuantity((Long) dtResult[2]);\n+\n+        dataTable.setVarQuantity((Long) dtResult[3]);\n+\n+        dataTable.setOriginalFileFormat((String) dtResult[4]);\n+\n+        dataTable.setOriginalFileSize((Long) dtResult[5]);\n+\n+        dataTable.setDataFile(dataFile);\n+        dataFile.setDataTable(dataTable);\n+\n+        // tabular tags:\n+\n+        List<Object[]> tagResults;\n+        try {\n+          tagResults =\n+            em.createNativeQuery(\"SELECT t.TYPE, t.DATAFILE_ID FROM DATAFILETAG t WHERE t.DATAFILE_ID = \" + id)\n+              .getResultList();\n+        } catch (Exception ex) {\n+          logger.info(\"EXCEPTION looking up tags.\");\n+          tagResults = null;\n         }\n-                \n-        dataFile.setOwner(owner);\n \n-        // If content type indicates it's tabular data, spend 2 extra queries \n-        // looking up the data table and tabular tags objects:\n-        \n-        if (MIME_TYPE_TSV.equalsIgnoreCase(contentType) || MIME_TYPE_TSV_ALT.equalsIgnoreCase(contentType)) {\n-            Object[] dtResult;\n-            try {\n-                dtResult = (Object[]) em.createNativeQuery(\"SELECT ID, UNF, CASEQUANTITY, VARQUANTITY, ORIGINALFILEFORMAT, ORIGINALFILESIZE FROM dataTable WHERE DATAFILE_ID = \" + id).getSingleResult();\n-            } catch (Exception ex) {\n-                dtResult = null;\n-            }\n-        \n-            if (dtResult != null) {\n-                DataTable dataTable = new DataTable(); \n-\n-                dataTable.setId(((Integer) dtResult[0]).longValue());\n-            \n-                dataTable.setUnf((String)dtResult[1]);\n-            \n-                dataTable.setCaseQuantity((Long)dtResult[2]);\n-            \n-                dataTable.setVarQuantity((Long)dtResult[3]);\n-            \n-                dataTable.setOriginalFileFormat((String)dtResult[4]);\n-                \n-                dataTable.setOriginalFileSize((Long)dtResult[5]);\n-                \n-                dataTable.setDataFile(dataFile);\n-                dataFile.setDataTable(dataTable);\n-                \n-                // tabular tags: \n-                \n-                List<Object[]> tagResults;\n-                try {\n-                    tagResults = em.createNativeQuery(\"SELECT t.TYPE, t.DATAFILE_ID FROM DATAFILETAG t WHERE t.DATAFILE_ID = \" + id).getResultList();\n-                } catch (Exception ex) {\n-                    logger.info(\"EXCEPTION looking up tags.\");\n-                    tagResults = null;\n-                }\n-                \n-                if (tagResults != null) {\n-                    List<String> fileTagLabels = DataFileTag.listTags();\n-                    \n-                    for (Object[] tagResult : tagResults) {\n-                        Integer tagId = (Integer)tagResult[0];\n-                        DataFileTag tag = new DataFileTag();\n-                        tag.setTypeByLabel(fileTagLabels.get(tagId));\n-                        tag.setDataFile(dataFile);\n-                        dataFile.addTag(tag);\n-                    }\n-                }\n-            }\n+        if (tagResults != null) {\n+          List<String> fileTagLabels = DataFileTag.listTags();\n+\n+          for (Object[] tagResult : tagResults) {\n+            Integer tagId = (Integer) tagResult[0];\n+            DataFileTag tag = new DataFileTag();\n+            tag.setTypeByLabel(fileTagLabels.get(tagId));\n+            tag.setDataFile(dataFile);\n+            dataFile.addTag(tag);\n+          }\n         }\n-        \n-        return dataFile;\n+      }\n     }\n-    /* \n-     * This is an experimental method for populating the versions of \n-     * the datafile with the filemetadatas, optimized for making as few db \n-     * queries as possible. \n-     * It should only be used to retrieve filemetadata for the DatasetPage!\n-     * It is not guaranteed to adequately perform anywhere else. \n-    */\n \n-    public void findFileMetadataOptimizedExperimental(Dataset owner, DatasetVersion version, AuthenticatedUser au) {\n-        List<DataFile> dataFiles = new ArrayList<>();\n-        List<DataTable> dataTables = new ArrayList<>();\n-        //List<FileMetadata> retList = new ArrayList<>(); \n-        \n-        // TODO: \n-        //  replace these maps with simple lists and run binary search on them. -- 4.2.1\n-        \n-        Map<Long, AuthenticatedUser> userMap = new HashMap<>(); \n-        Map<Long, Integer> filesMap = new HashMap<>();\n-        Map<Long, Integer> datatableMap = new HashMap<>();\n-        Map<Long, Integer> categoryMap = new HashMap<>();\n-        Map<Long, Set<Integer>> fileTagMap = new HashMap<>();\n-        List<Long> accessRequestFileIds = new ArrayList();\n-        \n-        List<String> fileTagLabels = DataFileTag.listTags();\n-        \n-        \n-        int i = 0; \n-        \n-        List<Object[]> dataTableResults = em.createNativeQuery(\"SELECT t0.ID, t0.DATAFILE_ID, t0.UNF, t0.CASEQUANTITY, t0.VARQUANTITY, t0.ORIGINALFILEFORMAT, t0.ORIGINALFILESIZE, t0.ORIGINALFILENAME FROM dataTable t0, dataFile t1, dvObject t2 WHERE ((t0.DATAFILE_ID = t1.ID) AND (t1.ID = t2.ID) AND (t2.OWNER_ID = \" + owner.getId() + \")) ORDER BY t0.ID\").getResultList();\n-        \n-        for (Object[] result : dataTableResults) {\n-            DataTable dataTable = new DataTable(); \n-            long fileId = ((Number) result[1]).longValue();\n-\n-            dataTable.setId(((Number) result[1]).longValue());\n-            \n-            dataTable.setUnf((String)result[2]);\n-            \n-            dataTable.setCaseQuantity((Long)result[3]);\n-            \n-            dataTable.setVarQuantity((Long)result[4]);\n-            \n-            dataTable.setOriginalFileFormat((String)result[5]);\n-            \n-            dataTable.setOriginalFileSize((Long)result[6]);\n-            \n-            dataTable.setOriginalFileName((String)result[7]);\n-            \n-            dataTables.add(dataTable);\n-            datatableMap.put(fileId, i++);\n-            \n-        }\n-        \n-        logger.fine(\"Retrieved \"+dataTables.size()+\" DataTable objects.\");\n-         \n-        List<Object[]> dataTagsResults = em.createNativeQuery(\"SELECT t0.DATAFILE_ID, t0.TYPE FROM DataFileTag t0, dvObject t1 WHERE (t1.ID = t0.DATAFILE_ID) AND (t1.OWNER_ID=\"+ owner.getId() + \")\").getResultList();\n-        for (Object[] result : dataTagsResults) {\n-            Long datafile_id = (Long) result[0];\n-            Integer tagtype_id = (Integer) result[1];\n-            if (fileTagMap.get(datafile_id) == null) {\n-                fileTagMap.put(datafile_id, new HashSet<>());\n-            }\n-            fileTagMap.get(datafile_id).add(tagtype_id);\n+    return dataFile;\n+  }\n+  /*\n+   * This is an experimental method for populating the versions of\n+   * the datafile with the filemetadatas, optimized for making as few db\n+   * queries as possible.\n+   * It should only be used to retrieve filemetadata for the DatasetPage!\n+   * It is not guaranteed to adequately perform anywhere else.\n+   */\n+\n+  public void findFileMetadataOptimizedExperimental(Dataset owner, DatasetVersion version, AuthenticatedUser au) {\n+    List<DataFile> dataFiles = new ArrayList<>();\n+    List<DataTable> dataTables = new ArrayList<>();\n+    //List<FileMetadata> retList = new ArrayList<>();\n+\n+    // TODO:\n+    //  replace these maps with simple lists and run binary search on them. -- 4.2.1\n+\n+    Map<Long, AuthenticatedUser> userMap = new HashMap<>();\n+    Map<Long, Integer> filesMap = new HashMap<>();\n+    Map<Long, Integer> datatableMap = new HashMap<>();\n+    Map<Long, Integer> categoryMap = new HashMap<>();\n+    Map<Long, Set<Integer>> fileTagMap = new HashMap<>();\n+    List<Long> accessRequestFileIds = new ArrayList();\n+\n+    List<String> fileTagLabels = DataFileTag.listTags();\n+\n+\n+    int i = 0;\n+\n+    List<Object[]> dataTableResults = em.createNativeQuery(\n+      \"SELECT t0.ID, t0.DATAFILE_ID, t0.UNF, t0.CASEQUANTITY, t0.VARQUANTITY, t0.ORIGINALFILEFORMAT, t0.ORIGINALFILESIZE, t0.ORIGINALFILENAME FROM dataTable t0, dataFile t1, dvObject t2 WHERE ((t0.DATAFILE_ID = t1.ID) AND (t1.ID = t2.ID) AND (t2.OWNER_ID = \" +\n+        owner.getId() + \")) ORDER BY t0.ID\").getResultList();\n+\n+    for (Object[] result : dataTableResults) {\n+      DataTable dataTable = new DataTable();\n+      long fileId = ((Number) result[1]).longValue();\n+\n+      dataTable.setId(((Number) result[1]).longValue());\n+\n+      dataTable.setUnf((String) result[2]);\n+\n+      dataTable.setCaseQuantity((Long) result[3]);\n+\n+      dataTable.setVarQuantity((Long) result[4]);\n+\n+      dataTable.setOriginalFileFormat((String) result[5]);\n+\n+      dataTable.setOriginalFileSize((Long) result[6]);\n+\n+      dataTable.setOriginalFileName((String) result[7]);\n+\n+      dataTables.add(dataTable);\n+      datatableMap.put(fileId, i++);\n+\n+    }\n+\n+    logger.fine(\"Retrieved \" + dataTables.size() + \" DataTable objects.\");\n+\n+    List<Object[]> dataTagsResults = em.createNativeQuery(\n+      \"SELECT t0.DATAFILE_ID, t0.TYPE FROM DataFileTag t0, dvObject t1 WHERE (t1.ID = t0.DATAFILE_ID) AND (t1.OWNER_ID=\" +\n+        owner.getId() + \")\").getResultList();\n+    for (Object[] result : dataTagsResults) {\n+      Long datafile_id = (Long) result[0];\n+      Integer tagtype_id = (Integer) result[1];\n+      if (fileTagMap.get(datafile_id) == null) {\n+        fileTagMap.put(datafile_id, new HashSet<>());\n+      }\n+      fileTagMap.get(datafile_id).add(tagtype_id);\n+    }\n+    logger.fine(\"Retrieved \" + dataTagsResults.size() + \"\u00a0data tags.\");\n+    dataTagsResults = null;\n+\n+    //Only need to check for access requests if there is an authenticated user\n+    if (au != null) {\n+      List<Object> accessRequests = em.createNativeQuery(\n+        \"SELECT t0.ID FROM DVOBJECT t0, FILEACCESSREQUESTS t1 WHERE t1.datafile_id = t0.id and t0.OWNER_ID = \" +\n+          owner.getId() + \"  and t1.AUTHENTICATED_USER_ID = \" + au.getId() + \" ORDER BY t0.ID\").getResultList();\n+      for (Object result : accessRequests) {\n+        accessRequestFileIds.add(Long.valueOf((Integer) result));\n+      }\n+      logger.fine(\"Retrieved \" + accessRequests.size() + \"\u00a0access requests.\");\n+      accessRequests = null;\n+    }\n+\n+    i = 0;\n+\n+    List<Object[]> fileResults = em.createNativeQuery(\n+      \"SELECT t0.ID, t0.CREATEDATE, t0.INDEXTIME, t0.MODIFICATIONTIME, t0.PERMISSIONINDEXTIME, t0.PERMISSIONMODIFICATIONTIME, t0.PUBLICATIONDATE, t0.CREATOR_ID, t0.RELEASEUSER_ID, t1.CONTENTTYPE, t0.STORAGEIDENTIFIER, t1.FILESIZE, t1.INGESTSTATUS, t1.CHECKSUMVALUE, t1.RESTRICTED, t1.CHECKSUMTYPE, t1.PREVIOUSDATAFILEID, t1.ROOTDATAFILEID, t0.PROTOCOL, t0.AUTHORITY, t0.IDENTIFIER FROM DVOBJECT t0, DATAFILE t1 WHERE ((t0.OWNER_ID = \" +\n+        owner.getId() + \") AND ((t1.ID = t0.ID) AND (t0.DTYPE = 'DataFile'))) ORDER BY t0.ID\").getResultList();\n+\n+    for (Object[] result : fileResults) {\n+      Integer file_id = (Integer) result[0];\n+\n+      DataFile dataFile = new DataFile();\n+      dataFile.setMergeable(false);\n+\n+      dataFile.setId(file_id.longValue());\n+\n+      Timestamp createDate = (Timestamp) result[1];\n+      Timestamp indexTime = (Timestamp) result[2];\n+      Timestamp modificationTime = (Timestamp) result[3];\n+      Timestamp permissionIndexTime = (Timestamp) result[4];\n+      Timestamp permissionModificationTime = (Timestamp) result[5];\n+      Timestamp publicationDate = (Timestamp) result[6];\n+\n+      dataFile.setCreateDate(createDate);\n+      dataFile.setIndexTime(indexTime);\n+      dataFile.setModificationTime(modificationTime);\n+      dataFile.setPermissionIndexTime(permissionIndexTime);\n+      dataFile.setPermissionModificationTime(permissionModificationTime);\n+      dataFile.setPublicationDate(publicationDate);\n+\n+      Long creatorId = (Long) result[7];\n+      if (creatorId != null) {\n+        AuthenticatedUser creator = userMap.get(creatorId);\n+        if (creator == null) {\n+          creator = userService.find(creatorId);\n+          if (creator != null) {\n+            userMap.put(creatorId, creator);\n+          }\n         }\n-        logger.fine(\"Retrieved \"+dataTagsResults.size()+\"\u00a0data tags.\");\n-        dataTagsResults = null;\n-\n-        //Only need to check for access requests if there is an authenticated user       \n-        if (au != null) {\n-            List<Object> accessRequests = em.createNativeQuery(\"SELECT t0.ID FROM DVOBJECT t0, FILEACCESSREQUESTS t1 WHERE t1.datafile_id = t0.id and t0.OWNER_ID = \" + owner.getId() + \"  and t1.AUTHENTICATED_USER_ID = \" + au.getId() + \" ORDER BY t0.ID\").getResultList();\n-            for (Object result : accessRequests) {               \n-                accessRequestFileIds.add(Long.valueOf((Integer)result));\n-            }\n-            logger.fine(\"Retrieved \" + accessRequests.size() + \"\u00a0access requests.\");           \n-            accessRequests = null;\n+        if (creator != null) {\n+          dataFile.setCreator(creator);\n         }\n+      }\n \n-        i = 0;\n-        \n-        List<Object[]> fileResults = em.createNativeQuery(\"SELECT t0.ID, t0.CREATEDATE, t0.INDEXTIME, t0.MODIFICATIONTIME, t0.PERMISSIONINDEXTIME, t0.PERMISSIONMODIFICATIONTIME, t0.PUBLICATIONDATE, t0.CREATOR_ID, t0.RELEASEUSER_ID, t1.CONTENTTYPE, t0.STORAGEIDENTIFIER, t1.FILESIZE, t1.INGESTSTATUS, t1.CHECKSUMVALUE, t1.RESTRICTED, t1.CHECKSUMTYPE, t1.PREVIOUSDATAFILEID, t1.ROOTDATAFILEID, t0.PROTOCOL, t0.AUTHORITY, t0.IDENTIFIER FROM DVOBJECT t0, DATAFILE t1 WHERE ((t0.OWNER_ID = \" + owner.getId() + \") AND ((t1.ID = t0.ID) AND (t0.DTYPE = 'DataFile'))) ORDER BY t0.ID\").getResultList(); \n-    \n-        for (Object[] result : fileResults) {\n-            Integer file_id = (Integer) result[0];\n-            \n-            DataFile dataFile = new DataFile();\n-            dataFile.setMergeable(false);\n-            \n-            dataFile.setId(file_id.longValue());\n-            \n-            Timestamp createDate = (Timestamp) result[1];\n-            Timestamp indexTime = (Timestamp) result[2];\n-            Timestamp modificationTime = (Timestamp) result[3];\n-            Timestamp permissionIndexTime = (Timestamp) result[4];\n-            Timestamp permissionModificationTime = (Timestamp) result[5];\n-            Timestamp publicationDate = (Timestamp) result[6];\n-            \n-            dataFile.setCreateDate(createDate);\n-            dataFile.setIndexTime(indexTime);\n-            dataFile.setModificationTime(modificationTime);\n-            dataFile.setPermissionIndexTime(permissionIndexTime);\n-            dataFile.setPermissionModificationTime(permissionModificationTime);\n-            dataFile.setPublicationDate(publicationDate);\n-            \n-            Long creatorId = (Long) result[7]; \n-            if (creatorId != null) {\n-                AuthenticatedUser creator = userMap.get(creatorId);\n-                if (creator == null) {\n-                    creator = userService.find(creatorId);\n-                    if (creator != null) {\n-                        userMap.put(creatorId, creator);\n-                    }\n-                }\n-                if (creator != null) {\n-                    dataFile.setCreator(creator);\n-                }\n-            }\n-            \n-            dataFile.setOwner(owner);\n-            \n-            Long releaseUserId = (Long) result[8]; \n-            if (releaseUserId != null) {\n-                AuthenticatedUser releaseUser = userMap.get(releaseUserId);\n-                if (releaseUser == null) {\n-                    releaseUser = userService.find(releaseUserId);\n-                    if (releaseUser != null) {\n-                        userMap.put(releaseUserId, releaseUser);\n-                    }\n-                }\n-                if (releaseUser != null) {\n-                    dataFile.setReleaseUser(releaseUser);\n-                }\n-            }\n-            \n-            String contentType = (String) result[9]; \n-            \n-            if (contentType != null) {\n-                dataFile.setContentType(contentType);\n-            }\n-            \n-            String storageIdentifier = (String) result[10];\n-            \n-            if (storageIdentifier != null) {\n-                dataFile.setStorageIdentifier(storageIdentifier);\n-            }\n-            \n-            Long fileSize = (Long) result[11];\n-            \n-            if (fileSize != null) {\n-                dataFile.setFilesize(fileSize);\n-            }\n-            \n-            if (result[12] != null) {\n-                String ingestStatusString = (String) result[12];\n-                dataFile.setIngestStatus(ingestStatusString.charAt(0));\n-            }\n-            \n-            String md5 = (String) result[13]; \n-            \n-            if (md5 != null) {\n-                dataFile.setChecksumValue(md5);\n-            }\n-            \n-            Boolean restricted = (Boolean) result[14];\n-            if (restricted != null) {\n-                dataFile.setRestricted(restricted);\n-            }\n-\n-            String checksumType = (String) result[15];\n-            if (checksumType != null) {\n-                try {\n-                    // In the database we store \"SHA1\" rather than \"SHA-1\".\n-                    DataFile.ChecksumType typeFromStringInDatabase = DataFile.ChecksumType.valueOf(checksumType);\n-                    dataFile.setChecksumType(typeFromStringInDatabase);\n-                } catch (IllegalArgumentException ex) {\n-                    logger.info(\"Exception trying to convert \" + checksumType + \" to enum: \" + ex);\n-                }\n-            }\n-\n-            Long previousDataFileId = (Long) result[16];\n-            if (previousDataFileId != null) {\n-                dataFile.setPreviousDataFileId(previousDataFileId);\n-            }\n-            \n-            Long rootDataFileId = (Long) result[17];\n-            if (rootDataFileId != null) {\n-                dataFile.setRootDataFileId(rootDataFileId);\n-            }\n-            \n-            String protocol = (String) result[18];\n-            if (protocol != null) {\n-                dataFile.setProtocol(protocol);\n-            }\n-            \n-            String authority = (String) result[19];\n-            if (authority != null) {\n-                dataFile.setAuthority(authority);\n-            }\n-            \n-            String identifier = (String) result[20];\n-            if (identifier != null) {\n-                dataFile.setIdentifier(identifier);\n-            }\n-            \n-            // TODO: \n-            // - if ingest status is \"bad\", look up the ingest report; \n-            // - is it a dedicated thumbnail for the dataset? (do we ever need that info?? - not on the dataset page, I don't think...)\n-            \n-            // Is this a tabular file? \n-            \n-            if (datatableMap.get(dataFile.getId()) != null) {\n-                dataTables.get(datatableMap.get(dataFile.getId())).setDataFile(dataFile);\n-                dataFile.setDataTable(dataTables.get(datatableMap.get(dataFile.getId())));\n-                \n-            }            \n-\n-            if (fileTagMap.get(dataFile.getId()) != null) {\n-                for (Integer tag_id : fileTagMap.get(dataFile.getId())) {\n-                    DataFileTag tag = new DataFileTag();\n-                    tag.setTypeByLabel(fileTagLabels.get(tag_id));\n-                    tag.setDataFile(dataFile);\n-                    dataFile.addTag(tag);\n-                }\n-            } \n-            \n-            if (dataFile.isRestricted() && accessRequestFileIds.contains(dataFile.getId())) {\n-                dataFile.setFileAccessRequesters(Collections.singletonList(au));\n-            } \n-\n-            dataFiles.add(dataFile);\n-            filesMap.put(dataFile.getId(), i++);\n+      dataFile.setOwner(owner);\n+\n+      Long releaseUserId = (Long) result[8];\n+      if (releaseUserId != null) {\n+        AuthenticatedUser releaseUser = userMap.get(releaseUserId);\n+        if (releaseUser == null) {\n+          releaseUser = userService.find(releaseUserId);\n+          if (releaseUser != null) {\n+            userMap.put(releaseUserId, releaseUser);\n+          }\n         }\n-        fileResults = null;\n-        \n-        logger.fine(\"Retrieved and cached \"+i+\" datafiles.\");\n+        if (releaseUser != null) {\n+          dataFile.setReleaseUser(releaseUser);\n+        }\n+      }\n \n-        i = 0; \n-        for (DataFileCategory fileCategory : owner.getCategories()) {\n-            //logger.fine(\"category: id=\"+fileCategory.getId());\n-            categoryMap.put(fileCategory.getId(), i++);\n+      String contentType = (String) result[9];\n+\n+      if (contentType != null) {\n+        dataFile.setContentType(contentType);\n+      }\n+\n+      String storageIdentifier = (String) result[10];\n+\n+      if (storageIdentifier != null) {\n+        dataFile.setStorageIdentifier(storageIdentifier);\n+      }\n+\n+      Long fileSize = (Long) result[11];\n+\n+      if (fileSize != null) {\n+        dataFile.setFilesize(fileSize);\n+      }\n+\n+      if (result[12] != null) {\n+        String ingestStatusString = (String) result[12];\n+        dataFile.setIngestStatus(ingestStatusString.charAt(0));\n+      }\n+\n+      String md5 = (String) result[13];\n+\n+      if (md5 != null) {\n+        dataFile.setChecksumValue(md5);\n+      }\n+\n+      Boolean restricted = (Boolean) result[14];\n+      if (restricted != null) {\n+        dataFile.setRestricted(restricted);\n+      }\n+\n+      String checksumType = (String) result[15];\n+      if (checksumType != null) {\n+        try {\n+          // In the database we store \"SHA1\" rather than \"SHA-1\".\n+          DataFile.ChecksumType typeFromStringInDatabase = DataFile.ChecksumType.valueOf(checksumType);\n+          dataFile.setChecksumType(typeFromStringInDatabase);\n+        } catch (IllegalArgumentException ex) {\n+          logger.info(\"Exception trying to convert \" + checksumType + \" to enum: \" + ex);\n         }\n-        \n-        logger.fine(\"Retrieved \"+i+\" file categories attached to the dataset.\");\n+      }\n+\n+      Long previousDataFileId = (Long) result[16];\n+      if (previousDataFileId != null) {\n+        dataFile.setPreviousDataFileId(previousDataFileId);\n+      }\n+\n+      Long rootDataFileId = (Long) result[17];\n+      if (rootDataFileId != null) {\n+        dataFile.setRootDataFileId(rootDataFileId);\n+      }\n+\n+      String protocol = (String) result[18];\n+      if (protocol != null) {\n+        dataFile.setProtocol(protocol);\n+      }\n+\n+      String authority = (String) result[19];\n+      if (authority != null) {\n+        dataFile.setAuthority(authority);\n+      }\n+\n+      String identifier = (String) result[20];\n+      if (identifier != null) {\n+        dataFile.setIdentifier(identifier);\n+      }\n+\n+      // TODO:\n+      // - if ingest status is \"bad\", look up the ingest report;\n+      // - is it a dedicated thumbnail for the dataset? (do we ever need that info?? - not on the dataset page, I don't think...)\n+\n+      // Is this a tabular file?\n+\n+      if (datatableMap.get(dataFile.getId()) != null) {\n+        dataTables.get(datatableMap.get(dataFile.getId())).setDataFile(dataFile);\n+        dataFile.setDataTable(dataTables.get(datatableMap.get(dataFile.getId())));\n+\n+      }\n+\n+      if (fileTagMap.get(dataFile.getId()) != null) {\n+        for (Integer tag_id : fileTagMap.get(dataFile.getId())) {\n+          DataFileTag tag = new DataFileTag();\n+          tag.setTypeByLabel(fileTagLabels.get(tag_id));\n+          tag.setDataFile(dataFile);\n+          dataFile.addTag(tag);\n+        }\n+      }\n+\n+      if (dataFile.isRestricted() && accessRequestFileIds.contains(dataFile.getId())) {\n+        dataFile.setFileAccessRequesters(Collections.singletonList(au));\n+      }\n+\n+      dataFiles.add(dataFile);\n+      filesMap.put(dataFile.getId(), i++);\n+    }\n+    fileResults = null;\n+\n+    logger.fine(\"Retrieved and cached \" + i + \" datafiles.\");\n+\n+    i = 0;\n+    for (DataFileCategory fileCategory : owner.getCategories()) {\n+      //logger.fine(\"category: id=\"+fileCategory.getId());\n+      categoryMap.put(fileCategory.getId(), i++);\n+    }\n \n-        version.setFileMetadatas(retrieveFileMetadataForVersion(owner, version, dataFiles, filesMap, categoryMap));\n-        logger.fine(\"Retrieved \" + version.getFileMetadatas().size() + \" filemetadatas for the version \" + version.getId());\n-        owner.setFiles(dataFiles);\n+    logger.fine(\"Retrieved \" + i + \" file categories attached to the dataset.\");\n+\n+    version.setFileMetadatas(retrieveFileMetadataForVersion(owner, version, dataFiles, filesMap, categoryMap));\n+    logger.fine(\"Retrieved \" + version.getFileMetadatas().size() + \" filemetadatas for the version \" + version.getId());\n+    owner.setFiles(dataFiles);\n+  }\n+\n+  private List<FileMetadata> retrieveFileMetadataForVersion(Dataset dataset, DatasetVersion version,\n+                                                            List<DataFile> dataFiles, Map<Long, Integer> filesMap,\n+                                                            Map<Long, Integer> categoryMap) {\n+    List<FileMetadata> retList = new ArrayList<>();\n+    Map<Long, Set<Long>> categoryMetaMap = new HashMap<>();\n+\n+    List<Object[]> categoryResults = em.createNativeQuery(\n+      \"select t0.filecategories_id, t0.filemetadatas_id from filemetadata_datafilecategory t0, filemetadata t1 where (t0.filemetadatas_id = t1.id) AND (t1.datasetversion_id = \" +\n+        version.getId() + \")\").getResultList();\n+    int i = 0;\n+    for (Object[] result : categoryResults) {\n+      Long category_id = (Long) result[0];\n+      Long filemeta_id = (Long) result[1];\n+      if (categoryMetaMap.get(filemeta_id) == null) {\n+        categoryMetaMap.put(filemeta_id, new HashSet<>());\n+      }\n+      categoryMetaMap.get(filemeta_id).add(category_id);\n+      i++;\n     }\n-    \n-    private List<FileMetadata> retrieveFileMetadataForVersion(Dataset dataset, DatasetVersion version, List<DataFile> dataFiles, Map<Long, Integer> filesMap, Map<Long, Integer> categoryMap) {\n-        List<FileMetadata> retList = new ArrayList<>();\n-        Map<Long, Set<Long>> categoryMetaMap = new HashMap<>();\n-        \n-        List<Object[]> categoryResults = em.createNativeQuery(\"select t0.filecategories_id, t0.filemetadatas_id from filemetadata_datafilecategory t0, filemetadata t1 where (t0.filemetadatas_id = t1.id) AND (t1.datasetversion_id = \"+version.getId()+\")\").getResultList();\n-        int i = 0;\n-        for (Object[] result : categoryResults) {\n-            Long category_id = (Long) result[0];\n-            Long filemeta_id = (Long) result[1];\n-            if (categoryMetaMap.get(filemeta_id) == null) {\n-                categoryMetaMap.put(filemeta_id, new HashSet<>());\n-            }\n-            categoryMetaMap.get(filemeta_id).add(category_id);\n-            i++;\n-        }\n-        logger.fine(\"Retrieved and mapped \"+i+\" file categories attached to files in the version \"+version.getId());\n-        \n-        List<Object[]> metadataResults = em.createNativeQuery(\"select id, datafile_id, DESCRIPTION, LABEL, RESTRICTED, DIRECTORYLABEL, prov_freeform from FileMetadata where datasetversion_id = \"+version.getId() + \" ORDER BY LABEL\").getResultList();\n-        \n-        for (Object[] result : metadataResults) {\n-            Integer filemeta_id = (Integer) result[0];\n-            \n-            if (filemeta_id == null) {\n-                continue;\n-            }\n-            \n-            Long file_id = (Long) result[1];\n-            if (file_id == null) {\n-                continue;\n-            }\n-            \n-            Integer file_list_id = filesMap.get(file_id);\n-            if (file_list_id == null) {\n-                continue;\n-            }\n-            FileMetadata fileMetadata = new FileMetadata();\n-            fileMetadata.setId(filemeta_id.longValue());\n-            fileMetadata.setCategories(new LinkedList<>());\n-\n-            if (categoryMetaMap.get(fileMetadata.getId()) != null) {\n-                for (Long cat_id : categoryMetaMap.get(fileMetadata.getId())) {\n-                    if (categoryMap.get(cat_id) != null) {\n-                        fileMetadata.getCategories().add(dataset.getCategories().get(categoryMap.get(cat_id)));\n-                    }\n-                }\n-            }\n-\n-            fileMetadata.setDatasetVersion(version);\n-            \n-            // Link the FileMetadata object to the DataFile:\n-            fileMetadata.setDataFile(dataFiles.get(file_list_id));\n-            // ... and the DataFile back to the FileMetadata:\n-            fileMetadata.getDataFile().getFileMetadatas().add(fileMetadata);\n-            \n-            String description = (String) result[2]; \n-            \n-            if (description != null) {\n-                fileMetadata.setDescription(description);\n-            }\n-            \n-            String label = (String) result[3];\n-            \n-            if (label != null) {\n-                fileMetadata.setLabel(label);\n-            }\n-                        \n-            Boolean restricted = (Boolean) result[4];\n-            if (restricted != null) {\n-                fileMetadata.setRestricted(restricted);\n-            }\n-            \n-            String dirLabel = (String) result[5];\n-            if (dirLabel != null){\n-                fileMetadata.setDirectoryLabel(dirLabel);\n-            }\n-            \n-            String provFreeForm = (String) result[6];\n-            if (provFreeForm != null){\n-                fileMetadata.setProvFreeForm(provFreeForm);\n-            }\n-                        \n-            retList.add(fileMetadata);\n+    logger.fine(\"Retrieved and mapped \" + i + \" file categories attached to files in the version \" + version.getId());\n+\n+    List<Object[]> metadataResults = em.createNativeQuery(\n+      \"select id, datafile_id, DESCRIPTION, LABEL, RESTRICTED, DIRECTORYLABEL, prov_freeform from FileMetadata where datasetversion_id = \" +\n+        version.getId() + \" ORDER BY LABEL\").getResultList();\n+\n+    for (Object[] result : metadataResults) {\n+      Integer filemeta_id = (Integer) result[0];\n+\n+      if (filemeta_id == null) {\n+        continue;\n+      }\n+\n+      Long file_id = (Long) result[1];\n+      if (file_id == null) {\n+        continue;\n+      }\n+\n+      Integer file_list_id = filesMap.get(file_id);\n+      if (file_list_id == null) {\n+        continue;\n+      }\n+      FileMetadata fileMetadata = new FileMetadata();\n+      fileMetadata.setId(filemeta_id.longValue());\n+      fileMetadata.setCategories(new LinkedList<>());\n+\n+      if (categoryMetaMap.get(fileMetadata.getId()) != null) {\n+        for (Long cat_id : categoryMetaMap.get(fileMetadata.getId())) {\n+          if (categoryMap.get(cat_id) != null) {\n+            fileMetadata.getCategories().add(dataset.getCategories().get(categoryMap.get(cat_id)));\n+          }\n         }\n-        \n-        logger.fine(\"Retrieved \"+retList.size()+\" file metadatas for version \"+version.getId()+\" (inside the retrieveFileMetadataForVersion method).\");\n+      }\n+\n+      fileMetadata.setDatasetVersion(version);\n+\n+      // Link the FileMetadata object to the DataFile:\n+      fileMetadata.setDataFile(dataFiles.get(file_list_id));\n+      // ... and the DataFile back to the FileMetadata:\n+      fileMetadata.getDataFile().getFileMetadatas().add(fileMetadata);\n+\n+      String description = (String) result[2];\n+\n+      if (description != null) {\n+        fileMetadata.setDescription(description);\n+      }\n+\n+      String label = (String) result[3];\n+\n+      if (label != null) {\n+        fileMetadata.setLabel(label);\n+      }\n+\n+      Boolean restricted = (Boolean) result[4];\n+      if (restricted != null) {\n+        fileMetadata.setRestricted(restricted);\n+      }\n+\n+      String dirLabel = (String) result[5];\n+      if (dirLabel != null) {\n+        fileMetadata.setDirectoryLabel(dirLabel);\n+      }\n+\n+      String provFreeForm = (String) result[6];\n+      if (provFreeForm != null) {\n+        fileMetadata.setProvFreeForm(provFreeForm);\n+      }\n+\n+      retList.add(fileMetadata);\n+    }\n+\n+    logger.fine(\"Retrieved \" + retList.size() + \" file metadatas for version \" + version.getId() +\n+      \" (inside the retrieveFileMetadataForVersion method).\");\n                 \n         \n         /* \n@@ -900,189 +941,197 @@ public class DataFileServiceBean implements java.io.Serializable {\n             method should be called. \n         \n         Collections.sort(retList, FileMetadata.compareByLabel); */\n-        \n-        return retList; \n+\n+    return retList;\n+  }\n+\n+  public List<DataFile> findIngestsInProgress() {\n+    if (em.isOpen()) {\n+      String qr =\n+        \"select object(o) from DataFile as o where o.ingestStatus =:scheduledStatusCode or o.ingestStatus =:progressStatusCode order by o.id\";\n+      return em.createQuery(qr, DataFile.class)\n+        .setParameter(\"scheduledStatusCode\", DataFile.INGEST_STATUS_SCHEDULED)\n+        .setParameter(\"progressStatusCode\", DataFile.INGEST_STATUS_INPROGRESS)\n+        .getResultList();\n+    } else {\n+      return Collections.emptyList();\n     }\n-    \n-    public List<DataFile> findIngestsInProgress() {\n-        if ( em.isOpen() ) {\n-            String qr = \"select object(o) from DataFile as o where o.ingestStatus =:scheduledStatusCode or o.ingestStatus =:progressStatusCode order by o.id\";\n-            return em.createQuery(qr, DataFile.class)\n-                .setParameter(\"scheduledStatusCode\", DataFile.INGEST_STATUS_SCHEDULED)\n-                .setParameter(\"progressStatusCode\", DataFile.INGEST_STATUS_INPROGRESS)\n-                .getResultList();\n-        } else {\n-            return Collections.emptyList();\n-        }\n+  }\n+\n+\n+  public DataTable findDataTableByFileId(Long fileId) {\n+    Query query = em.createQuery(\"select object(o) from DataTable as o where o.dataFile.id =:fileId order by o.id\");\n+    query.setParameter(\"fileId\", fileId);\n+\n+    Object singleResult;\n+\n+    try {\n+      return (DataTable) query.getSingleResult();\n+    } catch (NoResultException ex) {\n+      return null;\n     }\n-    \n-    \n-    public DataTable findDataTableByFileId(Long fileId) {\n-        Query query = em.createQuery(\"select object(o) from DataTable as o where o.dataFile.id =:fileId order by o.id\");\n-        query.setParameter(\"fileId\", fileId);\n-        \n-        Object singleResult;\n-        \n-        try{\n-            return (DataTable)query.getSingleResult();\n-        }catch(NoResultException ex){\n-            return null;\n-        }\n-    }\n-    \n-    public List<DataFile> findAll() {\n-        return em.createQuery(\"select object(o) from DataFile as o order by o.id\", DataFile.class).getResultList();\n-    }\n-    \n-    public DataFile save(DataFile dataFile) {\n+  }\n \n-        if (dataFile.isMergeable()) {   \n-            DataFile savedDataFile = em.merge(dataFile);\n-            return savedDataFile;\n-        } else {\n-            throw new IllegalArgumentException(\"This DataFile object has been set to NOT MERGEABLE; please ensure a MERGEABLE object is passed to the save method.\");\n-        } \n-    }\n-    \n-    @TransactionAttribute(TransactionAttributeType.REQUIRES_NEW)\n-    public DataFile saveInTransaction(DataFile dataFile) {\n+  public List<DataFile> findAll() {\n+    return em.createQuery(\"select object(o) from DataFile as o order by o.id\", DataFile.class).getResultList();\n+  }\n \n-        if (dataFile.isMergeable()) {   \n-            DataFile savedDataFile = em.merge(dataFile);\n-            return savedDataFile;\n-        } else {\n-            throw new IllegalArgumentException(\"This DataFile object has been set to NOT MERGEABLE; please ensure a MERGEABLE object is passed to the save method.\");\n-        } \n-    }\n-    \n-    private void msg(String m){\n-        System.out.println(m);\n-    }\n-    private void dashes(){\n-        msg(\"----------------\");\n-    }\n-    private void msgt(String m){\n-        dashes(); msg(m); dashes();\n-    }\n-    \n-    /*\n-        Make sure the file replace ids are set for a initial version \n-        of a file\n-    \n-    */\n-    public DataFile setAndCheckFileReplaceAttributes(DataFile savedDataFile){\n-               \n-        // Is this the initial version of a file?\n-        \n-        if ((savedDataFile.getRootDataFileId() == null)||\n-                (savedDataFile.getRootDataFileId().equals(DataFile.ROOT_DATAFILE_ID_DEFAULT))){\n-            msg(\"yes, initial version\");\n- \n-           // YES!  Set the RootDataFileId to the Id\n-           savedDataFile.setRootDataFileId(savedDataFile.getId());\n-           \n-           // SAVE IT AGAIN!!!\n-           msg(\"yes, save again\");\n-        \n-            return em.merge(savedDataFile);   \n-           \n-        }else{       \n-            // Looking Good Billy Ray! Feeling Good Louis!    \n-            msg(\"nope, looks ok\");\n+  public DataFile save(DataFile dataFile) {\n \n-            return savedDataFile;\n-        }\n+    if (dataFile.isMergeable()) {\n+      DataFile savedDataFile = em.merge(dataFile);\n+      return savedDataFile;\n+    } else {\n+      throw new IllegalArgumentException(\n+        \"This DataFile object has been set to NOT MERGEABLE; please ensure a MERGEABLE object is passed to the save method.\");\n     }\n-    \n-    \n-    public Boolean isPreviouslyPublished(Long fileId){\n-        Query query = em.createQuery(\"select object(o) from FileMetadata as o where o.dataFile.id =:fileId\");\n-        query.setParameter(\"fileId\", fileId);\n-        List<?> retList = query.getResultList();\n-        return (retList.size() > 1);\n+  }\n+\n+  @TransactionAttribute(TransactionAttributeType.REQUIRES_NEW)\n+  public DataFile saveInTransaction(DataFile dataFile) {\n+\n+    if (dataFile.isMergeable()) {\n+      DataFile savedDataFile = em.merge(dataFile);\n+      return savedDataFile;\n+    } else {\n+      throw new IllegalArgumentException(\n+        \"This DataFile object has been set to NOT MERGEABLE; please ensure a MERGEABLE object is passed to the save method.\");\n     }\n-    \n-    public void deleteFromVersion( DatasetVersion d, DataFile f ) {\n-\t\tem.createNamedQuery(\"DataFile.removeFromDatasetVersion\")\n-\t\t\t.setParameter(\"versionId\", d.getId()).setParameter(\"fileId\", f.getId())\n-\t\t\t\t.executeUpdate();\n+  }\n+\n+  private void msg(String m) {\n+    System.out.println(m);\n+  }\n+\n+  private void dashes() {\n+    msg(\"----------------\");\n+  }\n+\n+  private void msgt(String m) {\n+    dashes();\n+    msg(m);\n+    dashes();\n+  }\n+\n+  /*\n+      Make sure the file replace ids are set for a initial version\n+      of a file\n+\n+  */\n+  public DataFile setAndCheckFileReplaceAttributes(DataFile savedDataFile) {\n+\n+    // Is this the initial version of a file?\n+\n+    if ((savedDataFile.getRootDataFileId() == null) ||\n+      (savedDataFile.getRootDataFileId().equals(DataFile.ROOT_DATAFILE_ID_DEFAULT))) {\n+      msg(\"yes, initial version\");\n+\n+      // YES!  Set the RootDataFileId to the Id\n+      savedDataFile.setRootDataFileId(savedDataFile.getId());\n+\n+      // SAVE IT AGAIN!!!\n+      msg(\"yes, save again\");\n+\n+      return em.merge(savedDataFile);\n+\n+    } else {\n+      // Looking Good Billy Ray! Feeling Good Louis!\n+      msg(\"nope, looks ok\");\n+\n+      return savedDataFile;\n     }\n+  }\n+\n+\n+  public Boolean isPreviouslyPublished(Long fileId) {\n+    Query query = em.createQuery(\"select object(o) from FileMetadata as o where o.dataFile.id =:fileId\");\n+    query.setParameter(\"fileId\", fileId);\n+    List<?> retList = query.getResultList();\n+    return (retList.size() > 1);\n+  }\n+\n+  public void deleteFromVersion(DatasetVersion d, DataFile f) {\n+    em.createNamedQuery(\"DataFile.removeFromDatasetVersion\")\n+      .setParameter(\"versionId\", d.getId()).setParameter(\"fileId\", f.getId())\n+      .executeUpdate();\n+  }\n \n     /* \n      Convenience methods for merging and removingindividual file metadatas, \n      without touching the rest of the DataFile object:\n     */\n-    \n-    public FileMetadata mergeFileMetadata(FileMetadata fileMetadata) {\n-        \n-        FileMetadata newFileMetadata = em.merge(fileMetadata);\n-        em.flush();\n-        \n-        // Set the initial value of the rootDataFileId\n-        //    (does nothing if it's already set)\n-        //DataFile updatedDataFile = setAndCheckFileReplaceAttributes(newFileMetadata.getDataFile());\n-               \n-        return newFileMetadata;\n-    }\n-    \n-    public void removeFileMetadata(FileMetadata fileMetadata) {\n-        msgt(\"removeFileMetadata: fileMetadata\");\n-        FileMetadata mergedFM = em.merge(fileMetadata);\n-        em.remove(mergedFM);\n-    }\n-    \n-    /* \n-     * Same, for DataTables:\n-    */\n-    \n-    public DataTable saveDataTable(DataTable dataTable) {\n-        DataTable merged = em.merge(dataTable);\n-        em.flush();\n-        return merged;\n-    }\n-    \n-    public List<DataFile> findHarvestedFilesByClient(HarvestingClient harvestingClient) {\n-        String qr = \"SELECT d FROM DataFile d, DvObject o, Dataset s WHERE o.id = d.id AND o.owner.id = s.id AND s.harvestedFrom.id = :harvestingClientId\";\n-        return em.createQuery(qr, DataFile.class)\n-            .setParameter(\"harvestingClientId\", harvestingClient.getId())\n-            .getResultList();\n-    }\n-    \n-    /*moving to the fileutil*/\n-    \n-    public void generateStorageIdentifier(DataFile dataFile) {\n-        dataFile.setStorageIdentifier(generateStorageIdentifier());\n-    }\n-    \n-    public String generateStorageIdentifier() {\n-        \n-        UUID uid = UUID.randomUUID();\n-                \n-        logger.log(Level.FINE, \"UUID value: {0}\", uid.toString());\n-        \n-        // last 6 bytes, of the random UUID, in hex: \n-        \n-        String hexRandom = uid.toString().substring(24);\n-        \n-        logger.log(Level.FINE, \"UUID (last 6 bytes, 12 hex digits): {0}\", hexRandom);\n-        \n-        String hexTimestamp = Long.toHexString(new Date().getTime());\n-        \n-        logger.log(Level.FINE, \"(not UUID) timestamp in hex: {0}\", hexTimestamp);\n-            \n-        String storageIdentifier = hexTimestamp + \"-\" + hexRandom;\n-        \n-        logger.log(Level.FINE, \"timestamp/UUID hybrid: {0}\", storageIdentifier);\n-        return storageIdentifier; \n-    }\n-    \n-    public boolean isSpssPorFile (DataFile file) {\n-        return (file != null) ? MIME_TYPE_SPSS_POR.equalsIgnoreCase(file.getContentType()) : false;\n-    }\n-    \n-    public boolean isSpssSavFile (DataFile file) {\n-        return (file != null) ? MIME_TYPE_SPSS_SAV.equalsIgnoreCase(file.getContentType()) : false;\n-    }\n+\n+  public FileMetadata mergeFileMetadata(FileMetadata fileMetadata) {\n+\n+    FileMetadata newFileMetadata = em.merge(fileMetadata);\n+    em.flush();\n+\n+    // Set the initial value of the rootDataFileId\n+    //    (does nothing if it's already set)\n+    //DataFile updatedDataFile = setAndCheckFileReplaceAttributes(newFileMetadata.getDataFile());\n+\n+    return newFileMetadata;\n+  }\n+\n+  public void removeFileMetadata(FileMetadata fileMetadata) {\n+    msgt(\"removeFileMetadata: fileMetadata\");\n+    FileMetadata mergedFM = em.merge(fileMetadata);\n+    em.remove(mergedFM);\n+  }\n+\n+  /*\n+   * Same, for DataTables:\n+   */\n+\n+  public DataTable saveDataTable(DataTable dataTable) {\n+    DataTable merged = em.merge(dataTable);\n+    em.flush();\n+    return merged;\n+  }\n+\n+  public List<DataFile> findHarvestedFilesByClient(HarvestingClient harvestingClient) {\n+    String qr =\n+      \"SELECT d FROM DataFile d, DvObject o, Dataset s WHERE o.id = d.id AND o.owner.id = s.id AND s.harvestedFrom.id = :harvestingClientId\";\n+    return em.createQuery(qr, DataFile.class)\n+      .setParameter(\"harvestingClientId\", harvestingClient.getId())\n+      .getResultList();\n+  }\n+\n+  /*moving to the fileutil*/\n+\n+  public void generateStorageIdentifier(DataFile dataFile) {\n+    dataFile.setStorageIdentifier(generateStorageIdentifier());\n+  }\n+\n+  public String generateStorageIdentifier() {\n+\n+    UUID uid = UUID.randomUUID();\n+\n+    logger.log(Level.FINE, \"UUID value: {0}\", uid.toString());\n+\n+    // last 6 bytes, of the random UUID, in hex:\n+\n+    String hexRandom = uid.toString().substring(24);\n+\n+    logger.log(Level.FINE, \"UUID (last 6 bytes, 12 hex digits): {0}\", hexRandom);\n+\n+    String hexTimestamp = Long.toHexString(new Date().getTime());\n+\n+    logger.log(Level.FINE, \"(not UUID) timestamp in hex: {0}\", hexTimestamp);\n+\n+    String storageIdentifier = hexTimestamp + \"-\" + hexRandom;\n+\n+    logger.log(Level.FINE, \"timestamp/UUID hybrid: {0}\", storageIdentifier);\n+    return storageIdentifier;\n+  }\n+\n+  public boolean isSpssPorFile(DataFile file) {\n+    return (file != null) ? MIME_TYPE_SPSS_POR.equalsIgnoreCase(file.getContentType()) : false;\n+  }\n+\n+  public boolean isSpssSavFile(DataFile file) {\n+    return (file != null) ? MIME_TYPE_SPSS_SAV.equalsIgnoreCase(file.getContentType()) : false;\n+  }\n     \n     /*\n     public boolean isSpssPorFile (FileMetadata fileMetadata) {\n@@ -1092,29 +1141,29 @@ public class DataFileServiceBean implements java.io.Serializable {\n         return false; \n     }\n     */\n-    \n-    /*\n-     * This method will return true if the thumbnail is *actually available* and\n-     * ready to be downloaded. (it will try to generate a thumbnail for supported\n-     * file types, if not yet available)\n-     */\n-    public boolean isThumbnailAvailable (DataFile file) {\n-        if (file == null) {\n-            return false; \n-        } \n-\n-        // If this file already has the \"thumbnail generated\" flag set,\n-        // we'll just trust that:\n-        if (file.isPreviewImageAvailable()) {\n-            logger.fine(\"returning true\");\n-            return true;\n-        }\n-        \n-        // If thumbnails are not even supported for this class of files, \n-        // there's notthing to talk about:      \n-        if (!FileUtil.isThumbnailSupported(file)) {\n-            return false;\n-        }\n+\n+  /*\n+   * This method will return true if the thumbnail is *actually available* and\n+   * ready to be downloaded. (it will try to generate a thumbnail for supported\n+   * file types, if not yet available)\n+   */\n+  public boolean isThumbnailAvailable(DataFile file) {\n+    if (file == null) {\n+      return false;\n+    }\n+\n+    // If this file already has the \"thumbnail generated\" flag set,\n+    // we'll just trust that:\n+    if (file.isPreviewImageAvailable()) {\n+      logger.fine(\"returning true\");\n+      return true;\n+    }\n+\n+    // If thumbnails are not even supported for this class of files,\n+    // there's notthing to talk about:\n+    if (!FileUtil.isThumbnailSupported(file)) {\n+      return false;\n+    }\n         \n         /*\n          Checking the permission here was resulting in extra queries; \n@@ -1126,154 +1175,153 @@ public class DataFileServiceBean implements java.io.Serializable {\n          is more important... \n         \n         */\n-                \n-        \n-       if (ImageThumbConverter.isThumbnailAvailable(file)) {\n-           file = this.find(file.getId());\n-           file.setPreviewImageAvailable(true);\n-           this.save(file); \n-           return true;\n-       }\n \n-       return false;\n+\n+    if (ImageThumbConverter.isThumbnailAvailable(file)) {\n+      file = this.find(file.getId());\n+      file.setPreviewImageAvailable(true);\n+      this.save(file);\n+      return true;\n     }\n \n-    \n-    /* \n-     * Methods for identifying \"classes\" (groupings) of files by type:\n-    */\n-    \n-    public String getFileClassById (Long fileId) {\n-        DataFile file = find(fileId);\n-        \n-        if (file == null) {\n-            return null; \n-        }\n-        \n-        return getFileThumbnailClass(file);\n+    return false;\n+  }\n+\n+\n+  /*\n+   * Methods for identifying \"classes\" (groupings) of files by type:\n+   */\n+\n+  public String getFileClassById(Long fileId) {\n+    DataFile file = find(fileId);\n+\n+    if (file == null) {\n+      return null;\n     }\n-    \n-    public String getFileThumbnailClass (DataFile file) {\n-        // there's no solr search facet for \"package files\", but\n-        // there is a special thumbnail icon:\n-        if (isFileClassPackage(file)) {\n-            return FileUtil.FILE_THUMBNAIL_CLASS_PACKAGE;\n-        }\n-        \n-        if (file != null) {\n-            String fileTypeFacet = FileUtil.getFacetFileType(file);\n-        \n-            if (fileTypeFacet != null && FileUtil.FILE_THUMBNAIL_CLASSES.containsKey(fileTypeFacet)) {\n-                return FileUtil.FILE_THUMBNAIL_CLASSES.get(fileTypeFacet);\n-            }\n-        }\n-        \n-        return FileUtil.FILE_THUMBNAIL_CLASS_OTHER;\n+\n+    return getFileThumbnailClass(file);\n+  }\n+\n+  public String getFileThumbnailClass(DataFile file) {\n+    // there's no solr search facet for \"package files\", but\n+    // there is a special thumbnail icon:\n+    if (isFileClassPackage(file)) {\n+      return FileUtil.FILE_THUMBNAIL_CLASS_PACKAGE;\n     }\n-    \n-    \n-    \n-    public boolean isFileClassImage (DataFile file) {\n-        if (file == null) {\n-            return false;\n-        }\n-        \n-        String contentType = file.getContentType();\n \n-        // Some browsers (Chrome?) seem to identify FITS files as mime\n-        // type \"image/fits\" on upload; this is both incorrect (the official\n-        // mime type for FITS is \"application/fits\", and problematic: then\n-        // the file is identified as an image, and the page will attempt to \n-        // generate a preview - which of course is going to fail...\n-        \n-        if (FileUtil.MIME_TYPE_FITSIMAGE.equalsIgnoreCase(contentType)) {\n-            return false;\n-        }\n-        // besides most image/* types, we can generate thumbnails for \n-        // pdf and \"world map\" files:\n-        \n-        return (contentType != null && (contentType.toLowerCase().startsWith(\"image/\")));\n+    if (file != null) {\n+      String fileTypeFacet = FileUtil.getFacetFileType(file);\n+\n+      if (fileTypeFacet != null && FileUtil.FILE_THUMBNAIL_CLASSES.containsKey(fileTypeFacet)) {\n+        return FileUtil.FILE_THUMBNAIL_CLASSES.get(fileTypeFacet);\n+      }\n     }\n-    \n-    public boolean isFileClassAudio (DataFile file) {\n-        if (file == null) {\n-            return false;\n-        }\n-        \n-        String contentType = file.getContentType();\n-        \n-        // TODO: \n-        // verify that there are no audio types that don't start with \"audio/\" - \n-        //  some exotic mp[34]... ?\n-        \n-        return (contentType != null && (contentType.toLowerCase().startsWith(\"audio/\")));    \n+\n+    return FileUtil.FILE_THUMBNAIL_CLASS_OTHER;\n+  }\n+\n+\n+  public boolean isFileClassImage(DataFile file) {\n+    if (file == null) {\n+      return false;\n     }\n-    \n-    public boolean isFileClassCode (DataFile file) {\n-        if (file == null) {\n-            return false;\n-        }\n-     \n-        String contentType = file.getContentType();\n-        \n-        // The following are the \"control card/syntax\" formats that we recognize \n-        // as \"code\":\n-    \n-        return (MIME_TYPE_R_SYNTAX.equalsIgnoreCase(contentType)\n-            || MIME_TYPE_STATA_SYNTAX.equalsIgnoreCase(contentType) \n-            || MIME_TYPE_SAS_SYNTAX.equalsIgnoreCase(contentType)\n-            || MIME_TYPE_SPSS_CCARD.equalsIgnoreCase(contentType));\n-        \n+\n+    String contentType = file.getContentType();\n+\n+    // Some browsers (Chrome?) seem to identify FITS files as mime\n+    // type \"image/fits\" on upload; this is both incorrect (the official\n+    // mime type for FITS is \"application/fits\", and problematic: then\n+    // the file is identified as an image, and the page will attempt to\n+    // generate a preview - which of course is going to fail...\n+\n+    if (FileUtil.MIME_TYPE_FITSIMAGE.equalsIgnoreCase(contentType)) {\n+      return false;\n     }\n-    \n-    public boolean isFileClassDocument (DataFile file) {\n-        if (file == null) {\n-            return false;\n-        }\n-        \n-        //\u00a0\"Documents\": PDF, assorted MS docs, etc. \n-        \n-        String contentType = file.getContentType();\n-        int scIndex = 0;\n-        if (contentType != null && (scIndex = contentType.indexOf(';')) > 0) {\n-            contentType = contentType.substring(0, scIndex);\n-        }\n-        \n-        return (MIME_TYPE_PLAIN_TEXT.equalsIgnoreCase(contentType)\n-            || MIME_TYPE_DOCUMENT_PDF.equalsIgnoreCase(contentType)\n-            || MIME_TYPE_DOCUMENT_MSWORD.equalsIgnoreCase(contentType)\n-            || MIME_TYPE_DOCUMENT_MSEXCEL.equalsIgnoreCase(contentType)\n-            || MIME_TYPE_DOCUMENT_MSWORD_OPENXML.equalsIgnoreCase(contentType));\n-        \n+    // besides most image/* types, we can generate thumbnails for\n+    // pdf and \"world map\" files:\n+\n+    return (contentType != null && (contentType.toLowerCase().startsWith(\"image/\")));\n+  }\n+\n+  public boolean isFileClassAudio(DataFile file) {\n+    if (file == null) {\n+      return false;\n     }\n-    \n-    public boolean isFileClassAstro (DataFile file) {\n-        if (file == null) {\n-            return false;\n-        }\n-        \n-        String contentType = file.getContentType();\n-       \n-        // The only known/supported \"Astro\" file type is FITS,\n-        // so far:\n-        \n-        return (MIME_TYPE_FITS.equalsIgnoreCase(contentType) || FileUtil.MIME_TYPE_FITSIMAGE.equalsIgnoreCase(contentType));\n-        \n+\n+    String contentType = file.getContentType();\n+\n+    // TODO:\n+    // verify that there are no audio types that don't start with \"audio/\" -\n+    //  some exotic mp[34]... ?\n+\n+    return (contentType != null && (contentType.toLowerCase().startsWith(\"audio/\")));\n+  }\n+\n+  public boolean isFileClassCode(DataFile file) {\n+    if (file == null) {\n+      return false;\n     }\n-    \n-    public boolean isFileClassNetwork (DataFile file) {\n-        if (file == null) {\n-            return false;\n-        }\n-        \n-        String contentType = file.getContentType();\n-       \n-        // The only known/supported Network Data type is GRAPHML,\n-        // so far:\n-        \n-        return MIME_TYPE_NETWORK_GRAPHML.equalsIgnoreCase(contentType);\n-        \n+\n+    String contentType = file.getContentType();\n+\n+    // The following are the \"control card/syntax\" formats that we recognize\n+    // as \"code\":\n+\n+    return (MIME_TYPE_R_SYNTAX.equalsIgnoreCase(contentType)\n+      || MIME_TYPE_STATA_SYNTAX.equalsIgnoreCase(contentType)\n+      || MIME_TYPE_SAS_SYNTAX.equalsIgnoreCase(contentType)\n+      || MIME_TYPE_SPSS_CCARD.equalsIgnoreCase(contentType));\n+\n+  }\n+\n+  public boolean isFileClassDocument(DataFile file) {\n+    if (file == null) {\n+      return false;\n+    }\n+\n+    //\u00a0\"Documents\": PDF, assorted MS docs, etc.\n+\n+    String contentType = file.getContentType();\n+    int scIndex = 0;\n+    if (contentType != null && (scIndex = contentType.indexOf(';')) > 0) {\n+      contentType = contentType.substring(0, scIndex);\n+    }\n+\n+    return (MIME_TYPE_PLAIN_TEXT.equalsIgnoreCase(contentType)\n+      || MIME_TYPE_DOCUMENT_PDF.equalsIgnoreCase(contentType)\n+      || MIME_TYPE_DOCUMENT_MSWORD.equalsIgnoreCase(contentType)\n+      || MIME_TYPE_DOCUMENT_MSEXCEL.equalsIgnoreCase(contentType)\n+      || MIME_TYPE_DOCUMENT_MSWORD_OPENXML.equalsIgnoreCase(contentType));\n+\n+  }\n+\n+  public boolean isFileClassAstro(DataFile file) {\n+    if (file == null) {\n+      return false;\n     }\n+\n+    String contentType = file.getContentType();\n+\n+    // The only known/supported \"Astro\" file type is FITS,\n+    // so far:\n+\n+    return (MIME_TYPE_FITS.equalsIgnoreCase(contentType) || FileUtil.MIME_TYPE_FITSIMAGE.equalsIgnoreCase(contentType));\n+\n+  }\n+\n+  public boolean isFileClassNetwork(DataFile file) {\n+    if (file == null) {\n+      return false;\n+    }\n+\n+    String contentType = file.getContentType();\n+\n+    // The only known/supported Network Data type is GRAPHML,\n+    // so far:\n+\n+    return MIME_TYPE_NETWORK_GRAPHML.equalsIgnoreCase(contentType);\n+\n+  }\n     \n     /* \n      * we don't really need a method for \"other\" - \n@@ -1286,347 +1334,358 @@ public class DataFileServiceBean implements java.io.Serializable {\n         \n     }\n     */\n-    \n-    public boolean isFileClassGeo (DataFile file) {\n-        if (file == null) {\n-            return false;\n-        }\n-        \n-        String contentType = file.getContentType();\n-       \n-        // The only known/supported Geo Data type is SHAPE,\n-        // so far:\n-        \n-        return FileUtil.MIME_TYPE_GEO_SHAPE.equalsIgnoreCase(contentType);\n+\n+  public boolean isFileClassGeo(DataFile file) {\n+    if (file == null) {\n+      return false;\n     }\n-    \n-    public boolean isFileClassTabularData (DataFile file) {\n-        if (file == null) {\n-            return false;\n-        }\n-        \n-        // \"Tabular data\" is EITHER an INGESTED tabular data file, i.e.\n-        // a file with a DataTable and DataVariables; or a DataFile \n-        // of one of the many known tabular data formats - SPSS, Stata, etc.\n-        // that for one reason or another didn't get ingested: \n-        \n-        if (file.isTabularData()) {\n-            return true; \n-        }\n-        \n-        // The formats we know how to ingest: \n-        if (FileUtil.canIngestAsTabular(file)) {\n-            return true;\n-        }\n-        \n-        String contentType = file.getContentType();\n-        \n-        // And these are the formats we DON'T know how to ingest, \n-        // but nevertheless recognize as \"tabular data\":\n-        \n-        return (MIME_TYPE_TSV.equalsIgnoreCase(contentType)\n-            || MIME_TYPE_FIXED_FIELD.equalsIgnoreCase(contentType) \n-            || MIME_TYPE_SAS_TRANSPORT.equalsIgnoreCase(contentType)\n-            || MIME_TYPE_SAS_SYSTEM.equalsIgnoreCase(contentType));\n-        \n+\n+    String contentType = file.getContentType();\n+\n+    // The only known/supported Geo Data type is SHAPE,\n+    // so far:\n+\n+    return FileUtil.MIME_TYPE_GEO_SHAPE.equalsIgnoreCase(contentType);\n+  }\n+\n+  public boolean isFileClassTabularData(DataFile file) {\n+    if (file == null) {\n+      return false;\n     }\n-    \n-    public boolean isFileClassVideo (DataFile file) {\n-        if (file == null) {\n-            return false;\n-        }\n-        \n-        String contentType = file.getContentType();\n-        \n-        // TODO: \n-        // check if there are video types that don't start with \"audio/\" - \n-        // some exotic application/... formats ?\n-        \n-        return (contentType != null && (contentType.toLowerCase().startsWith(\"video/\")));    \n-        \n+\n+    // \"Tabular data\" is EITHER an INGESTED tabular data file, i.e.\n+    // a file with a DataTable and DataVariables; or a DataFile\n+    // of one of the many known tabular data formats - SPSS, Stata, etc.\n+    // that for one reason or another didn't get ingested:\n+\n+    if (file.isTabularData()) {\n+      return true;\n     }\n-    \n-    public boolean isFileClassPackage (DataFile file) {\n-        if (file == null) {\n-            return false;\n-        }\n-        \n-        String contentType = file.getContentType();\n-       \n-        return MIME_TYPE_PACKAGE_FILE.equalsIgnoreCase(contentType);\n+\n+    // The formats we know how to ingest:\n+    if (FileUtil.canIngestAsTabular(file)) {\n+      return true;\n     }\n-    \n-    public void populateFileSearchCard(SolrSearchResult solrSearchResult) {\n-        solrSearchResult.setEntity(this.findCheapAndEasy(solrSearchResult.getEntityId()));\n+\n+    String contentType = file.getContentType();\n+\n+    // And these are the formats we DON'T know how to ingest,\n+    // but nevertheless recognize as \"tabular data\":\n+\n+    return (MIME_TYPE_TSV.equalsIgnoreCase(contentType)\n+      || MIME_TYPE_FIXED_FIELD.equalsIgnoreCase(contentType)\n+      || MIME_TYPE_SAS_TRANSPORT.equalsIgnoreCase(contentType)\n+      || MIME_TYPE_SAS_SYSTEM.equalsIgnoreCase(contentType));\n+\n+  }\n+\n+  public boolean isFileClassVideo(DataFile file) {\n+    if (file == null) {\n+      return false;\n     }\n-    \n-    public boolean hasBeenDeleted(DataFile df){\n-        Dataset dataset = df.getOwner();\n-        DatasetVersion dsv = dataset.getLatestVersion();\n-        \n-        return findFileMetadataByDatasetVersionIdAndDataFileId(dsv.getId(), df.getId()) == null;\n-        \n+\n+    String contentType = file.getContentType();\n+\n+    // TODO:\n+    // check if there are video types that don't start with \"audio/\" -\n+    // some exotic application/... formats ?\n+\n+    return (contentType != null && (contentType.toLowerCase().startsWith(\"video/\")));\n+\n+  }\n+\n+  public boolean isFileClassPackage(DataFile file) {\n+    if (file == null) {\n+      return false;\n     }\n-    \n-    /**\n-     * Is this a replacement file??\n-     * \n-     * The indication of a previousDataFileId says that it is\n-     * \n-     * @param df\n-     * @return\n-     */\n-    public boolean isReplacementFile(DataFile df) {\n-\n-        if (df.getPreviousDataFileId() == null){\n-            return false;\n-        }else if (df.getPreviousDataFileId() < 1){\n-            String errMSg = \"Stop! previousDataFileId should either be null or a number greater than 0\";\n-            logger.severe(errMSg);\n-            return false;\n-            // blow up -- this shouldn't happen!\n-            //throw new FileReplaceException(errMSg);\n-        }else if (df.getPreviousDataFileId() > 0){\n-            return true;\n-        }\n-        return false;\n-    }  // end: isReplacementFile\n-    \n-    public List<Long> selectFilesWithMissingOriginalTypes() {\n-        Query query = em.createNativeQuery(\"SELECT f.id FROM datafile f, datatable t where t.datafile_id = f.id AND (t.originalfileformat='\" + MIME_TYPE_TSV + \"' OR t.originalfileformat IS NULL) ORDER BY f.id\");\n-        \n-        try {\n-            return query.getResultList();\n-        } catch (Exception ex) {\n-            return new ArrayList<>();\n-        }\n+\n+    String contentType = file.getContentType();\n+\n+    return MIME_TYPE_PACKAGE_FILE.equalsIgnoreCase(contentType);\n+  }\n+\n+  public void populateFileSearchCard(SolrSearchResult solrSearchResult) {\n+    solrSearchResult.setEntity(this.findCheapAndEasy(solrSearchResult.getEntityId()));\n+  }\n+\n+  public boolean hasBeenDeleted(DataFile df) {\n+    Dataset dataset = df.getOwner();\n+    DatasetVersion dsv = dataset.getLatestVersion();\n+\n+    return findFileMetadataByDatasetVersionIdAndDataFileId(dsv.getId(), df.getId()) == null;\n+\n+  }\n+\n+  /**\n+   * Is this a replacement file??\n+   * <p>\n+   * The indication of a previousDataFileId says that it is\n+   *\n+   * @param df\n+   * @return\n+   */\n+  public boolean isReplacementFile(DataFile df) {\n+\n+    if (df.getPreviousDataFileId() == null) {\n+      return false;\n+    } else if (df.getPreviousDataFileId() < 1) {\n+      String errMSg = \"Stop! previousDataFileId should either be null or a number greater than 0\";\n+      logger.severe(errMSg);\n+      return false;\n+      // blow up -- this shouldn't happen!\n+      //throw new FileReplaceException(errMSg);\n+    } else if (df.getPreviousDataFileId() > 0) {\n+      return true;\n     }\n-    \n-    public List<Long> selectFilesWithMissingOriginalSizes() {\n-        Query query = em.createNativeQuery(\"SELECT f.id FROM datafile f, datatable t where t.datafile_id = f.id AND (t.originalfilesize IS NULL ) AND (t.originalfileformat IS NOT NULL) ORDER BY f.id\");\n-        \n-        try {\n-            return query.getResultList();\n-        } catch (Exception ex) {\n-            return new ArrayList<>();\n-        }\n+    return false;\n+  }  // end: isReplacementFile\n+\n+  public List<Long> selectFilesWithMissingOriginalTypes() {\n+    Query query = em.createNativeQuery(\n+      \"SELECT f.id FROM datafile f, datatable t where t.datafile_id = f.id AND (t.originalfileformat='\" +\n+        MIME_TYPE_TSV + \"' OR t.originalfileformat IS NULL) ORDER BY f.id\");\n+\n+    try {\n+      return query.getResultList();\n+    } catch (Exception ex) {\n+      return new ArrayList<>();\n     }\n-    \n-    public String generateDataFileIdentifier(DataFile datafile, GlobalIdServiceBean idServiceBean) {\n-        String doiIdentifierType = settingsService.getValueForKey(SettingsServiceBean.Key.IdentifierGenerationStyle, \"randomString\");\n-        String doiDataFileFormat = settingsService.getValueForKey(SettingsServiceBean.Key.DataFilePIDFormat, \"DEPENDENT\");\n-\n-        String prepend = \"\";\n-        if (doiDataFileFormat.equals(SystemConfig.DataFilePIDFormat.DEPENDENT.toString())){\n-            //If format is dependent then pre-pend the dataset identifier \n-            prepend = datafile.getOwner().getIdentifier() + \"/\";\n-        } else {\n-            //If there's a shoulder prepend independent identifiers with it\n-        \tprepend = settingsService.getValueForKey(SettingsServiceBean.Key.Shoulder, \"\");\n-        }\n- \n-        switch (doiIdentifierType) {\n-            case \"randomString\":               \n-                return generateIdentifierAsRandomString(datafile, idServiceBean, prepend);\n-            case \"sequentialNumber\":\n-                if (doiDataFileFormat.equals(SystemConfig.DataFilePIDFormat.INDEPENDENT.toString())){ \n-                    return generateIdentifierAsIndependentSequentialNumber(datafile, idServiceBean, prepend);\n-                } else {\n-                    return generateIdentifierAsDependentSequentialNumber(datafile, idServiceBean, prepend);\n-                }\n-            default:\n-                /* Should we throw an exception instead?? -- L.A. 4.6.2 */\n-                return generateIdentifierAsRandomString(datafile, idServiceBean, prepend);\n-        }\n+  }\n+\n+  public List<Long> selectFilesWithMissingOriginalSizes() {\n+    Query query = em.createNativeQuery(\n+      \"SELECT f.id FROM datafile f, datatable t where t.datafile_id = f.id AND (t.originalfilesize IS NULL ) AND (t.originalfileformat IS NOT NULL) ORDER BY f.id\");\n+\n+    try {\n+      return query.getResultList();\n+    } catch (Exception ex) {\n+      return new ArrayList<>();\n     }\n-    \n-    private String generateIdentifierAsRandomString(DataFile datafile, GlobalIdServiceBean idServiceBean, String prepend) {\n-        String identifier = null;\n-        do {\n-            identifier = prepend + RandomStringUtils.randomAlphanumeric(6).toUpperCase();  \n-        } while (!isGlobalIdUnique(identifier, datafile, idServiceBean));\n-\n-        return identifier;\n-    }\n-\n-\n-    private String generateIdentifierAsIndependentSequentialNumber(DataFile datafile, GlobalIdServiceBean idServiceBean, String prepend) {\n-        String identifier; \n-        do {\n-            StoredProcedureQuery query = this.em.createNamedStoredProcedureQuery(\"Dataset.generateIdentifierAsSequentialNumber\");\n-            query.execute();\n-            Integer identifierNumeric = (Integer) query.getOutputParameterValue(1); \n-            // some diagnostics here maybe - is it possible to determine that it's failing \n-            // because the stored procedure hasn't been created in the database?\n-            if (identifierNumeric == null) {\n-                return null; \n-            }\n-            identifier = prepend + identifierNumeric.toString();\n-        } while (!isGlobalIdUnique(identifier, datafile, idServiceBean));\n-        \n-        return identifier;\n+  }\n+\n+  public String generateDataFileIdentifier(DataFile datafile, GlobalIdServiceBean idServiceBean) {\n+    String doiIdentifierType =\n+      settingsService.getValueForKey(SettingsServiceBean.Key.IdentifierGenerationStyle, \"randomString\");\n+    String doiDataFileFormat = settingsService.getValueForKey(SettingsServiceBean.Key.DataFilePIDFormat, \"DEPENDENT\");\n+\n+    String prepend = \"\";\n+    if (doiDataFileFormat.equals(SystemConfig.DataFilePIDFormat.DEPENDENT.toString())) {\n+      //If format is dependent then pre-pend the dataset identifier\n+      prepend = datafile.getOwner().getIdentifier() + \"/\";\n+    } else {\n+      //If there's a shoulder prepend independent identifiers with it\n+      prepend = settingsService.getValueForKey(SettingsServiceBean.Key.Shoulder, \"\");\n     }\n-    \n-    private String generateIdentifierAsDependentSequentialNumber(DataFile datafile, GlobalIdServiceBean idServiceBean, String prepend) {\n-        String identifier;\n-        Long retVal;\n-\n-        retVal = new Long(0);\n-\n-        do {\n-            retVal++;\n-            identifier = prepend + retVal.toString();\n-\n-        } while (!isGlobalIdUnique(identifier, datafile, idServiceBean));\n-\n-        return identifier;\n-    }\n-\n-    /**\n-     * Check that a identifier entered by the user is unique (not currently used\n-     * for any other study in this Dataverse Network). Also check for duplicate\n-     * in the remote PID service if needed\n-     * @param userIdentifier\n-     * @param datafile\n-     * @param idServiceBean\n-     * @return  {@code true} iff the global identifier is unique.\n-     */\n-    public boolean isGlobalIdUnique(String userIdentifier, DataFile datafile, GlobalIdServiceBean idServiceBean) {\n-        String testProtocol = \"\";\n-        String testAuthority = \"\";\n-        if (datafile.getAuthority() != null){\n-            testAuthority = datafile.getAuthority();\n-        } else {\n-            testAuthority = settingsService.getValueForKey(SettingsServiceBean.Key.Authority);\n-        }\n-        if (datafile.getProtocol() != null){\n-            testProtocol = datafile.getProtocol();\n+\n+    switch (doiIdentifierType) {\n+      case \"randomString\":\n+        return generateIdentifierAsRandomString(datafile, idServiceBean, prepend);\n+      case \"sequentialNumber\":\n+        if (doiDataFileFormat.equals(SystemConfig.DataFilePIDFormat.INDEPENDENT.toString())) {\n+          return generateIdentifierAsIndependentSequentialNumber(datafile, idServiceBean, prepend);\n         } else {\n-            testProtocol = settingsService.getValueForKey(SettingsServiceBean.Key.Protocol);\n-        }\n-        \n-        boolean u = em.createNamedQuery(\"DvObject.findByProtocolIdentifierAuthority\")\n-            .setParameter(\"protocol\", testProtocol)\n-            .setParameter(\"authority\", testAuthority)\n-            .setParameter(\"identifier\",userIdentifier)\n-            .getResultList().isEmpty();\n-            \n-        try{\n-            if (idServiceBean.alreadyExists(new GlobalId(testProtocol, testAuthority, userIdentifier))) {\n-                u = false;\n-            }\n-        } catch (Exception e){\n-            //we can live with failure - means identifier not found remotely\n-        }\n+          return generateIdentifierAsDependentSequentialNumber(datafile, idServiceBean, prepend);\n+        }\n+      default:\n+        /* Should we throw an exception instead?? -- L.A. 4.6.2 */\n+        return generateIdentifierAsRandomString(datafile, idServiceBean, prepend);\n+    }\n+  }\n+\n+  private String generateIdentifierAsRandomString(DataFile datafile, GlobalIdServiceBean idServiceBean,\n+                                                  String prepend) {\n+    String identifier = null;\n+    do {\n+      identifier = prepend + RandomStringUtils.randomAlphanumeric(6).toUpperCase();\n+    } while (!isGlobalIdUnique(identifier, datafile, idServiceBean));\n+\n+    return identifier;\n+  }\n+\n+\n+  private String generateIdentifierAsIndependentSequentialNumber(DataFile datafile, GlobalIdServiceBean idServiceBean,\n+                                                                 String prepend) {\n+    String identifier;\n+    do {\n+      StoredProcedureQuery query =\n+        this.em.createNamedStoredProcedureQuery(\"Dataset.generateIdentifierAsSequentialNumber\");\n+      query.execute();\n+      Integer identifierNumeric = (Integer) query.getOutputParameterValue(1);\n+      // some diagnostics here maybe - is it possible to determine that it's failing\n+      // because the stored procedure hasn't been created in the database?\n+      if (identifierNumeric == null) {\n+        return null;\n+      }\n+      identifier = prepend + identifierNumeric.toString();\n+    } while (!isGlobalIdUnique(identifier, datafile, idServiceBean));\n+\n+    return identifier;\n+  }\n+\n+  private String generateIdentifierAsDependentSequentialNumber(DataFile datafile, GlobalIdServiceBean idServiceBean,\n+                                                               String prepend) {\n+    String identifier;\n+    Long retVal;\n+\n+    retVal = new Long(0);\n+\n+    do {\n+      retVal++;\n+      identifier = prepend + retVal.toString();\n+\n+    } while (!isGlobalIdUnique(identifier, datafile, idServiceBean));\n+\n+    return identifier;\n+  }\n \n-       \n-        return u;\n-    }\n-    \n-    public void finalizeFileDelete(Long dataFileId, String storageLocation) throws IOException {\n-        // Verify that the DataFile no longer exists: \n-        if (find(dataFileId) != null) {\n-            throw new IOException(\"Attempted to permanently delete a physical file still associated with an existing DvObject \"\n-                    + \"(id: \" + dataFileId + \", location: \" + storageLocation);\n-        }\n-        StorageIO<DvObject> directStorageAccess = DataAccess.getDirectStorageIO(storageLocation);\n-        directStorageAccess.delete();\n-    }\n-    \n-    public void finalizeFileDeletes(Map<Long, String> storageLocations) {\n-        storageLocations.keySet().stream().forEach((dataFileId) -> {\n-            String storageLocation = storageLocations.get(dataFileId);\n-\n-            try {\n-                finalizeFileDelete(dataFileId, storageLocation);\n-            } catch (IOException ioex) {\n-                logger.warning(\"Failed to delete the physical file associated with the deleted datafile id=\"\n-                        + dataFileId + \", storage location: \" + storageLocation);\n-            }\n-        });\n-    }\n-    \n-    public Map<Long, String> getPhysicalFilesToDelete(DatasetVersion datasetVersion) {\n-        return getPhysicalFilesToDelete(datasetVersion, false);\n+  /**\n+   * Check that a identifier entered by the user is unique (not currently used\n+   * for any other study in this Dataverse Network). Also check for duplicate\n+   * in the remote PID service if needed\n+   *\n+   * @param userIdentifier\n+   * @param datafile\n+   * @param idServiceBean\n+   * @return {@code true} iff the global identifier is unique.\n+   */\n+  public boolean isGlobalIdUnique(String userIdentifier, DataFile datafile, GlobalIdServiceBean idServiceBean) {\n+    String testProtocol = \"\";\n+    String testAuthority = \"\";\n+    if (datafile.getAuthority() != null) {\n+      testAuthority = datafile.getAuthority();\n+    } else {\n+      testAuthority = settingsService.getValueForKey(SettingsServiceBean.Key.Authority);\n+    }\n+    if (datafile.getProtocol() != null) {\n+      testProtocol = datafile.getProtocol();\n+    } else {\n+      testProtocol = settingsService.getValueForKey(SettingsServiceBean.Key.Protocol);\n     }\n-    \n-    public Map<Long, String> getPhysicalFilesToDelete(DatasetVersion datasetVersion, boolean destroy) {\n-        // Gather the locations of the physical files associated with DRAFT\n-        // (unpublished) DataFiles (or ALL the DataFiles, if \"destroy\") in the \n-        // DatasetVersion, that will need to be deleted once the \n-        // DeleteDatasetVersionCommand execution has been finalized:\n \n-        return getPhysicalFilesToDelete(datasetVersion.getFileMetadatas(), destroy);\n+    boolean u = em.createNamedQuery(\"DvObject.findByProtocolIdentifierAuthority\")\n+      .setParameter(\"protocol\", testProtocol)\n+      .setParameter(\"authority\", testAuthority)\n+      .setParameter(\"identifier\", userIdentifier)\n+      .getResultList().isEmpty();\n+\n+    try {\n+      if (idServiceBean.alreadyExists(new GlobalId(testProtocol, testAuthority, userIdentifier))) {\n+        u = false;\n+      }\n+    } catch (Exception e) {\n+      //we can live with failure - means identifier not found remotely\n     }\n-    \n-    public Map<Long, String> getPhysicalFilesToDelete(List<FileMetadata> fileMetadatasToDelete) {\n-        return getPhysicalFilesToDelete(fileMetadatasToDelete, false);\n+\n+\n+    return u;\n+  }\n+\n+  public void finalizeFileDelete(Long dataFileId, String storageLocation) throws IOException {\n+    // Verify that the DataFile no longer exists:\n+    if (find(dataFileId) != null) {\n+      throw new IOException(\n+        \"Attempted to permanently delete a physical file still associated with an existing DvObject \"\n+          + \"(id: \" + dataFileId + \", location: \" + storageLocation);\n     }\n-    \n-    public Map<Long, String> getPhysicalFilesToDelete(List<FileMetadata> fileMetadatasToDelete, boolean destroy) {\n-        Map<Long, String> deleteStorageLocations = new HashMap<>();\n+    StorageIO<DvObject> directStorageAccess = DataAccess.getDirectStorageIO(storageLocation);\n+    directStorageAccess.delete();\n+  }\n \n-        Iterator<FileMetadata> dfIt = fileMetadatasToDelete.iterator();\n-        while (dfIt.hasNext()) {\n-            DataFile df = dfIt.next().getDataFile();\n+  public void finalizeFileDeletes(Map<Long, String> storageLocations) {\n+    storageLocations.keySet().stream().forEach((dataFileId) -> {\n+      String storageLocation = storageLocations.get(dataFileId);\n \n-            if (destroy || !df.isReleased()) {\n+      try {\n+        finalizeFileDelete(dataFileId, storageLocation);\n+      } catch (IOException ioex) {\n+        logger.warning(\"Failed to delete the physical file associated with the deleted datafile id=\"\n+          + dataFileId + \", storage location: \" + storageLocation);\n+      }\n+    });\n+  }\n \n-                String storageLocation = getPhysicalFileToDelete(df);\n-                if (storageLocation != null) {\n-                    deleteStorageLocations.put(df.getId(), storageLocation);\n-                }\n+  public Map<Long, String> getPhysicalFilesToDelete(DatasetVersion datasetVersion) {\n+    return getPhysicalFilesToDelete(datasetVersion, false);\n+  }\n \n-            }\n-        }\n+  public Map<Long, String> getPhysicalFilesToDelete(DatasetVersion datasetVersion, boolean destroy) {\n+    // Gather the locations of the physical files associated with DRAFT\n+    // (unpublished) DataFiles (or ALL the DataFiles, if \"destroy\") in the\n+    // DatasetVersion, that will need to be deleted once the\n+    // DeleteDatasetVersionCommand execution has been finalized:\n \n-        return deleteStorageLocations;\n-    }\n-  \n-    public Map<Long, String> getPhysicalFilesToDelete(Dataset dataset) {\n-        // Gather the locations of ALL the physical files associated with \n-        // a DATASET that is being DESTROYED, that will need to be deleted\n-        // once the DestroyDataset command execution has been finalized. \n-        // Once again, note that we are selecting all the files from the dataset\n-        // - not just drafts. \n+    return getPhysicalFilesToDelete(datasetVersion.getFileMetadatas(), destroy);\n+  }\n+\n+  public Map<Long, String> getPhysicalFilesToDelete(List<FileMetadata> fileMetadatasToDelete) {\n+    return getPhysicalFilesToDelete(fileMetadatasToDelete, false);\n+  }\n \n-        Map<Long, String> deleteStorageLocations = new HashMap<>();\n+  public Map<Long, String> getPhysicalFilesToDelete(List<FileMetadata> fileMetadatasToDelete, boolean destroy) {\n+    Map<Long, String> deleteStorageLocations = new HashMap<>();\n \n-        Iterator<DataFile> dfIt = dataset.getFiles().iterator();\n-        while (dfIt.hasNext()) {\n-            DataFile df = dfIt.next();\n+    Iterator<FileMetadata> dfIt = fileMetadatasToDelete.iterator();\n+    while (dfIt.hasNext()) {\n+      DataFile df = dfIt.next().getDataFile();\n \n-            String storageLocation = getPhysicalFileToDelete(df);\n-            if (storageLocation != null) {\n-                deleteStorageLocations.put(df.getId(), storageLocation);\n-            }\n+      if (destroy || !df.isReleased()) {\n \n+        String storageLocation = getPhysicalFileToDelete(df);\n+        if (storageLocation != null) {\n+          deleteStorageLocations.put(df.getId(), storageLocation);\n         }\n \n-        return deleteStorageLocations;\n+      }\n+    }\n+\n+    return deleteStorageLocations;\n+  }\n+\n+  public Map<Long, String> getPhysicalFilesToDelete(Dataset dataset) {\n+    // Gather the locations of ALL the physical files associated with\n+    // a DATASET that is being DESTROYED, that will need to be deleted\n+    // once the DestroyDataset command execution has been finalized.\n+    // Once again, note that we are selecting all the files from the dataset\n+    // - not just drafts.\n+\n+    Map<Long, String> deleteStorageLocations = new HashMap<>();\n+\n+    Iterator<DataFile> dfIt = dataset.getFiles().iterator();\n+    while (dfIt.hasNext()) {\n+      DataFile df = dfIt.next();\n+\n+      String storageLocation = getPhysicalFileToDelete(df);\n+      if (storageLocation != null) {\n+        deleteStorageLocations.put(df.getId(), storageLocation);\n+      }\n+\n     }\n-    \n-    public String getPhysicalFileToDelete(DataFile dataFile) {\n-        try {\n-            StorageIO<DataFile> storageIO = dataFile.getStorageIO();\n-            return storageIO.getStorageLocation();\n \n-        } catch (IOException ioex) {\n-            // something potentially wrong with the physical file,\n-            // or connection to the physical storage? \n-            // we don't care (?) - we'll still try to delete the datafile from the database.\n-        }\n-        return null;\n+    return deleteStorageLocations;\n+  }\n+\n+  public String getPhysicalFileToDelete(DataFile dataFile) {\n+    try {\n+      StorageIO<DataFile> storageIO = dataFile.getStorageIO();\n+      return storageIO.getStorageLocation();\n+\n+    } catch (IOException ioex) {\n+      // something potentially wrong with the physical file,\n+      // or connection to the physical storage?\n+      // we don't care (?) - we'll still try to delete the datafile from the database.\n     }\n-    \n-    public boolean isFoldersMetadataPresentInVersion(DatasetVersion datasetVersion) {\n-        Query query = em.createNativeQuery(\"SELECT id FROM fileMetadata WHERE datasetversion_id=\"+datasetVersion.getId()+\" AND directoryLabel IS NOT null LIMIT 1\");\n-        \n-        try {\n-            int count = query.getResultList().size();\n-            return count > 0;\n-        } catch (Exception ex) {\n-            return false;\n-        }\n+    return null;\n+  }\n+\n+  public boolean isFoldersMetadataPresentInVersion(DatasetVersion datasetVersion) {\n+    Query query = em.createNativeQuery(\"SELECT id FROM fileMetadata WHERE datasetversion_id=\" + datasetVersion.getId() +\n+      \" AND directoryLabel IS NOT null LIMIT 1\");\n+\n+    try {\n+      int count = query.getResultList().size();\n+      return count > 0;\n+    } catch (Exception ex) {\n+      return false;\n     }\n+  }\n }\n",
            "diff_size": 2064
        },
        {
            "tool": "naturalize",
            "errors": null,
            "diff": null
        },
        {
            "tool": "codebuff",
            "errors": null,
            "diff": null
        },
        {
            "tool": "styler_random",
            "errors": [
                {
                    "line": "1007",
                    "column": "1",
                    "severity": "error",
                    "message": "File contains tab characters (this is the first instance).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.whitespace.FileTabCharacterCheck"
                }
            ],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/IQSS-dataverse/errored/1/21/DataFileServiceBean.java b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/IQSS-dataverse/styler_random/21/DataFileServiceBean.java\nindex 706b8d9f4e5..937859d485b 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/IQSS-dataverse/errored/1/21/DataFileServiceBean.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/IQSS-dataverse/styler_random/21/DataFileServiceBean.java\n@@ -1003,7 +1003,7 @@ public class DataFileServiceBean implements java.io.Serializable {\n     }\n     \n     public void deleteFromVersion( DatasetVersion d, DataFile f ) {\n-\t\tem.createNamedQuery(\"DataFile.removeFromDatasetVersion\")\n+      em.createNamedQuery(\"DataFile.removeFromDatasetVersion\")\n \t\t\t.setParameter(\"versionId\", d.getId()).setParameter(\"fileId\", f.getId())\n \t\t\t\t.executeUpdate();\n     }\n",
            "diff_size": 1
        },
        {
            "tool": "styler_three_grams",
            "errors": [
                {
                    "line": "1007",
                    "column": "1",
                    "severity": "error",
                    "message": "File contains tab characters (this is the first instance).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.whitespace.FileTabCharacterCheck"
                }
            ],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/IQSS-dataverse/errored/1/21/DataFileServiceBean.java b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/IQSS-dataverse/styler_three_grams/21/DataFileServiceBean.java\nindex 706b8d9f4e5..5b50e363603 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/IQSS-dataverse/errored/1/21/DataFileServiceBean.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/IQSS-dataverse/styler_three_grams/21/DataFileServiceBean.java\n@@ -1003,7 +1003,7 @@ public class DataFileServiceBean implements java.io.Serializable {\n     }\n     \n     public void deleteFromVersion( DatasetVersion d, DataFile f ) {\n-\t\tem.createNamedQuery(\"DataFile.removeFromDatasetVersion\")\n+        em.createNamedQuery(\"DataFile.removeFromDatasetVersion\")\n \t\t\t.setParameter(\"versionId\", d.getId()).setParameter(\"fileId\", f.getId())\n \t\t\t\t.executeUpdate();\n     }\n",
            "diff_size": 1
        }
    ],
    "repaired_by": [
        "intellij"
    ],
    "not_repaired_by": [
        "styler",
        "naturalize",
        "codebuff",
        "styler_random",
        "styler_three_grams"
    ]
}