{
    "project_name": "vostok-hercules",
    "error_id": "40",
    "information": {
        "errors": [
            {
                "line": "199",
                "column": "56",
                "severity": "warning",
                "message": "'{' is not preceded with whitespace.",
                "source": "com.puppycrawl.tools.checkstyle.checks.whitespace.WhitespaceAroundCheck"
            }
        ]
    },
    "source_code": "        long[] timetrapOffsets = TimeTrapUtil.getTimetrapOffsets(from, toInclusive, timetrapSize);\n\n        if (timetrapOffsets.length > requestLimitCount){\n            throw new LimitExceededException();\n        }\n",
    "results": [
        {
            "tool": "styler",
            "errors": null,
            "diff": null
        },
        {
            "tool": "intellij",
            "errors": [],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/vostok-hercules/errored/1/40/TimelineReader.java b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/vostok-hercules/intellij/40/TimelineReader.java\nindex f287cefc907..c7ef07c0296 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/vostok-hercules/errored/1/40/TimelineReader.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/vostok-hercules/intellij/40/TimelineReader.java\n@@ -28,270 +28,272 @@ import java.util.stream.Collectors;\n \n /**\n  * Read event timeline from Cassandra cluster\n- *\n+ * <p>\n  * FIXME: Should be revised and refactored\n  */\n public class TimelineReader {\n \n-    private static final Logger LOGGER = LoggerFactory.getLogger(TimelineReader.class);\n+  private static final Logger LOGGER = LoggerFactory.getLogger(TimelineReader.class);\n \n-    /**\n-     * Utility class to store shard read offset\n-     */\n-    private static class TimelineShardReadStateOffset {\n-        long ttOffset;\n-        byte[] eventId;\n+  /**\n+   * Utility class to store shard read offset\n+   */\n+  private static class TimelineShardReadStateOffset {\n+    long ttOffset;\n+    byte[] eventId;\n \n-        public TimelineShardReadStateOffset(long ttOffset, byte[] eventId) {\n-            this.ttOffset = ttOffset;\n-            this.eventId = eventId;\n-        }\n+    public TimelineShardReadStateOffset(long ttOffset, byte[] eventId) {\n+      this.ttOffset = ttOffset;\n+      this.eventId = eventId;\n     }\n-\n-    /**\n-     * Iterable values for GridIterator\n-     */\n-    private static class Parameters {\n-        final int slice;\n-        final long ttOffset;\n-\n-        public Parameters(int slice, long ttOffset) {\n-            this.slice = slice;\n-            this.ttOffset = ttOffset;\n-        }\n+  }\n+\n+  /**\n+   * Iterable values for GridIterator\n+   */\n+  private static class Parameters {\n+    final int slice;\n+    final long ttOffset;\n+\n+    public Parameters(int slice, long ttOffset) {\n+      this.slice = slice;\n+      this.ttOffset = ttOffset;\n     }\n+  }\n \n-    /**\n-     * GridIterator iterate over slice and tt_offset parameters grid\n-     */\n-    private static class GridIterator implements Iterator<Parameters> {\n-        int[] slices;\n-        long[] ttOffsets;\n-\n-        int sliceCurrentIdx = 0;\n-        int ttOffsetCurrentIdx = 0;\n-\n-        public GridIterator(int[] slices, long[] ttOffsets) {\n-            this.slices = slices;\n-            this.ttOffsets = ttOffsets;\n-        }\n-\n-        @Override\n-        public boolean hasNext() {\n-            return ttOffsetCurrentIdx < ttOffsets.length;\n-        }\n-\n-        @Override\n-        public Parameters next() {\n-            if (ttOffsets.length <= ttOffsetCurrentIdx) {\n-                throw new NoSuchElementException();\n-            }\n-            Parameters result = new Parameters(slices[sliceCurrentIdx], ttOffsets[ttOffsetCurrentIdx]);\n-            ++sliceCurrentIdx;\n-            if (sliceCurrentIdx == slices.length) {\n-                ++ttOffsetCurrentIdx;\n-                sliceCurrentIdx = 0;\n-            }\n-            return result;\n-        }\n-    }\n+  /**\n+   * GridIterator iterate over slice and tt_offset parameters grid\n+   */\n+  private static class GridIterator implements Iterator<Parameters> {\n+    int[] slices;\n+    long[] ttOffsets;\n \n-    /**\n-     * Iterable to create GridIterator\n-     */\n-    private static class Grid implements Iterable<Parameters> {\n-        int[] slices;\n-        long[] ttOffsets;\n-\n-        public Grid(int[] slices, long[] ttOffsets) {\n-            this.slices = slices;\n-            this.ttOffsets = ttOffsets;\n-        }\n-\n-        @Override\n-        public Iterator<Parameters> iterator() {\n-            return new GridIterator(slices, ttOffsets);\n-        }\n-    }\n+    int sliceCurrentIdx = 0;\n+    int ttOffsetCurrentIdx = 0;\n \n-    private static final byte[] NIL = new byte[24];\n-    private static boolean isNil(byte[] eventId) {\n-        return Arrays.equals(NIL, eventId);\n+    public GridIterator(int[] slices, long[] ttOffsets) {\n+      this.slices = slices;\n+      this.ttOffsets = ttOffsets;\n     }\n \n-    private static final String EVENT_ID = \"event_id\";\n-    private static final String PAYLOAD = \"payload\";\n-\n-    private static final String SELECT_EVENTS = \"\" +\n-            \"SELECT\" +\n-            \"  event_id,\" +\n-            \"  payload\" +\n-            \" \" +\n-            \"FROM\" +\n-            \"  %s\" +\n-            \" \" +\n-            \"WHERE\" +\n-            \"  slice = %d AND\" +\n-            \"  tt_offset = %d AND\" +\n-            \"  event_id > %s AND\" + // Lower bound\n-            \"  event_id < %s\" + // Upper bound\n-            \" \" +\n-            \"ORDER BY \" +\n-            \"  event_id\" +\n-            \" \" +\n-            \"LIMIT %d;\";\n-\n-    private static final String SELECT_EVENTS_START_READING_SLICE = \"\" +\n-            \"SELECT\" +\n-            \"  event_id,\" +\n-            \"  payload\" +\n-            \" \" +\n-            \"FROM\" +\n-            \"  %s\" +\n-            \" \" +\n-            \"WHERE\" +\n-            \"  slice = %d AND\" +\n-            \"  tt_offset = %d AND\" +\n-            \"  event_id >= %s AND\" + // Lower bound\n-            \"  event_id < %s\" + // Upper bound\n-            \" \" +\n-            \"ORDER BY \" +\n-            \"  event_id\" +\n-            \" \" +\n-            \"LIMIT %d;\";\n-\n-    private final Session session;\n-\n-    public TimelineReader(CassandraConnector connector) {\n-        this.session = connector.session();\n+    @Override\n+    public boolean hasNext() {\n+      return ttOffsetCurrentIdx < ttOffsets.length;\n     }\n \n-    /**\n-     * Read timeline content from Cassandra cluster\n-     * @param timeline timeline info\n-     * @param readState offsets data\n-     * @param shardIndex parameter for logical partitioning\n-     * @param shardCount parameter for logical partitioning\n-     * @param take fetch size\n-     * @param from lower timestamp bound in 100-ns ticks from Unix epoch\n-     * @param to upper timestamp bound exclusive in 100-ns ticks from Unix epoch\n-     * @return timeline content\n-     */\n-    public TimelineByteContent readTimeline(\n-            Timeline timeline,\n-            TimelineState readState,\n-            int shardIndex,\n-            int shardCount,\n-            int take,\n-            long from,\n-            long to,\n-            int requestLimitCount\n-    ) throws LimitExceededException {\n-        long toInclusive = to - 1;\n-        long timetrapSize = timeline.getTimetrapSize();\n-\n-        int[] partitions = LogicalPartitioner.getPartitionsForLogicalSharding(timeline, shardIndex, shardCount);\n-        if (partitions.length == 0) {\n-            return new TimelineByteContent(readState, new byte[][]{});\n-        }\n-        long[] timetrapOffsets = TimeTrapUtil.getTimetrapOffsets(from, toInclusive, timetrapSize);\n-\n-        if (timetrapOffsets.length > requestLimitCount){\n-            throw new LimitExceededException();\n-        }\n-\n-        Map<Integer, TimelineShardReadStateOffset> offsetMap = toMap(readState);\n-\n-        List<byte[]> result = new LinkedList<>();\n-\n-        for (Parameters params : new Grid(partitions, timetrapOffsets)) {\n-            TimelineShardReadStateOffset offset = offsetMap.computeIfAbsent(\n-                    params.slice,\n-                    i -> getEmptyReadStateOffset(params.ttOffset)\n-            );\n-            if (params.ttOffset < offset.ttOffset) {\n-                continue; // Skip already red timetrap offsets\n-            } else if (offset.ttOffset < params.ttOffset ) {\n-                offsetMap.put(params.slice, getEmptyReadStateOffset(params.ttOffset));\n-                offset = offsetMap.get(params.slice);\n-            }\n-\n-            SimpleStatement statement = generateStatement(timeline, params, offset, take);\n-            statement.setFetchSize(Integer.MAX_VALUE); // fetch size defined by 'take' parameter\n-\n-            LOGGER.info(\"Executing '{}'\", statement.toString());\n-\n-            ResultSet rows = session.execute(statement);\n-            for (Row row : rows) {\n-                offset.eventId = ByteUtil.fromByteBuffer(row.getBytes(EVENT_ID));\n-                result.add(row.getBytes(PAYLOAD).array());\n-                --take;\n-            }\n-            // If no rows were fetched increment tt_offset to mark partition (slice, offset_id) as red\n-            if (isNil(offset.eventId)) {\n-                offset.ttOffset += timeline.getTimetrapSize();\n-            }\n-\n-            if (take <= 0) {\n-                break;\n-            }\n-        }\n-\n-        return new TimelineByteContent(toState(offsetMap), result.toArray(new byte[0][]));\n+    @Override\n+    public Parameters next() {\n+      if (ttOffsets.length <= ttOffsetCurrentIdx) {\n+        throw new NoSuchElementException();\n+      }\n+      Parameters result = new Parameters(slices[sliceCurrentIdx], ttOffsets[ttOffsetCurrentIdx]);\n+      ++sliceCurrentIdx;\n+      if (sliceCurrentIdx == slices.length) {\n+        ++ttOffsetCurrentIdx;\n+        sliceCurrentIdx = 0;\n+      }\n+      return result;\n     }\n-\n-    public void shutdown() {\n-        session.close();\n+  }\n+\n+  /**\n+   * Iterable to create GridIterator\n+   */\n+  private static class Grid implements Iterable<Parameters> {\n+    int[] slices;\n+    long[] ttOffsets;\n+\n+    public Grid(int[] slices, long[] ttOffsets) {\n+      this.slices = slices;\n+      this.ttOffsets = ttOffsets;\n     }\n \n-    private static TimelineShardReadStateOffset getEmptyReadStateOffset(long ttOffset) {\n-        return new TimelineShardReadStateOffset(ttOffset, NIL);\n+    @Override\n+    public Iterator<Parameters> iterator() {\n+      return new GridIterator(slices, ttOffsets);\n+    }\n+  }\n+\n+  private static final byte[] NIL = new byte[24];\n+\n+  private static boolean isNil(byte[] eventId) {\n+    return Arrays.equals(NIL, eventId);\n+  }\n+\n+  private static final String EVENT_ID = \"event_id\";\n+  private static final String PAYLOAD = \"payload\";\n+\n+  private static final String SELECT_EVENTS = \"\" +\n+    \"SELECT\" +\n+    \"  event_id,\" +\n+    \"  payload\" +\n+    \" \" +\n+    \"FROM\" +\n+    \"  %s\" +\n+    \" \" +\n+    \"WHERE\" +\n+    \"  slice = %d AND\" +\n+    \"  tt_offset = %d AND\" +\n+    \"  event_id > %s AND\" + // Lower bound\n+    \"  event_id < %s\" + // Upper bound\n+    \" \" +\n+    \"ORDER BY \" +\n+    \"  event_id\" +\n+    \" \" +\n+    \"LIMIT %d;\";\n+\n+  private static final String SELECT_EVENTS_START_READING_SLICE = \"\" +\n+    \"SELECT\" +\n+    \"  event_id,\" +\n+    \"  payload\" +\n+    \" \" +\n+    \"FROM\" +\n+    \"  %s\" +\n+    \" \" +\n+    \"WHERE\" +\n+    \"  slice = %d AND\" +\n+    \"  tt_offset = %d AND\" +\n+    \"  event_id >= %s AND\" + // Lower bound\n+    \"  event_id < %s\" + // Upper bound\n+    \" \" +\n+    \"ORDER BY \" +\n+    \"  event_id\" +\n+    \" \" +\n+    \"LIMIT %d;\";\n+\n+  private final Session session;\n+\n+  public TimelineReader(CassandraConnector connector) {\n+    this.session = connector.session();\n+  }\n+\n+  /**\n+   * Read timeline content from Cassandra cluster\n+   *\n+   * @param timeline   timeline info\n+   * @param readState  offsets data\n+   * @param shardIndex parameter for logical partitioning\n+   * @param shardCount parameter for logical partitioning\n+   * @param take       fetch size\n+   * @param from       lower timestamp bound in 100-ns ticks from Unix epoch\n+   * @param to         upper timestamp bound exclusive in 100-ns ticks from Unix epoch\n+   * @return timeline content\n+   */\n+  public TimelineByteContent readTimeline(\n+    Timeline timeline,\n+    TimelineState readState,\n+    int shardIndex,\n+    int shardCount,\n+    int take,\n+    long from,\n+    long to,\n+    int requestLimitCount\n+  ) throws LimitExceededException {\n+    long toInclusive = to - 1;\n+    long timetrapSize = timeline.getTimetrapSize();\n+\n+    int[] partitions = LogicalPartitioner.getPartitionsForLogicalSharding(timeline, shardIndex, shardCount);\n+    if (partitions.length == 0) {\n+      return new TimelineByteContent(readState, new byte[][] {});\n     }\n+    long[] timetrapOffsets = TimeTrapUtil.getTimetrapOffsets(from, toInclusive, timetrapSize);\n \n-    private static SimpleStatement generateStatement(Timeline timeline, Parameters params, TimelineShardReadStateOffset offset, int take) {\n-        if (!isNil(offset.eventId)) {\n-            return new SimpleStatement(String.format(\n-                    SELECT_EVENTS,\n-                    timeline.getName(),\n-                    params.slice,\n-                    params.ttOffset,\n-                    EventUtil.eventIdOfBytesAsHexString(offset.eventId),\n-                    EventUtil.minEventIdForTimestampAsHexString(TimeUtil.millisToTicks(params.ttOffset + timeline.getTimetrapSize())),\n-                    take\n-            ));\n-        } else {\n-            return new SimpleStatement(String.format(\n-                    SELECT_EVENTS_START_READING_SLICE,\n-                    timeline.getName(),\n-                    params.slice,\n-                    params.ttOffset,\n-                    EventUtil.minEventIdForTimestampAsHexString(TimeUtil.millisToTicks(params.ttOffset)),\n-                    EventUtil.minEventIdForTimestampAsHexString(TimeUtil.millisToTicks(params.ttOffset + timeline.getTimetrapSize())),\n-                    take\n-            ));\n-        }\n+    if (timetrapOffsets.length > requestLimitCount) {\n+      throw new LimitExceededException();\n     }\n \n-    private static Map<Integer, TimelineShardReadStateOffset> toMap(TimelineState readState) {\n-        return Arrays.stream(readState.getSliceStates())\n-                .collect(Collectors.toMap(\n-                        TimelineSliceState::getSlice,\n-                        shardState -> new TimelineShardReadStateOffset(\n-                                shardState.getTtOffset(),\n-                                shardState.getEventId()\n-                        )\n-                ));\n+    Map<Integer, TimelineShardReadStateOffset> offsetMap = toMap(readState);\n+\n+    List<byte[]> result = new LinkedList<>();\n+\n+    for (Parameters params : new Grid(partitions, timetrapOffsets)) {\n+      TimelineShardReadStateOffset offset = offsetMap.computeIfAbsent(\n+        params.slice,\n+        i -> getEmptyReadStateOffset(params.ttOffset)\n+      );\n+      if (params.ttOffset < offset.ttOffset) {\n+        continue; // Skip already red timetrap offsets\n+      } else if (offset.ttOffset < params.ttOffset) {\n+        offsetMap.put(params.slice, getEmptyReadStateOffset(params.ttOffset));\n+        offset = offsetMap.get(params.slice);\n+      }\n+\n+      SimpleStatement statement = generateStatement(timeline, params, offset, take);\n+      statement.setFetchSize(Integer.MAX_VALUE); // fetch size defined by 'take' parameter\n+\n+      LOGGER.info(\"Executing '{}'\", statement.toString());\n+\n+      ResultSet rows = session.execute(statement);\n+      for (Row row : rows) {\n+        offset.eventId = ByteUtil.fromByteBuffer(row.getBytes(EVENT_ID));\n+        result.add(row.getBytes(PAYLOAD).array());\n+        --take;\n+      }\n+      // If no rows were fetched increment tt_offset to mark partition (slice, offset_id) as red\n+      if (isNil(offset.eventId)) {\n+        offset.ttOffset += timeline.getTimetrapSize();\n+      }\n+\n+      if (take <= 0) {\n+        break;\n+      }\n     }\n \n-    private static TimelineState toState(Map<Integer, TimelineShardReadStateOffset> offsetMap) {\n-        return new TimelineState(offsetMap.entrySet().stream()\n-                .map(offsetEntry -> new TimelineSliceState(\n-                        offsetEntry.getKey(),\n-                        offsetEntry.getValue().ttOffset,\n-                        offsetEntry.getValue().eventId\n-                ))\n-                .toArray(TimelineSliceState[]::new)\n-        );\n+    return new TimelineByteContent(toState(offsetMap), result.toArray(new byte[0][]));\n+  }\n+\n+  public void shutdown() {\n+    session.close();\n+  }\n+\n+  private static TimelineShardReadStateOffset getEmptyReadStateOffset(long ttOffset) {\n+    return new TimelineShardReadStateOffset(ttOffset, NIL);\n+  }\n+\n+  private static SimpleStatement generateStatement(Timeline timeline, Parameters params, TimelineShardReadStateOffset offset, int take) {\n+    if (!isNil(offset.eventId)) {\n+      return new SimpleStatement(String.format(\n+        SELECT_EVENTS,\n+        timeline.getName(),\n+        params.slice,\n+        params.ttOffset,\n+        EventUtil.eventIdOfBytesAsHexString(offset.eventId),\n+        EventUtil.minEventIdForTimestampAsHexString(TimeUtil.millisToTicks(params.ttOffset + timeline.getTimetrapSize())),\n+        take\n+      ));\n+    } else {\n+      return new SimpleStatement(String.format(\n+        SELECT_EVENTS_START_READING_SLICE,\n+        timeline.getName(),\n+        params.slice,\n+        params.ttOffset,\n+        EventUtil.minEventIdForTimestampAsHexString(TimeUtil.millisToTicks(params.ttOffset)),\n+        EventUtil.minEventIdForTimestampAsHexString(TimeUtil.millisToTicks(params.ttOffset + timeline.getTimetrapSize())),\n+        take\n+      ));\n     }\n+  }\n+\n+  private static Map<Integer, TimelineShardReadStateOffset> toMap(TimelineState readState) {\n+    return Arrays.stream(readState.getSliceStates())\n+      .collect(Collectors.toMap(\n+        TimelineSliceState::getSlice,\n+        shardState -> new TimelineShardReadStateOffset(\n+          shardState.getTtOffset(),\n+          shardState.getEventId()\n+        )\n+      ));\n+  }\n+\n+  private static TimelineState toState(Map<Integer, TimelineShardReadStateOffset> offsetMap) {\n+    return new TimelineState(offsetMap.entrySet().stream()\n+      .map(offsetEntry -> new TimelineSliceState(\n+        offsetEntry.getKey(),\n+        offsetEntry.getValue().ttOffset,\n+        offsetEntry.getValue().eventId\n+      ))\n+      .toArray(TimelineSliceState[]::new)\n+    );\n+  }\n \n }\n",
            "diff_size": 408
        },
        {
            "tool": "naturalize",
            "errors": null,
            "diff": null
        },
        {
            "tool": "codebuff",
            "errors": null,
            "diff": null
        },
        {
            "tool": "styler_random",
            "errors": null,
            "diff": null
        },
        {
            "tool": "styler_three_grams",
            "errors": null,
            "diff": null
        }
    ],
    "repaired_by": [
        "intellij"
    ],
    "not_repaired_by": [
        "styler",
        "naturalize",
        "codebuff",
        "styler_random",
        "styler_three_grams"
    ]
}