{
    "project_name": "opencb-opencga",
    "error_id": "278",
    "information": {
        "errors": [
            {
                "line": "596",
                "severity": "error",
                "message": "Line is longer than 140 characters (found 144).",
                "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
            }
        ]
    },
    "source_code": "            List<Study> studiesToValidate;\n            if (tool.scope() == Tool.Scope.PROJECT) {\n                String projectFqn = job.getStudy().getId().substring(0, job.getStudy().getId().indexOf(ParamConstants.PROJECT_STUDY_SEPARATOR));\n                studiesToValidate = catalogManager.getStudyManager().search(projectFqn, new Query(),\n                        new QueryOptions(QueryOptions.INCLUDE, Arrays.asList(StudyDBAdaptor.QueryParams.GROUPS.key(),\n                                StudyDBAdaptor.QueryParams.FQN.key())), token).getResults();",
    "results": [
        {
            "tool": "styler",
            "errors": [
                {
                    "line": "596",
                    "severity": "error",
                    "message": "Line is longer than 140 characters (found 227).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "596",
                    "column": "145",
                    "severity": "error",
                    "message": "';' is not followed by whitespace.",
                    "source": "com.puppycrawl.tools.checkstyle.checks.whitespace.WhitespaceAfterCheck"
                }
            ],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/opencb-opencga/errored/1/278/ExecutionDaemon.java b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/opencb-opencga/styler/278/ExecutionDaemon.java\nindex 4ab7639085c..d39e48dde7e 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/opencb-opencga/errored/1/278/ExecutionDaemon.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/opencb-opencga/styler/278/ExecutionDaemon.java\n@@ -593,8 +593,7 @@ public class ExecutionDaemon extends MonitorParentDaemon {\n \n             List<Study> studiesToValidate;\n             if (tool.scope() == Tool.Scope.PROJECT) {\n-                String projectFqn = job.getStudy().getId().substring(0, job.getStudy().getId().indexOf(ParamConstants.PROJECT_STUDY_SEPARATOR));\n-                studiesToValidate = catalogManager.getStudyManager().search(projectFqn, new Query(),\n+                String projectFqn = job.getStudy().getId().substring(0, job.getStudy().getId().indexOf(ParamConstants.PROJECT_STUDY_SEPARATOR));studiesToValidate= catalogManager.getStudyManager().search(projectFqn, new Query(),\n                         new QueryOptions(QueryOptions.INCLUDE, Arrays.asList(StudyDBAdaptor.QueryParams.GROUPS.key(),\n                                 StudyDBAdaptor.QueryParams.FQN.key())), token).getResults();\n             } else {\n",
            "diff_size": 2
        },
        {
            "tool": "intellij",
            "errors": [],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/opencb-opencga/errored/1/278/ExecutionDaemon.java b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/opencb-opencga/intellij/278/ExecutionDaemon.java\nindex 4ab7639085c..39eb228fdb9 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/opencb-opencga/errored/1/278/ExecutionDaemon.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/opencb-opencga/intellij/278/ExecutionDaemon.java\n@@ -127,1026 +127,1026 @@ import static org.opencb.opencga.core.api.ParamConstants.STUDY_PARAM;\n  */\n public class ExecutionDaemon extends MonitorParentDaemon {\n \n-    public static final String OUTDIR_PARAM = \"outdir\";\n-    public static final int EXECUTION_RESULT_FILE_EXPIRATION_MINUTES = 10;\n-    public static final String REDACTED_TOKEN = \"xxxxxxxxxxxxxxxxxxxxx\";\n-    private String internalCli;\n-    private JobManager jobManager;\n-    private FileManager fileManager;\n-    private final Map<String, Long> jobsCountByType = new HashMap<>();\n-    private final Map<String, Long> retainedLogsTime = new HashMap<>();\n-\n-    private Path defaultJobDir;\n-\n-    private static final Map<String, String> TOOL_CLI_MAP;\n-\n-    // Maximum number of jobs of each type (Pending, queued, running) that will be handled on each iteration.\n-    // Example: If there are 100 pending jobs, 15 queued, 70 running.\n-    // On first iteration, it will queue 50 out of the 100 pending jobs. It will check up to 50 queue-running changes out of the 65\n-    // (15 + 50 from pending), and it will check up to 50 finished jobs from the running ones.\n-    // On second iteration, it will queue the remaining 50 pending jobs, and so on...\n-    private static final int NUM_JOBS_HANDLED = 50;\n-    private final Query pendingJobsQuery;\n-    private final Query queuedJobsQuery;\n-    private final Query runningJobsQuery;\n-    private final QueryOptions queryOptions;\n-\n-    private final ExecutorService executor = Executors.newSingleThreadExecutor();\n-\n-    static {\n-        TOOL_CLI_MAP = new HashMap<String, String>(){{\n-            put(FileUnlinkTask.ID, \"files unlink\");\n-            put(FileDeleteTask.ID, \"files delete\");\n-            put(FetchAndRegisterTask.ID, \"files fetch\");\n-            put(FileIndexTask.ID, \"files secondary-index\");\n-            put(FileTsvAnnotationLoader.ID, \"files tsv-load\");\n-            put(PostLinkSampleAssociation.ID, \"files postlink\");\n-\n-            put(SampleIndexTask.ID, \"samples secondary-index\");\n-            put(SampleTsvAnnotationLoader.ID, \"samples tsv-load\");\n-\n-            put(IndividualIndexTask.ID, \"individuals secondary-index\");\n-            put(IndividualTsvAnnotationLoader.ID, \"individuals tsv-load\");\n-\n-            put(CohortIndexTask.ID, \"cohorts secondary-index\");\n-            put(CohortTsvAnnotationLoader.ID, \"cohorts tsv-load\");\n-\n-            put(FamilyIndexTask.ID, \"families secondary-index\");\n-            put(FamilyTsvAnnotationLoader.ID, \"families tsv-load\");\n-\n-            put(JobIndexTask.ID, \"jobs secondary-index\");\n-\n-            put(\"alignment-index-run\", \"alignment index-run\");\n-            put(\"alignment-coverage-run\", \"alignment coverage-run\");\n-            put(\"alignment-stats-run\", \"alignment stats-run\");\n-            put(BwaWrapperAnalysis.ID, \"alignment \" + BwaWrapperAnalysis.ID + \"-run\");\n-            put(SamtoolsWrapperAnalysis.ID, \"alignment \" + SamtoolsWrapperAnalysis.ID + \"-run\");\n-            put(DeeptoolsWrapperAnalysis.ID, \"alignment \" + DeeptoolsWrapperAnalysis.ID + \"-run\");\n-            put(FastqcWrapperAnalysis.ID, \"alignment \" + FastqcWrapperAnalysis.ID + \"-run\");\n-            put(PicardWrapperAnalysis.ID, \"alignment \" + PicardWrapperAnalysis.ID + \"-run\");\n-\n-            put(VariantIndexOperationTool.ID, \"variant index-run\");\n-            put(VariantExportTool.ID, \"variant export-run\");\n-            put(VariantStatsAnalysis.ID, \"variant stats-run\");\n-            put(\"variant-stats-export\", \"variant stats-export-run\");\n-            put(SampleVariantStatsAnalysis.ID, \"variant sample-stats-run\");\n-            put(CohortVariantStatsAnalysis.ID, \"variant cohort-stats-run\");\n-            put(GwasAnalysis.ID, \"variant gwas-run\");\n-            put(PlinkWrapperAnalysis.ID, \"variant \" + PlinkWrapperAnalysis.ID + \"-run\");\n-            put(RvtestsWrapperAnalysis.ID, \"variant \" + RvtestsWrapperAnalysis.ID + \"-run\");\n-            put(GatkWrapperAnalysis.ID, \"variant \" + GatkWrapperAnalysis.ID + \"-run\");\n-            put(VariantFileDeleteOperationTool.ID, \"variant file-delete\");\n-            put(VariantSecondaryIndexOperationTool.ID, \"variant secondary-index\");\n-            put(VariantSecondaryIndexSamplesDeleteOperationTool.ID, \"variant secondary-index-delete\");\n-            put(VariantScoreDeleteOperationTool.ID, \"variant score-delete\");\n-            put(VariantScoreIndexOperationTool.ID, \"variant score-index\");\n-            put(VariantSampleIndexOperationTool.ID, \"variant sample-index\");\n-            put(VariantFamilyIndexOperationTool.ID, \"variant family-index\");\n-            put(VariantAggregateFamilyOperationTool.ID, \"variant aggregate-family\");\n-            put(VariantAggregateOperationTool.ID, \"variant aggregate\");\n-            put(VariantAnnotationIndexOperationTool.ID, \"variant annotation-index\");\n-            put(VariantAnnotationDeleteOperationTool.ID, \"variant annotation-delete\");\n-            put(VariantAnnotationSaveOperationTool.ID, \"variant annotation-save\");\n-            put(SampleVariantFilterAnalysis.ID, \"variant sample-run\");\n-            put(KnockoutAnalysis.ID, \"variant knockout-run\");\n-            put(SampleEligibilityAnalysis.ID, \"variant \" + SampleEligibilityAnalysis.ID + \"-run\");\n-            put(MutationalSignatureAnalysis.ID, \"variant \" + MutationalSignatureAnalysis.ID + \"-run\");\n-            put(MendelianErrorAnalysis.ID, \"variant \" + MendelianErrorAnalysis.ID + \"-run\");\n-            put(InferredSexAnalysis.ID, \"variant \" + InferredSexAnalysis.ID + \"-run\");\n-            put(RelatednessAnalysis.ID, \"variant \" + RelatednessAnalysis.ID + \"-run\");\n-            put(FamilyQcAnalysis.ID, \"variant \" + FamilyQcAnalysis.ID + \"-run\");\n-            put(IndividualQcAnalysis.ID, \"variant \" + IndividualQcAnalysis.ID + \"-run\");\n-            put(SampleQcAnalysis.ID, \"variant \" + SampleQcAnalysis.ID + \"-run\");\n-\n-            put(TeamInterpretationAnalysis.ID, \"clinical \" + TeamInterpretationAnalysis.ID + \"-run\");\n-            put(TieringInterpretationAnalysis.ID, \"clinical \" + TieringInterpretationAnalysis.ID + \"-run\");\n-            put(ZettaInterpretationAnalysis.ID, \"clinical \" + ZettaInterpretationAnalysis.ID + \"-run\");\n-            put(CancerTieringInterpretationAnalysis.ID, \"clinical \" + CancerTieringInterpretationAnalysis.ID + \"-run\");\n-\n-            put(JulieTool.ID, \"variant julie-run\");\n-        }};\n-    }\n-\n-    public ExecutionDaemon(int interval, String token, CatalogManager catalogManager, String appHome) throws CatalogDBException {\n-        super(interval, token, catalogManager);\n-\n-        this.jobManager = catalogManager.getJobManager();\n-        this.fileManager = catalogManager.getFileManager();\n-        this.internalCli = appHome + \"/bin/opencga-internal.sh\";\n-\n-        this.defaultJobDir = Paths.get(catalogManager.getConfiguration().getJobDir());\n-\n-        pendingJobsQuery = new Query(JobDBAdaptor.QueryParams.INTERNAL_STATUS_NAME.key(), Enums.ExecutionStatus.PENDING);\n-        queuedJobsQuery = new Query(JobDBAdaptor.QueryParams.INTERNAL_STATUS_NAME.key(), Enums.ExecutionStatus.QUEUED);\n-        runningJobsQuery = new Query(JobDBAdaptor.QueryParams.INTERNAL_STATUS_NAME.key(), Enums.ExecutionStatus.RUNNING);\n-        // Sort jobs by priority and creation date\n-        queryOptions = new QueryOptions()\n-                .append(QueryOptions.SORT, Arrays.asList(JobDBAdaptor.QueryParams.PRIORITY.key(),\n-                        JobDBAdaptor.QueryParams.CREATION_DATE.key()))\n-                .append(QueryOptions.ORDER, QueryOptions.ASCENDING);\n-    }\n-\n-    @Override\n-    public void run() {\n-        while (!exit) {\n-            try {\n-                Thread.sleep(interval);\n-            } catch (InterruptedException e) {\n-                if (!exit) {\n-                    e.printStackTrace();\n-                }\n-            }\n-\n-            try {\n-                checkJobs();\n-            } catch (Exception e) {\n-                logger.error(\"Catch exception \" + e.getMessage(), e);\n-            }\n+  public static final String OUTDIR_PARAM = \"outdir\";\n+  public static final int EXECUTION_RESULT_FILE_EXPIRATION_MINUTES = 10;\n+  public static final String REDACTED_TOKEN = \"xxxxxxxxxxxxxxxxxxxxx\";\n+  private String internalCli;\n+  private JobManager jobManager;\n+  private FileManager fileManager;\n+  private final Map<String, Long> jobsCountByType = new HashMap<>();\n+  private final Map<String, Long> retainedLogsTime = new HashMap<>();\n+\n+  private Path defaultJobDir;\n+\n+  private static final Map<String, String> TOOL_CLI_MAP;\n+\n+  // Maximum number of jobs of each type (Pending, queued, running) that will be handled on each iteration.\n+  // Example: If there are 100 pending jobs, 15 queued, 70 running.\n+  // On first iteration, it will queue 50 out of the 100 pending jobs. It will check up to 50 queue-running changes out of the 65\n+  // (15 + 50 from pending), and it will check up to 50 finished jobs from the running ones.\n+  // On second iteration, it will queue the remaining 50 pending jobs, and so on...\n+  private static final int NUM_JOBS_HANDLED = 50;\n+  private final Query pendingJobsQuery;\n+  private final Query queuedJobsQuery;\n+  private final Query runningJobsQuery;\n+  private final QueryOptions queryOptions;\n+\n+  private final ExecutorService executor = Executors.newSingleThreadExecutor();\n+\n+  static {\n+    TOOL_CLI_MAP = new HashMap<String, String>() {{\n+      put(FileUnlinkTask.ID, \"files unlink\");\n+      put(FileDeleteTask.ID, \"files delete\");\n+      put(FetchAndRegisterTask.ID, \"files fetch\");\n+      put(FileIndexTask.ID, \"files secondary-index\");\n+      put(FileTsvAnnotationLoader.ID, \"files tsv-load\");\n+      put(PostLinkSampleAssociation.ID, \"files postlink\");\n+\n+      put(SampleIndexTask.ID, \"samples secondary-index\");\n+      put(SampleTsvAnnotationLoader.ID, \"samples tsv-load\");\n+\n+      put(IndividualIndexTask.ID, \"individuals secondary-index\");\n+      put(IndividualTsvAnnotationLoader.ID, \"individuals tsv-load\");\n+\n+      put(CohortIndexTask.ID, \"cohorts secondary-index\");\n+      put(CohortTsvAnnotationLoader.ID, \"cohorts tsv-load\");\n+\n+      put(FamilyIndexTask.ID, \"families secondary-index\");\n+      put(FamilyTsvAnnotationLoader.ID, \"families tsv-load\");\n+\n+      put(JobIndexTask.ID, \"jobs secondary-index\");\n+\n+      put(\"alignment-index-run\", \"alignment index-run\");\n+      put(\"alignment-coverage-run\", \"alignment coverage-run\");\n+      put(\"alignment-stats-run\", \"alignment stats-run\");\n+      put(BwaWrapperAnalysis.ID, \"alignment \" + BwaWrapperAnalysis.ID + \"-run\");\n+      put(SamtoolsWrapperAnalysis.ID, \"alignment \" + SamtoolsWrapperAnalysis.ID + \"-run\");\n+      put(DeeptoolsWrapperAnalysis.ID, \"alignment \" + DeeptoolsWrapperAnalysis.ID + \"-run\");\n+      put(FastqcWrapperAnalysis.ID, \"alignment \" + FastqcWrapperAnalysis.ID + \"-run\");\n+      put(PicardWrapperAnalysis.ID, \"alignment \" + PicardWrapperAnalysis.ID + \"-run\");\n+\n+      put(VariantIndexOperationTool.ID, \"variant index-run\");\n+      put(VariantExportTool.ID, \"variant export-run\");\n+      put(VariantStatsAnalysis.ID, \"variant stats-run\");\n+      put(\"variant-stats-export\", \"variant stats-export-run\");\n+      put(SampleVariantStatsAnalysis.ID, \"variant sample-stats-run\");\n+      put(CohortVariantStatsAnalysis.ID, \"variant cohort-stats-run\");\n+      put(GwasAnalysis.ID, \"variant gwas-run\");\n+      put(PlinkWrapperAnalysis.ID, \"variant \" + PlinkWrapperAnalysis.ID + \"-run\");\n+      put(RvtestsWrapperAnalysis.ID, \"variant \" + RvtestsWrapperAnalysis.ID + \"-run\");\n+      put(GatkWrapperAnalysis.ID, \"variant \" + GatkWrapperAnalysis.ID + \"-run\");\n+      put(VariantFileDeleteOperationTool.ID, \"variant file-delete\");\n+      put(VariantSecondaryIndexOperationTool.ID, \"variant secondary-index\");\n+      put(VariantSecondaryIndexSamplesDeleteOperationTool.ID, \"variant secondary-index-delete\");\n+      put(VariantScoreDeleteOperationTool.ID, \"variant score-delete\");\n+      put(VariantScoreIndexOperationTool.ID, \"variant score-index\");\n+      put(VariantSampleIndexOperationTool.ID, \"variant sample-index\");\n+      put(VariantFamilyIndexOperationTool.ID, \"variant family-index\");\n+      put(VariantAggregateFamilyOperationTool.ID, \"variant aggregate-family\");\n+      put(VariantAggregateOperationTool.ID, \"variant aggregate\");\n+      put(VariantAnnotationIndexOperationTool.ID, \"variant annotation-index\");\n+      put(VariantAnnotationDeleteOperationTool.ID, \"variant annotation-delete\");\n+      put(VariantAnnotationSaveOperationTool.ID, \"variant annotation-save\");\n+      put(SampleVariantFilterAnalysis.ID, \"variant sample-run\");\n+      put(KnockoutAnalysis.ID, \"variant knockout-run\");\n+      put(SampleEligibilityAnalysis.ID, \"variant \" + SampleEligibilityAnalysis.ID + \"-run\");\n+      put(MutationalSignatureAnalysis.ID, \"variant \" + MutationalSignatureAnalysis.ID + \"-run\");\n+      put(MendelianErrorAnalysis.ID, \"variant \" + MendelianErrorAnalysis.ID + \"-run\");\n+      put(InferredSexAnalysis.ID, \"variant \" + InferredSexAnalysis.ID + \"-run\");\n+      put(RelatednessAnalysis.ID, \"variant \" + RelatednessAnalysis.ID + \"-run\");\n+      put(FamilyQcAnalysis.ID, \"variant \" + FamilyQcAnalysis.ID + \"-run\");\n+      put(IndividualQcAnalysis.ID, \"variant \" + IndividualQcAnalysis.ID + \"-run\");\n+      put(SampleQcAnalysis.ID, \"variant \" + SampleQcAnalysis.ID + \"-run\");\n+\n+      put(TeamInterpretationAnalysis.ID, \"clinical \" + TeamInterpretationAnalysis.ID + \"-run\");\n+      put(TieringInterpretationAnalysis.ID, \"clinical \" + TieringInterpretationAnalysis.ID + \"-run\");\n+      put(ZettaInterpretationAnalysis.ID, \"clinical \" + ZettaInterpretationAnalysis.ID + \"-run\");\n+      put(CancerTieringInterpretationAnalysis.ID, \"clinical \" + CancerTieringInterpretationAnalysis.ID + \"-run\");\n+\n+      put(JulieTool.ID, \"variant julie-run\");\n+    }};\n+  }\n+\n+  public ExecutionDaemon(int interval, String token, CatalogManager catalogManager, String appHome) throws CatalogDBException {\n+    super(interval, token, catalogManager);\n+\n+    this.jobManager = catalogManager.getJobManager();\n+    this.fileManager = catalogManager.getFileManager();\n+    this.internalCli = appHome + \"/bin/opencga-internal.sh\";\n+\n+    this.defaultJobDir = Paths.get(catalogManager.getConfiguration().getJobDir());\n+\n+    pendingJobsQuery = new Query(JobDBAdaptor.QueryParams.INTERNAL_STATUS_NAME.key(), Enums.ExecutionStatus.PENDING);\n+    queuedJobsQuery = new Query(JobDBAdaptor.QueryParams.INTERNAL_STATUS_NAME.key(), Enums.ExecutionStatus.QUEUED);\n+    runningJobsQuery = new Query(JobDBAdaptor.QueryParams.INTERNAL_STATUS_NAME.key(), Enums.ExecutionStatus.RUNNING);\n+    // Sort jobs by priority and creation date\n+    queryOptions = new QueryOptions()\n+        .append(QueryOptions.SORT, Arrays.asList(JobDBAdaptor.QueryParams.PRIORITY.key(),\n+            JobDBAdaptor.QueryParams.CREATION_DATE.key()))\n+        .append(QueryOptions.ORDER, QueryOptions.ASCENDING);\n+  }\n+\n+  @Override\n+  public void run() {\n+    while (!exit) {\n+      try {\n+        Thread.sleep(interval);\n+      } catch (InterruptedException e) {\n+        if (!exit) {\n+          e.printStackTrace();\n         }\n+      }\n \n-        try {\n-            logger.info(\"Attempt to shutdown webhook executor\");\n-            executor.shutdown();\n-            executor.awaitTermination(5, TimeUnit.SECONDS);\n-        } catch (InterruptedException e) {\n-            logger.error(\"Webhook tasks interrupted\");\n-        } finally {\n-            if (!executor.isTerminated()) {\n-                logger.error(\"Cancel non-finished webhook tasks\");\n-            }\n-            executor.shutdownNow();\n-            logger.info(\"Webhook tasks finished\");\n-        }\n+      try {\n+        checkJobs();\n+      } catch (Exception e) {\n+        logger.error(\"Catch exception \" + e.getMessage(), e);\n+      }\n     }\n \n-    protected void checkJobs() {\n-        long pendingJobs = -1;\n-        long queuedJobs = -1;\n-        long runningJobs = -1;\n-        try {\n-            pendingJobs = jobManager.count(pendingJobsQuery, token).getNumMatches();\n-            queuedJobs = jobManager.count(queuedJobsQuery, token).getNumMatches();\n-            runningJobs = jobManager.count(runningJobsQuery, token).getNumMatches();\n-        } catch (CatalogException e) {\n-            logger.error(\"{}\", e.getMessage(), e);\n-        }\n-        logger.info(\"----- EXECUTION DAEMON  ----- pending={}, queued={}, running={}\", pendingJobs, queuedJobs, runningJobs);\n+    try {\n+      logger.info(\"Attempt to shutdown webhook executor\");\n+      executor.shutdown();\n+      executor.awaitTermination(5, TimeUnit.SECONDS);\n+    } catch (InterruptedException e) {\n+      logger.error(\"Webhook tasks interrupted\");\n+    } finally {\n+      if (!executor.isTerminated()) {\n+        logger.error(\"Cancel non-finished webhook tasks\");\n+      }\n+      executor.shutdownNow();\n+      logger.info(\"Webhook tasks finished\");\n+    }\n+  }\n+\n+  protected void checkJobs() {\n+    long pendingJobs = -1;\n+    long queuedJobs = -1;\n+    long runningJobs = -1;\n+    try {\n+      pendingJobs = jobManager.count(pendingJobsQuery, token).getNumMatches();\n+      queuedJobs = jobManager.count(queuedJobsQuery, token).getNumMatches();\n+      runningJobs = jobManager.count(runningJobsQuery, token).getNumMatches();\n+    } catch (CatalogException e) {\n+      logger.error(\"{}\", e.getMessage(), e);\n+    }\n+    logger.info(\"----- EXECUTION DAEMON  ----- pending={}, queued={}, running={}\", pendingJobs, queuedJobs, runningJobs);\n \n             /*\n             PENDING JOBS\n              */\n-        checkPendingJobs();\n+    checkPendingJobs();\n \n             /*\n             QUEUED JOBS\n              */\n-        checkQueuedJobs();\n+    checkQueuedJobs();\n \n             /*\n             RUNNING JOBS\n              */\n-        checkRunningJobs();\n-    }\n+    checkRunningJobs();\n+  }\n \n-    protected void checkRunningJobs() {\n-        int handledRunningJobs = 0;\n-        try (DBIterator<Job> iterator = jobManager.iterator(runningJobsQuery, queryOptions, token)) {\n-            while (handledRunningJobs < NUM_JOBS_HANDLED && iterator.hasNext()) {\n-                try {\n-                    Job job = iterator.next();\n-                    handledRunningJobs += checkRunningJob(job);\n-                } catch (Exception e) {\n-                    logger.error(\"{}\", e.getMessage(), e);\n-                }\n-            }\n+  protected void checkRunningJobs() {\n+    int handledRunningJobs = 0;\n+    try (DBIterator<Job> iterator = jobManager.iterator(runningJobsQuery, queryOptions, token)) {\n+      while (handledRunningJobs < NUM_JOBS_HANDLED && iterator.hasNext()) {\n+        try {\n+          Job job = iterator.next();\n+          handledRunningJobs += checkRunningJob(job);\n         } catch (Exception e) {\n-            logger.error(\"{}\", e.getMessage(), e);\n-        }\n-    }\n-\n-    protected int checkRunningJob(Job job) {\n-        Enums.ExecutionStatus jobStatus = getCurrentStatus(job);\n-\n-        switch (jobStatus.getName()) {\n-            case Enums.ExecutionStatus.RUNNING:\n-                ExecutionResult result = readExecutionResult(job);\n-                if (result != null) {\n-                    if (result.getExecutor() != null\n-                            && result.getExecutor().getParams() != null\n-                            && result.getExecutor().getParams().containsKey(ParamConstants.TOKEN)) {\n-                        result.getExecutor().getParams().put(ParamConstants.TOKEN, REDACTED_TOKEN);\n-                    }\n-                    // Update the result of the job\n-                    PrivateJobUpdateParams updateParams = new PrivateJobUpdateParams().setExecution(result);\n-                    try {\n-                        jobManager.update(job.getStudy().getId(), job.getId(), updateParams, QueryOptions.empty(), token);\n-                    } catch (CatalogException e) {\n-                        logger.error(\"[{}] - Could not update result information: {}\", job.getId(), e.getMessage(), e);\n-                        return 0;\n-                    }\n-                }\n-                return 1;\n-            case Enums.ExecutionStatus.ABORTED:\n-            case Enums.ExecutionStatus.ERROR:\n-            case Enums.ExecutionStatus.DONE:\n-            case Enums.ExecutionStatus.READY:\n-                // Register job results\n-                return processFinishedJob(job, jobStatus);\n-            case Enums.ExecutionStatus.QUEUED:\n-                // Running job went back to Queued?\n-                logger.info(\"Running job '{}' went back to '{}' status\", job.getId(), jobStatus.getName());\n-                return setStatus(job, new Enums.ExecutionStatus(Enums.ExecutionStatus.QUEUED));\n-            case Enums.ExecutionStatus.PENDING:\n-            case Enums.ExecutionStatus.UNKNOWN:\n-            default:\n-                logger.info(\"Unexpected status '{}' for job '{}'\", jobStatus.getName(), job.getId());\n-                return 0;\n-\n+          logger.error(\"{}\", e.getMessage(), e);\n         }\n+      }\n+    } catch (Exception e) {\n+      logger.error(\"{}\", e.getMessage(), e);\n     }\n-\n-    protected void checkQueuedJobs() {\n-        int handledQueuedJobs = 0;\n-        try (DBIterator<Job> iterator = jobManager.iterator(queuedJobsQuery, queryOptions, token)) {\n-            while (handledQueuedJobs < NUM_JOBS_HANDLED && iterator.hasNext()) {\n-                try {\n-                    Job job = iterator.next();\n-                    handledQueuedJobs += checkQueuedJob(job);\n-                } catch (Exception e) {\n-                    logger.error(\"{}\", e.getMessage(), e);\n-                }\n-            }\n-        } catch (Exception e) {\n-            logger.error(\"{}\", e.getMessage(), e);\n+  }\n+\n+  protected int checkRunningJob(Job job) {\n+    Enums.ExecutionStatus jobStatus = getCurrentStatus(job);\n+\n+    switch (jobStatus.getName()) {\n+      case Enums.ExecutionStatus.RUNNING:\n+        ExecutionResult result = readExecutionResult(job);\n+        if (result != null) {\n+          if (result.getExecutor() != null\n+              && result.getExecutor().getParams() != null\n+              && result.getExecutor().getParams().containsKey(ParamConstants.TOKEN)) {\n+            result.getExecutor().getParams().put(ParamConstants.TOKEN, REDACTED_TOKEN);\n+          }\n+          // Update the result of the job\n+          PrivateJobUpdateParams updateParams = new PrivateJobUpdateParams().setExecution(result);\n+          try {\n+            jobManager.update(job.getStudy().getId(), job.getId(), updateParams, QueryOptions.empty(), token);\n+          } catch (CatalogException e) {\n+            logger.error(\"[{}] - Could not update result information: {}\", job.getId(), e.getMessage(), e);\n+            return 0;\n+          }\n         }\n-    }\n+        return 1;\n+      case Enums.ExecutionStatus.ABORTED:\n+      case Enums.ExecutionStatus.ERROR:\n+      case Enums.ExecutionStatus.DONE:\n+      case Enums.ExecutionStatus.READY:\n+        // Register job results\n+        return processFinishedJob(job, jobStatus);\n+      case Enums.ExecutionStatus.QUEUED:\n+        // Running job went back to Queued?\n+        logger.info(\"Running job '{}' went back to '{}' status\", job.getId(), jobStatus.getName());\n+        return setStatus(job, new Enums.ExecutionStatus(Enums.ExecutionStatus.QUEUED));\n+      case Enums.ExecutionStatus.PENDING:\n+      case Enums.ExecutionStatus.UNKNOWN:\n+      default:\n+        logger.info(\"Unexpected status '{}' for job '{}'\", jobStatus.getName(), job.getId());\n+        return 0;\n \n-    /**\n-     * Check if the job is still queued or it has changed to running or error.\n-     *\n-     * @param job Job object.\n-     * @return 1 if the job has changed the status, 0 otherwise.\n-     */\n-    protected int checkQueuedJob(Job job) {\n-        Enums.ExecutionStatus status = getCurrentStatus(job);\n-\n-        switch (status.getName()) {\n-            case Enums.ExecutionStatus.QUEUED:\n-                // Job is still queued\n-                return 0;\n-            case Enums.ExecutionStatus.RUNNING:\n-                logger.info(\"[{}] - Updating status from {} to {}\", job.getId(),\n-                        Enums.ExecutionStatus.QUEUED, Enums.ExecutionStatus.RUNNING);\n-                logger.info(\"[{}] - stdout file '{}'\", job.getId(),\n-                        job.getOutDir().getUri().resolve(getLogFileName(job)).getPath());\n-                logger.info(\"[{}] - stderr file: '{}'\", job.getId(),\n-                        job.getOutDir().getUri().resolve(getErrorLogFileName(job)).getPath());\n-                return setStatus(job, new Enums.ExecutionStatus(Enums.ExecutionStatus.RUNNING));\n-            case Enums.ExecutionStatus.ABORTED:\n-            case Enums.ExecutionStatus.ERROR:\n-            case Enums.ExecutionStatus.DONE:\n-            case Enums.ExecutionStatus.READY:\n-                // Job has finished the execution, so we need to register the job results\n-                return processFinishedJob(job, status);\n-            case Enums.ExecutionStatus.UNKNOWN:\n-                logger.info(\"Job '{}' in status {}\", job.getId(), Enums.ExecutionStatus.UNKNOWN);\n-                return 0;\n-            default:\n-                logger.info(\"Unexpected status '{}' for job '{}'\", status.getName(), job.getId());\n-                return 0;\n-        }\n     }\n+  }\n \n-    protected void checkPendingJobs() {\n-        // Clear job counts each cycle\n-        jobsCountByType.clear();\n-\n-        int handledPendingJobs = 0;\n-        try (DBIterator<Job> iterator = jobManager.iterator(pendingJobsQuery, queryOptions, token)) {\n-            while (handledPendingJobs < NUM_JOBS_HANDLED && iterator.hasNext()) {\n-                try {\n-                    Job job = iterator.next();\n-                    handledPendingJobs += checkPendingJob(job);\n-                } catch (Exception e) {\n-                    logger.error(\"{}\", e.getMessage(), e);\n-                }\n-            }\n+  protected void checkQueuedJobs() {\n+    int handledQueuedJobs = 0;\n+    try (DBIterator<Job> iterator = jobManager.iterator(queuedJobsQuery, queryOptions, token)) {\n+      while (handledQueuedJobs < NUM_JOBS_HANDLED && iterator.hasNext()) {\n+        try {\n+          Job job = iterator.next();\n+          handledQueuedJobs += checkQueuedJob(job);\n         } catch (Exception e) {\n-            logger.error(\"{}\", e.getMessage(), e);\n+          logger.error(\"{}\", e.getMessage(), e);\n         }\n+      }\n+    } catch (Exception e) {\n+      logger.error(\"{}\", e.getMessage(), e);\n     }\n+  }\n+\n+  /**\n+   * Check if the job is still queued or it has changed to running or error.\n+   *\n+   * @param job Job object.\n+   * @return 1 if the job has changed the status, 0 otherwise.\n+   */\n+  protected int checkQueuedJob(Job job) {\n+    Enums.ExecutionStatus status = getCurrentStatus(job);\n+\n+    switch (status.getName()) {\n+      case Enums.ExecutionStatus.QUEUED:\n+        // Job is still queued\n+        return 0;\n+      case Enums.ExecutionStatus.RUNNING:\n+        logger.info(\"[{}] - Updating status from {} to {}\", job.getId(),\n+            Enums.ExecutionStatus.QUEUED, Enums.ExecutionStatus.RUNNING);\n+        logger.info(\"[{}] - stdout file '{}'\", job.getId(),\n+            job.getOutDir().getUri().resolve(getLogFileName(job)).getPath());\n+        logger.info(\"[{}] - stderr file: '{}'\", job.getId(),\n+            job.getOutDir().getUri().resolve(getErrorLogFileName(job)).getPath());\n+        return setStatus(job, new Enums.ExecutionStatus(Enums.ExecutionStatus.RUNNING));\n+      case Enums.ExecutionStatus.ABORTED:\n+      case Enums.ExecutionStatus.ERROR:\n+      case Enums.ExecutionStatus.DONE:\n+      case Enums.ExecutionStatus.READY:\n+        // Job has finished the execution, so we need to register the job results\n+        return processFinishedJob(job, status);\n+      case Enums.ExecutionStatus.UNKNOWN:\n+        logger.info(\"Job '{}' in status {}\", job.getId(), Enums.ExecutionStatus.UNKNOWN);\n+        return 0;\n+      default:\n+        logger.info(\"Unexpected status '{}' for job '{}'\", status.getName(), job.getId());\n+        return 0;\n+    }\n+  }\n \n-    /**\n-     * Check everything is correct and queues the job.\n-     *\n-     * @param job Job object.\n-     * @return 1 if the job has changed the status, 0 otherwise.\n-     */\n-    protected int checkPendingJob(Job job) {\n-        if (StringUtils.isEmpty(job.getStudy().getId())) {\n-            return abortJob(job, \"Missing mandatory 'studyUuid' field\");\n-        }\n-\n-        if (StringUtils.isEmpty(job.getTool().getId())) {\n-            return abortJob(job, \"Tool id '\" + job.getTool().getId() + \"' not found.\");\n-        }\n-\n-        if (!canBeQueued(job)) {\n-            return 0;\n-        }\n-\n-        Tool tool;\n-        try {\n-            tool = new ToolFactory().getTool(job.getTool().getId());\n-        } catch (Exception e) {\n-            logger.error(e.getMessage(), e);\n-            return abortJob(job, \"Tool \" + job.getTool().getId() + \" not found\");\n-        }\n+  protected void checkPendingJobs() {\n+    // Clear job counts each cycle\n+    jobsCountByType.clear();\n \n+    int handledPendingJobs = 0;\n+    try (DBIterator<Job> iterator = jobManager.iterator(pendingJobsQuery, queryOptions, token)) {\n+      while (handledPendingJobs < NUM_JOBS_HANDLED && iterator.hasNext()) {\n         try {\n-            checkToolExecutionPermission(job);\n+          Job job = iterator.next();\n+          handledPendingJobs += checkPendingJob(job);\n         } catch (Exception e) {\n-            return abortJob(job, e);\n+          logger.error(\"{}\", e.getMessage(), e);\n         }\n+      }\n+    } catch (Exception e) {\n+      logger.error(\"{}\", e.getMessage(), e);\n+    }\n+  }\n+\n+  /**\n+   * Check everything is correct and queues the job.\n+   *\n+   * @param job Job object.\n+   * @return 1 if the job has changed the status, 0 otherwise.\n+   */\n+  protected int checkPendingJob(Job job) {\n+    if (StringUtils.isEmpty(job.getStudy().getId())) {\n+      return abortJob(job, \"Missing mandatory 'studyUuid' field\");\n+    }\n \n-        PrivateJobUpdateParams updateParams = new PrivateJobUpdateParams();\n-        updateParams.setTool(new ToolInfo(tool.id(), tool.description(), tool.scope(), tool.type(), tool.resource()));\n-\n-        if (tool.scope() == Tool.Scope.PROJECT) {\n-            String projectFqn = job.getStudy().getId().substring(0, job.getStudy().getId().indexOf(ParamConstants.PROJECT_STUDY_SEPARATOR));\n-            try {\n-                List<String> studyFqnSet = catalogManager.getStudyManager().search(projectFqn, new Query(),\n-                        new QueryOptions(QueryOptions.INCLUDE, Arrays.asList(StudyDBAdaptor.QueryParams.GROUPS.key(),\n-                                StudyDBAdaptor.QueryParams.FQN.key())), token)\n-                        .getResults()\n-                        .stream()\n-                        .map(Study::getFqn)\n-                        .filter(fqn -> !fqn.equals(job.getStudy().getId()))\n-                        .distinct()\n-                        .collect(Collectors.toList());\n-\n-                updateParams.setStudy(new JobStudyParam(job.getStudy().getId(), studyFqnSet));\n-            } catch (CatalogException e) {\n-                return abortJob(job, e);\n-            }\n-        }\n-\n-        String userToken;\n-        try {\n-            userToken = catalogManager.getUserManager().getNonExpiringToken(job.getUserId(), token);\n-        } catch (CatalogException e) {\n-            logger.error(e.getMessage(), e);\n-            return abortJob(job, \"Internal error. Could not obtain token for user '\" + job.getUserId() + \"'\");\n-        }\n-\n-        if (CollectionUtils.isNotEmpty(job.getDependsOn())) {\n-            // The job(s) it depended on finished successfully. Check if the input files are correct.\n-            try {\n-                List<File> inputFiles = catalogManager.getJobManager().getJobInputFilesFromParams(job.getStudy().getId(), job, token);\n-                updateParams.setInput(inputFiles);\n-            } catch (CatalogException e) {\n-                return abortJob(job, e);\n-            }\n-        }\n-\n-\n-        Map<String, Object> params = job.getParams();\n-        String outDirPathParam = (String) params.get(OUTDIR_PARAM);\n-        if (!StringUtils.isEmpty(outDirPathParam)) {\n-            try {\n-                // Any path the user has requested\n-                updateParams.setOutDir(getValidInternalOutDir(job.getStudy().getId(), job, outDirPathParam, userToken));\n-            } catch (CatalogException e) {\n-                logger.error(\"Cannot create output directory. {}\", e.getMessage(), e);\n-                return abortJob(job, \"Cannot create output directory. \" + e.getMessage());\n-            }\n-        } else {\n-            try {\n-                // JOBS/user/job_id/\n-                updateParams.setOutDir(getValidDefaultOutDir(job));\n-            } catch (CatalogException e) {\n-                logger.error(\"Cannot create output directory. {}\", e.getMessage(), e);\n-                return abortJob(job, \"Cannot create output directory. \" + e.getMessage());\n-            }\n-        }\n-\n-        Path outDirPath = Paths.get(updateParams.getOutDir().getUri());\n-        params.put(OUTDIR_PARAM, outDirPath.toAbsolutePath().toString());\n-        params.put(JOB_PARAM, job.getId());\n-\n-        // Define where the stdout and stderr will be stored\n-        Path stderr = outDirPath.resolve(getErrorLogFileName(job));\n-        Path stdout = outDirPath.resolve(getLogFileName(job));\n-\n-        // Create cli\n-        String commandLine = buildCli(internalCli, job);\n-        String authenticatedCommandLine = commandLine + \" --token \" + userToken;\n-        String shadedCommandLine = commandLine + \" --token \" + REDACTED_TOKEN;\n+    if (StringUtils.isEmpty(job.getTool().getId())) {\n+      return abortJob(job, \"Tool id '\" + job.getTool().getId() + \"' not found.\");\n+    }\n \n-        updateParams.setCommandLine(shadedCommandLine);\n+    if (!canBeQueued(job)) {\n+      return 0;\n+    }\n \n-        logger.info(\"Updating job {} from {} to {}\", job.getId(), Enums.ExecutionStatus.PENDING, Enums.ExecutionStatus.QUEUED);\n-        updateParams.setInternal(new JobInternal(new Enums.ExecutionStatus(Enums.ExecutionStatus.QUEUED)));\n-        try {\n-            jobManager.update(job.getStudy().getId(), job.getId(), updateParams, QueryOptions.empty(), token);\n-        } catch (CatalogException e) {\n-            logger.error(\"Could not update job {}. {}\", job.getId(), e.getMessage(), e);\n-            return 0;\n-        }\n+    Tool tool;\n+    try {\n+      tool = new ToolFactory().getTool(job.getTool().getId());\n+    } catch (Exception e) {\n+      logger.error(e.getMessage(), e);\n+      return abortJob(job, \"Tool \" + job.getTool().getId() + \" not found\");\n+    }\n \n-        try {\n-            String queue = getQueue(tool);\n-            logger.info(\"Queue job '{}' on queue '{}'\", job.getId(), queue);\n-            batchExecutor.execute(job.getId(), queue, authenticatedCommandLine, stdout, stderr);\n-        } catch (Exception e) {\n-            logger.error(\"Error executing job {}.\", job.getId(), e);\n-            return abortJob(job, \"Error executing job. \" + e.getMessage());\n-        }\n+    try {\n+      checkToolExecutionPermission(job);\n+    } catch (Exception e) {\n+      return abortJob(job, e);\n+    }\n \n-        job.getInternal().setStatus(updateParams.getInternal().getStatus());\n-        notifyStatusChange(job);\n+    PrivateJobUpdateParams updateParams = new PrivateJobUpdateParams();\n+    updateParams.setTool(new ToolInfo(tool.id(), tool.description(), tool.scope(), tool.type(), tool.resource()));\n+\n+    if (tool.scope() == Tool.Scope.PROJECT) {\n+      String projectFqn = job.getStudy().getId().substring(0, job.getStudy().getId().indexOf(ParamConstants.PROJECT_STUDY_SEPARATOR));\n+      try {\n+        List<String> studyFqnSet = catalogManager.getStudyManager().search(projectFqn, new Query(),\n+            new QueryOptions(QueryOptions.INCLUDE, Arrays.asList(StudyDBAdaptor.QueryParams.GROUPS.key(),\n+                StudyDBAdaptor.QueryParams.FQN.key())), token)\n+            .getResults()\n+            .stream()\n+            .map(Study::getFqn)\n+            .filter(fqn -> !fqn.equals(job.getStudy().getId()))\n+            .distinct()\n+            .collect(Collectors.toList());\n+\n+        updateParams.setStudy(new JobStudyParam(job.getStudy().getId(), studyFqnSet));\n+      } catch (CatalogException e) {\n+        return abortJob(job, e);\n+      }\n+    }\n \n-        return 1;\n+    String userToken;\n+    try {\n+      userToken = catalogManager.getUserManager().getNonExpiringToken(job.getUserId(), token);\n+    } catch (CatalogException e) {\n+      logger.error(e.getMessage(), e);\n+      return abortJob(job, \"Internal error. Could not obtain token for user '\" + job.getUserId() + \"'\");\n     }\n \n-    protected void checkToolExecutionPermission(Job job) throws Exception {\n-        Tool tool = new ToolFactory().getTool(job.getTool().getId());\n+    if (CollectionUtils.isNotEmpty(job.getDependsOn())) {\n+      // The job(s) it depended on finished successfully. Check if the input files are correct.\n+      try {\n+        List<File> inputFiles = catalogManager.getJobManager().getJobInputFilesFromParams(job.getStudy().getId(), job, token);\n+        updateParams.setInput(inputFiles);\n+      } catch (CatalogException e) {\n+        return abortJob(job, e);\n+      }\n+    }\n \n-        if (tool.scope().equals(Tool.Scope.GLOBAL)) {\n-            if (!job.getUserId().equals(ParamConstants.OPENCGA_USER_ID)) {\n-                throw new CatalogAuthorizationException(\"Only user '\" + ParamConstants.OPENCGA_USER_ID + \"' \"\n-                        + \"can run tools with scope '\" + Tool.Scope.GLOBAL + \"'\");\n-            }\n-        } else {\n-            if (job.getStudy().getId().startsWith(job.getUserId() + ParamConstants.USER_PROJECT_SEPARATOR)) {\n-                // If the user is the owner of the project, accept all.\n-                return;\n-            }\n \n-            // Validate user is owner or belongs to the right group\n-            String requiredGroup;\n-            if (tool.type().equals(Tool.Type.OPERATION)) {\n-                requiredGroup = ParamConstants.ADMINS_GROUP;\n-            } else {\n-                requiredGroup = ParamConstants.MEMBERS_GROUP;\n-            }\n+    Map<String, Object> params = job.getParams();\n+    String outDirPathParam = (String) params.get(OUTDIR_PARAM);\n+    if (!StringUtils.isEmpty(outDirPathParam)) {\n+      try {\n+        // Any path the user has requested\n+        updateParams.setOutDir(getValidInternalOutDir(job.getStudy().getId(), job, outDirPathParam, userToken));\n+      } catch (CatalogException e) {\n+        logger.error(\"Cannot create output directory. {}\", e.getMessage(), e);\n+        return abortJob(job, \"Cannot create output directory. \" + e.getMessage());\n+      }\n+    } else {\n+      try {\n+        // JOBS/user/job_id/\n+        updateParams.setOutDir(getValidDefaultOutDir(job));\n+      } catch (CatalogException e) {\n+        logger.error(\"Cannot create output directory. {}\", e.getMessage(), e);\n+        return abortJob(job, \"Cannot create output directory. \" + e.getMessage());\n+      }\n+    }\n \n-            List<Study> studiesToValidate;\n-            if (tool.scope() == Tool.Scope.PROJECT) {\n-                String projectFqn = job.getStudy().getId().substring(0, job.getStudy().getId().indexOf(ParamConstants.PROJECT_STUDY_SEPARATOR));\n-                studiesToValidate = catalogManager.getStudyManager().search(projectFqn, new Query(),\n-                        new QueryOptions(QueryOptions.INCLUDE, Arrays.asList(StudyDBAdaptor.QueryParams.GROUPS.key(),\n-                                StudyDBAdaptor.QueryParams.FQN.key())), token).getResults();\n-            } else {\n-                studiesToValidate = catalogManager.getStudyManager().get(job.getStudy().getId(),\n-                        new QueryOptions(QueryOptions.INCLUDE, Arrays.asList(StudyDBAdaptor.QueryParams.GROUPS.key(),\n-                                StudyDBAdaptor.QueryParams.FQN.key())), token).getResults();\n-            }\n+    Path outDirPath = Paths.get(updateParams.getOutDir().getUri());\n+    params.put(OUTDIR_PARAM, outDirPath.toAbsolutePath().toString());\n+    params.put(JOB_PARAM, job.getId());\n \n-            List<String> missingStudies = new LinkedList<>();\n-            // It is not the owner, so we check if it is the right group\n-            for (Study study : studiesToValidate) {\n-                for (Group group : study.getGroups()) {\n-                    if (group.getId().equals(requiredGroup)) {\n-                        // If the user does not belong to the admins group\n-                        if (!group.getUserIds().contains(job.getUserId())) {\n-                            missingStudies.add(study.getFqn());\n-                        }\n-                        break;\n-                    }\n-                }\n-            }\n+    // Define where the stdout and stderr will be stored\n+    Path stderr = outDirPath.resolve(getErrorLogFileName(job));\n+    Path stdout = outDirPath.resolve(getLogFileName(job));\n \n-            if (!missingStudies.isEmpty()) {\n-                throw new CatalogAuthorizationException(\"User '\" + job.getUserId() + \"' is not member of \"\n-                        + requiredGroup + \" of studies '\" + missingStudies\n-                        + \"'. The tool '\" + job.getTool().getId()\n-                        + \"' can only be executed by the project owners or members of \" + requiredGroup);\n-            }\n+    // Create cli\n+    String commandLine = buildCli(internalCli, job);\n+    String authenticatedCommandLine = commandLine + \" --token \" + userToken;\n+    String shadedCommandLine = commandLine + \" --token \" + REDACTED_TOKEN;\n \n-        }\n+    updateParams.setCommandLine(shadedCommandLine);\n \n+    logger.info(\"Updating job {} from {} to {}\", job.getId(), Enums.ExecutionStatus.PENDING, Enums.ExecutionStatus.QUEUED);\n+    updateParams.setInternal(new JobInternal(new Enums.ExecutionStatus(Enums.ExecutionStatus.QUEUED)));\n+    try {\n+      jobManager.update(job.getStudy().getId(), job.getId(), updateParams, QueryOptions.empty(), token);\n+    } catch (CatalogException e) {\n+      logger.error(\"Could not update job {}. {}\", job.getId(), e.getMessage(), e);\n+      return 0;\n     }\n \n-    private String getQueue(Tool tool) {\n-        String queue = \"default\";\n-        Execution execution = catalogManager.getConfiguration().getAnalysis().getExecution();\n-        if (StringUtils.isNotEmpty(execution.getDefaultQueue())) {\n-            queue = execution.getDefaultQueue();\n-        }\n-        if (execution.getToolsPerQueue() != null) {\n-            for (Map.Entry<String, List<String>> entry : execution.getToolsPerQueue().entrySet()) {\n-                if (entry.getValue().contains(tool.id())) {\n-                    queue = entry.getKey();\n-                }\n-            }\n-        }\n-        return queue;\n+    try {\n+      String queue = getQueue(tool);\n+      logger.info(\"Queue job '{}' on queue '{}'\", job.getId(), queue);\n+      batchExecutor.execute(job.getId(), queue, authenticatedCommandLine, stdout, stderr);\n+    } catch (Exception e) {\n+      logger.error(\"Error executing job {}.\", job.getId(), e);\n+      return abortJob(job, \"Error executing job. \" + e.getMessage());\n     }\n \n-    private File getValidInternalOutDir(String study, Job job, String outDirPath, String userToken) throws CatalogException {\n-        // TODO: Remove this line when we stop passing the outdir as a query param in the URL\n-        outDirPath = outDirPath.replace(\":\", \"/\");\n-        if (!outDirPath.endsWith(\"/\")) {\n-            outDirPath += \"/\";\n-        }\n-        File outDir;\n-        try {\n-            outDir = fileManager.get(study, outDirPath, FileManager.INCLUDE_FILE_URI_PATH, token).first();\n-        } catch (CatalogException e) {\n-            // Directory not found. Will try to create using user's token\n-            boolean parents = (boolean) job.getAttributes().getOrDefault(Job.OPENCGA_PARENTS, false);\n-            try {\n-                outDir = fileManager.createFolder(study, outDirPath, parents, \"\", FileManager.INCLUDE_FILE_URI_PATH,\n-                        userToken).first();\n-                IOManager ioManager = catalogManager.getIoManagerFactory().get(outDir.getUri());\n-                ioManager.createDirectory(outDir.getUri(), true);\n-            } catch (CatalogException | IOException e1) {\n-                throw new CatalogException(\"Cannot create output directory. \" + e1.getMessage(), e1.getCause());\n+    job.getInternal().setStatus(updateParams.getInternal().getStatus());\n+    notifyStatusChange(job);\n+\n+    return 1;\n+  }\n+\n+  protected void checkToolExecutionPermission(Job job) throws Exception {\n+    Tool tool = new ToolFactory().getTool(job.getTool().getId());\n+\n+    if (tool.scope().equals(Tool.Scope.GLOBAL)) {\n+      if (!job.getUserId().equals(ParamConstants.OPENCGA_USER_ID)) {\n+        throw new CatalogAuthorizationException(\"Only user '\" + ParamConstants.OPENCGA_USER_ID + \"' \"\n+            + \"can run tools with scope '\" + Tool.Scope.GLOBAL + \"'\");\n+      }\n+    } else {\n+      if (job.getStudy().getId().startsWith(job.getUserId() + ParamConstants.USER_PROJECT_SEPARATOR)) {\n+        // If the user is the owner of the project, accept all.\n+        return;\n+      }\n+\n+      // Validate user is owner or belongs to the right group\n+      String requiredGroup;\n+      if (tool.type().equals(Tool.Type.OPERATION)) {\n+        requiredGroup = ParamConstants.ADMINS_GROUP;\n+      } else {\n+        requiredGroup = ParamConstants.MEMBERS_GROUP;\n+      }\n+\n+      List<Study> studiesToValidate;\n+      if (tool.scope() == Tool.Scope.PROJECT) {\n+        String projectFqn = job.getStudy().getId().substring(0, job.getStudy().getId().indexOf(ParamConstants.PROJECT_STUDY_SEPARATOR));\n+        studiesToValidate = catalogManager.getStudyManager().search(projectFqn, new Query(),\n+            new QueryOptions(QueryOptions.INCLUDE, Arrays.asList(StudyDBAdaptor.QueryParams.GROUPS.key(),\n+                StudyDBAdaptor.QueryParams.FQN.key())), token).getResults();\n+      } else {\n+        studiesToValidate = catalogManager.getStudyManager().get(job.getStudy().getId(),\n+            new QueryOptions(QueryOptions.INCLUDE, Arrays.asList(StudyDBAdaptor.QueryParams.GROUPS.key(),\n+                StudyDBAdaptor.QueryParams.FQN.key())), token).getResults();\n+      }\n+\n+      List<String> missingStudies = new LinkedList<>();\n+      // It is not the owner, so we check if it is the right group\n+      for (Study study : studiesToValidate) {\n+        for (Group group : study.getGroups()) {\n+          if (group.getId().equals(requiredGroup)) {\n+            // If the user does not belong to the admins group\n+            if (!group.getUserIds().contains(job.getUserId())) {\n+              missingStudies.add(study.getFqn());\n             }\n+            break;\n+          }\n         }\n+      }\n \n-        // Ensure the directory is empty\n-        IOManager ioManager;\n-        try {\n-            ioManager = catalogManager.getIoManagerFactory().get(outDir.getUri());\n-        } catch (IOException e) {\n-            throw CatalogIOException.ioManagerException(outDir.getUri(), e);\n-        }\n-        if (!ioManager.isDirectory(outDir.getUri())) {\n-            throw new CatalogException(OUTDIR_PARAM + \" seems not to be a directory\");\n-        }\n-        if (!ioManager.listFiles(outDir.getUri()).isEmpty()) {\n-            throw new CatalogException(OUTDIR_PARAM + \" \" + outDirPath + \" is not an empty directory\");\n-        }\n+      if (!missingStudies.isEmpty()) {\n+        throw new CatalogAuthorizationException(\"User '\" + job.getUserId() + \"' is not member of \"\n+            + requiredGroup + \" of studies '\" + missingStudies\n+            + \"'. The tool '\" + job.getTool().getId()\n+            + \"' can only be executed by the project owners or members of \" + requiredGroup);\n+      }\n \n-        return outDir;\n     }\n \n-    private File getValidDefaultOutDir(Job job) throws CatalogException {\n-        File folder = fileManager.createFolder(job.getStudy().getId(), \"JOBS/\" + job.getUserId() + \"/\" + TimeUtils.getDay() + \"/\"\n-                        + job.getId(), true, \"Job \" + job.getTool().getId(), job.getId(), QueryOptions.empty(), token).first();\n-\n-        // By default, OpenCGA will not create the physical folders until there is a file, so we need to create it manually\n-        try {\n-            catalogManager.getIoManagerFactory().get(folder.getUri()).createDirectory(folder.getUri(), true);\n-        } catch (CatalogIOException | IOException e) {\n-            // Submit job to delete job folder\n-            ObjectMap params = new ObjectMap()\n-                    .append(\"files\", folder.getUuid())\n-                    .append(\"study\", job.getStudy().getId())\n-                    .append(Constants.SKIP_TRASH, true);\n-            jobManager.submit(job.getStudy().getId(), FileDeleteTask.ID, Enums.Priority.LOW, params, token);\n-            throw new CatalogException(\"Cannot create job directory '\" + folder.getUri() + \"' for path '\" + folder.getPath() + \"'\");\n-        }\n+  }\n \n-        // Check if the user already has permissions set in his folder\n-        OpenCGAResult<Map<String, List<String>>> result = fileManager.getAcls(job.getStudy().getId(),\n-                Collections.singletonList(\"JOBS/\" + job.getUserId() + \"/\"), job.getUserId(), true, token);\n-        if (result.getNumResults() == 0 || result.first().isEmpty() || ListUtils.isEmpty(result.first().get(job.getUserId()))) {\n-            // Add permissions to do anything under that path to the user launching the job\n-            String allFilePermissions = EnumSet.allOf(FileAclEntry.FilePermissions.class)\n-                    .stream()\n-                    .map(FileAclEntry.FilePermissions::toString)\n-                    .collect(Collectors.joining(\",\"));\n-            fileManager.updateAcl(job.getStudy().getId(), Collections.singletonList(\"JOBS/\" + job.getUserId() + \"/\"), job.getUserId(),\n-                    new FileAclParams(null, allFilePermissions), SET, token);\n-            // Remove permissions to the @members group\n-            fileManager.updateAcl(job.getStudy().getId(), Collections.singletonList(\"JOBS/\" + job.getUserId() + \"/\"),\n-                    StudyManager.MEMBERS, new FileAclParams(null, \"\"), SET, token);\n-        }\n-\n-        return folder;\n+  private String getQueue(Tool tool) {\n+    String queue = \"default\";\n+    Execution execution = catalogManager.getConfiguration().getAnalysis().getExecution();\n+    if (StringUtils.isNotEmpty(execution.getDefaultQueue())) {\n+      queue = execution.getDefaultQueue();\n     }\n-\n-    public static String buildCli(String internalCli, Job job) {\n-        String toolId = job.getTool().getId();\n-        String internalCommand = TOOL_CLI_MAP.get(toolId);\n-        if (StringUtils.isEmpty(internalCommand)) {\n-            ObjectMap params = new ObjectMap()\n-                    .append(JOB_PARAM, job.getId())\n-                    .append(STUDY_PARAM, job.getStudy().getId());\n-            return buildCli(internalCli, \"tools execute-job\", params);\n-        } else {\n-            return buildCli(internalCli, internalCommand, job.getParams());\n+    if (execution.getToolsPerQueue() != null) {\n+      for (Map.Entry<String, List<String>> entry : execution.getToolsPerQueue().entrySet()) {\n+        if (entry.getValue().contains(tool.id())) {\n+          queue = entry.getKey();\n         }\n+      }\n+    }\n+    return queue;\n+  }\n+\n+  private File getValidInternalOutDir(String study, Job job, String outDirPath, String userToken) throws CatalogException {\n+    // TODO: Remove this line when we stop passing the outdir as a query param in the URL\n+    outDirPath = outDirPath.replace(\":\", \"/\");\n+    if (!outDirPath.endsWith(\"/\")) {\n+      outDirPath += \"/\";\n+    }\n+    File outDir;\n+    try {\n+      outDir = fileManager.get(study, outDirPath, FileManager.INCLUDE_FILE_URI_PATH, token).first();\n+    } catch (CatalogException e) {\n+      // Directory not found. Will try to create using user's token\n+      boolean parents = (boolean) job.getAttributes().getOrDefault(Job.OPENCGA_PARENTS, false);\n+      try {\n+        outDir = fileManager.createFolder(study, outDirPath, parents, \"\", FileManager.INCLUDE_FILE_URI_PATH,\n+            userToken).first();\n+        IOManager ioManager = catalogManager.getIoManagerFactory().get(outDir.getUri());\n+        ioManager.createDirectory(outDir.getUri(), true);\n+      } catch (CatalogException | IOException e1) {\n+        throw new CatalogException(\"Cannot create output directory. \" + e1.getMessage(), e1.getCause());\n+      }\n     }\n \n-    public static String buildCli(String internalCli, String internalCommand, Map<String, Object> params) {\n-        StringBuilder cliBuilder = new StringBuilder()\n-                .append(internalCli)\n-                .append(\" \").append(internalCommand);\n-        for (Map.Entry<String, Object> entry : params.entrySet()) {\n-            String key = entry.getKey();\n-            String param = CaseFormat.LOWER_CAMEL.to(CaseFormat.LOWER_HYPHEN, key);\n-            if (entry.getValue() instanceof Map) {\n-                Map<String, String> dynamicParams = (Map<String, String>) entry.getValue();\n-                for (Map.Entry<String, String> dynamicEntry : dynamicParams.entrySet()) {\n-                    cliBuilder.append(\" \").append(\"--\").append(param).append(\" \");\n-                    escapeCliArg(cliBuilder, dynamicEntry.getKey());\n-                    cliBuilder.append(\"=\");\n-                    escapeCliArg(cliBuilder, dynamicEntry.getValue());\n-                }\n-            } else {\n-                if (!StringUtils.isAlphanumeric(StringUtils.replaceChars(key, \"-_\", \"\"))) {\n-                    // This should never happen\n-                    throw new IllegalArgumentException(\"Invalid job param key '\" + key + \"'\");\n-                }\n-                cliBuilder\n-                        .append(\" --\").append(param)\n-                        .append(\" \");\n-                escapeCliArg(cliBuilder, entry.getValue().toString());\n-            }\n-        }\n-        return cliBuilder.toString();\n+    // Ensure the directory is empty\n+    IOManager ioManager;\n+    try {\n+      ioManager = catalogManager.getIoManagerFactory().get(outDir.getUri());\n+    } catch (IOException e) {\n+      throw CatalogIOException.ioManagerException(outDir.getUri(), e);\n+    }\n+    if (!ioManager.isDirectory(outDir.getUri())) {\n+      throw new CatalogException(OUTDIR_PARAM + \" seems not to be a directory\");\n+    }\n+    if (!ioManager.listFiles(outDir.getUri()).isEmpty()) {\n+      throw new CatalogException(OUTDIR_PARAM + \" \" + outDirPath + \" is not an empty directory\");\n     }\n \n-    /**\n-     * Escape args if needed.\n-     *\n-     * Surround with single quotes. ('value')\n-     * Detect if the value had any single quote, and escape them with double quotes (\"'\")\n-     *\n-     *   --description It's true\n-     *   --description 'It'\"'\"'s true'\n-     *\n-     * 'It'\n-     * \"'\"\n-     * 's true'\n-     *\n-     * @param cliBuilder CommandLine StringBuilder\n-     * @param value value to escape\n-     */\n-    public static void escapeCliArg(StringBuilder cliBuilder, String value) {\n-        if (StringUtils.isAlphanumeric(value) || StringUtils.isEmpty(value)) {\n-            cliBuilder.append(value);\n-        } else {\n-            if (value.contains(\"'\")) {\n-                value = value.replace(\"'\", \"'\\\"'\\\"'\");\n-            }\n-            cliBuilder.append(\"'\").append(value).append(\"'\");\n-        }\n+    return outDir;\n+  }\n+\n+  private File getValidDefaultOutDir(Job job) throws CatalogException {\n+    File folder = fileManager.createFolder(job.getStudy().getId(), \"JOBS/\" + job.getUserId() + \"/\" + TimeUtils.getDay() + \"/\"\n+        + job.getId(), true, \"Job \" + job.getTool().getId(), job.getId(), QueryOptions.empty(), token).first();\n+\n+    // By default, OpenCGA will not create the physical folders until there is a file, so we need to create it manually\n+    try {\n+      catalogManager.getIoManagerFactory().get(folder.getUri()).createDirectory(folder.getUri(), true);\n+    } catch (CatalogIOException | IOException e) {\n+      // Submit job to delete job folder\n+      ObjectMap params = new ObjectMap()\n+          .append(\"files\", folder.getUuid())\n+          .append(\"study\", job.getStudy().getId())\n+          .append(Constants.SKIP_TRASH, true);\n+      jobManager.submit(job.getStudy().getId(), FileDeleteTask.ID, Enums.Priority.LOW, params, token);\n+      throw new CatalogException(\"Cannot create job directory '\" + folder.getUri() + \"' for path '\" + folder.getPath() + \"'\");\n     }\n \n-    private boolean canBeQueued(Job job) {\n-        if (job.getDependsOn() != null && !job.getDependsOn().isEmpty()) {\n-            for (Job tmpJob : job.getDependsOn()) {\n-                if (!Enums.ExecutionStatus.DONE.equals(tmpJob.getInternal().getStatus().getName())) {\n-                    if (Enums.ExecutionStatus.ABORTED.equals(tmpJob.getInternal().getStatus().getName())\n-                            || Enums.ExecutionStatus.ERROR.equals(tmpJob.getInternal().getStatus().getName())) {\n-                        abortJob(job, \"Job '\" + tmpJob.getId() + \"' it depended on did not finish successfully\");\n-                    }\n-                    return false;\n-                }\n-            }\n-        }\n+    // Check if the user already has permissions set in his folder\n+    OpenCGAResult<Map<String, List<String>>> result = fileManager.getAcls(job.getStudy().getId(),\n+        Collections.singletonList(\"JOBS/\" + job.getUserId() + \"/\"), job.getUserId(), true, token);\n+    if (result.getNumResults() == 0 || result.first().isEmpty() || ListUtils.isEmpty(result.first().get(job.getUserId()))) {\n+      // Add permissions to do anything under that path to the user launching the job\n+      String allFilePermissions = EnumSet.allOf(FileAclEntry.FilePermissions.class)\n+          .stream()\n+          .map(FileAclEntry.FilePermissions::toString)\n+          .collect(Collectors.joining(\",\"));\n+      fileManager.updateAcl(job.getStudy().getId(), Collections.singletonList(\"JOBS/\" + job.getUserId() + \"/\"), job.getUserId(),\n+          new FileAclParams(null, allFilePermissions), SET, token);\n+      // Remove permissions to the @members group\n+      fileManager.updateAcl(job.getStudy().getId(), Collections.singletonList(\"JOBS/\" + job.getUserId() + \"/\"),\n+          StudyManager.MEMBERS, new FileAclParams(null, \"\"), SET, token);\n+    }\n \n-        if (!batchExecutor.canBeQueued()) {\n-            return false;\n+    return folder;\n+  }\n+\n+  public static String buildCli(String internalCli, Job job) {\n+    String toolId = job.getTool().getId();\n+    String internalCommand = TOOL_CLI_MAP.get(toolId);\n+    if (StringUtils.isEmpty(internalCommand)) {\n+      ObjectMap params = new ObjectMap()\n+          .append(JOB_PARAM, job.getId())\n+          .append(STUDY_PARAM, job.getStudy().getId());\n+      return buildCli(internalCli, \"tools execute-job\", params);\n+    } else {\n+      return buildCli(internalCli, internalCommand, job.getParams());\n+    }\n+  }\n+\n+  public static String buildCli(String internalCli, String internalCommand, Map<String, Object> params) {\n+    StringBuilder cliBuilder = new StringBuilder()\n+        .append(internalCli)\n+        .append(\" \").append(internalCommand);\n+    for (Map.Entry<String, Object> entry : params.entrySet()) {\n+      String key = entry.getKey();\n+      String param = CaseFormat.LOWER_CAMEL.to(CaseFormat.LOWER_HYPHEN, key);\n+      if (entry.getValue() instanceof Map) {\n+        Map<String, String> dynamicParams = (Map<String, String>) entry.getValue();\n+        for (Map.Entry<String, String> dynamicEntry : dynamicParams.entrySet()) {\n+          cliBuilder.append(\" \").append(\"--\").append(param).append(\" \");\n+          escapeCliArg(cliBuilder, dynamicEntry.getKey());\n+          cliBuilder.append(\"=\");\n+          escapeCliArg(cliBuilder, dynamicEntry.getValue());\n         }\n-\n-        Integer maxJobs = catalogManager.getConfiguration().getAnalysis().getExecution().getMaxConcurrentJobs().get(job.getTool().getId());\n-        if (maxJobs == null) {\n-            // No limit for this tool\n-            return true;\n-        } else {\n-            return canBeQueued(job.getTool().getId(), maxJobs);\n+      } else {\n+        if (!StringUtils.isAlphanumeric(StringUtils.replaceChars(key, \"-_\", \"\"))) {\n+          // This should never happen\n+          throw new IllegalArgumentException(\"Invalid job param key '\" + key + \"'\");\n         }\n+        cliBuilder\n+            .append(\" --\").append(param)\n+            .append(\" \");\n+        escapeCliArg(cliBuilder, entry.getValue().toString());\n+      }\n     }\n-\n-    private boolean canBeQueued(String toolId, int maxJobs) {\n-        Query query = new Query()\n-                .append(JobDBAdaptor.QueryParams.INTERNAL_STATUS_NAME.key(), Enums.ExecutionStatus.QUEUED + \",\"\n-                        + Enums.ExecutionStatus.RUNNING)\n-                .append(JobDBAdaptor.QueryParams.TOOL_ID.key(), toolId);\n-        long currentJobs = jobsCountByType.computeIfAbsent(toolId, k -> {\n-            try {\n-                return catalogManager.getJobManager().count(query, token).getNumMatches();\n-            } catch (CatalogException e) {\n-                logger.error(\"Error counting the current number of running and queued \\\"\" + toolId + \"\\\" jobs\", e);\n-                return 0L;\n-            }\n-        });\n-        if (currentJobs >= maxJobs) {\n-            long now = System.currentTimeMillis();\n-            Long lastTimeLog = retainedLogsTime.getOrDefault(toolId, 0L);\n-            if (now - lastTimeLog > 60000) {\n-                logger.info(\"There are {} \" + toolId + \" jobs running or queued already. \"\n-                        + \"Current limit is {}. \"\n-                        + \"Halt new \" + toolId + \" jobs.\", currentJobs, maxJobs);\n-                retainedLogsTime.put(toolId, now);\n-            }\n-            return false;\n-        } else {\n-            jobsCountByType.remove(toolId);\n-            retainedLogsTime.put(toolId, 0L);\n-            return true;\n+    return cliBuilder.toString();\n+  }\n+\n+  /**\n+   * Escape args if needed.\n+   * <p>\n+   * Surround with single quotes. ('value')\n+   * Detect if the value had any single quote, and escape them with double quotes (\"'\")\n+   * <p>\n+   * --description It's true\n+   * --description 'It'\"'\"'s true'\n+   * <p>\n+   * 'It'\n+   * \"'\"\n+   * 's true'\n+   *\n+   * @param cliBuilder CommandLine StringBuilder\n+   * @param value      value to escape\n+   */\n+  public static void escapeCliArg(StringBuilder cliBuilder, String value) {\n+    if (StringUtils.isAlphanumeric(value) || StringUtils.isEmpty(value)) {\n+      cliBuilder.append(value);\n+    } else {\n+      if (value.contains(\"'\")) {\n+        value = value.replace(\"'\", \"'\\\"'\\\"'\");\n+      }\n+      cliBuilder.append(\"'\").append(value).append(\"'\");\n+    }\n+  }\n+\n+  private boolean canBeQueued(Job job) {\n+    if (job.getDependsOn() != null && !job.getDependsOn().isEmpty()) {\n+      for (Job tmpJob : job.getDependsOn()) {\n+        if (!Enums.ExecutionStatus.DONE.equals(tmpJob.getInternal().getStatus().getName())) {\n+          if (Enums.ExecutionStatus.ABORTED.equals(tmpJob.getInternal().getStatus().getName())\n+              || Enums.ExecutionStatus.ERROR.equals(tmpJob.getInternal().getStatus().getName())) {\n+            abortJob(job, \"Job '\" + tmpJob.getId() + \"' it depended on did not finish successfully\");\n+          }\n+          return false;\n         }\n+      }\n     }\n \n-    private int abortJob(Job job, Exception e) {\n-        logger.error(e.getMessage(), e);\n-        return abortJob(job, e.getMessage());\n+    if (!batchExecutor.canBeQueued()) {\n+      return false;\n     }\n \n-    private int abortJob(Job job, String description) {\n-        logger.info(\"Aborting job: {} - Reason: '{}'\", job.getId(), description);\n-        return setStatus(job, new Enums.ExecutionStatus(Enums.ExecutionStatus.ABORTED, description));\n+    Integer maxJobs = catalogManager.getConfiguration().getAnalysis().getExecution().getMaxConcurrentJobs().get(job.getTool().getId());\n+    if (maxJobs == null) {\n+      // No limit for this tool\n+      return true;\n+    } else {\n+      return canBeQueued(job.getTool().getId(), maxJobs);\n+    }\n+  }\n+\n+  private boolean canBeQueued(String toolId, int maxJobs) {\n+    Query query = new Query()\n+        .append(JobDBAdaptor.QueryParams.INTERNAL_STATUS_NAME.key(), Enums.ExecutionStatus.QUEUED + \",\"\n+            + Enums.ExecutionStatus.RUNNING)\n+        .append(JobDBAdaptor.QueryParams.TOOL_ID.key(), toolId);\n+    long currentJobs = jobsCountByType.computeIfAbsent(toolId, k -> {\n+      try {\n+        return catalogManager.getJobManager().count(query, token).getNumMatches();\n+      } catch (CatalogException e) {\n+        logger.error(\"Error counting the current number of running and queued \\\"\" + toolId + \"\\\" jobs\", e);\n+        return 0L;\n+      }\n+    });\n+    if (currentJobs >= maxJobs) {\n+      long now = System.currentTimeMillis();\n+      Long lastTimeLog = retainedLogsTime.getOrDefault(toolId, 0L);\n+      if (now - lastTimeLog > 60000) {\n+        logger.info(\"There are {} \" + toolId + \" jobs running or queued already. \"\n+            + \"Current limit is {}. \"\n+            + \"Halt new \" + toolId + \" jobs.\", currentJobs, maxJobs);\n+        retainedLogsTime.put(toolId, now);\n+      }\n+      return false;\n+    } else {\n+      jobsCountByType.remove(toolId);\n+      retainedLogsTime.put(toolId, 0L);\n+      return true;\n+    }\n+  }\n+\n+  private int abortJob(Job job, Exception e) {\n+    logger.error(e.getMessage(), e);\n+    return abortJob(job, e.getMessage());\n+  }\n+\n+  private int abortJob(Job job, String description) {\n+    logger.info(\"Aborting job: {} - Reason: '{}'\", job.getId(), description);\n+    return setStatus(job, new Enums.ExecutionStatus(Enums.ExecutionStatus.ABORTED, description));\n+  }\n+\n+  private int setStatus(Job job, Enums.ExecutionStatus status) {\n+    PrivateJobUpdateParams updateParams = new PrivateJobUpdateParams().setInternal(new JobInternal(status));\n+\n+    try {\n+      jobManager.update(job.getStudy().getId(), job.getId(), updateParams, QueryOptions.empty(), token);\n+    } catch (CatalogException e) {\n+      logger.error(\"Unexpected error. Cannot update job '{}' to status '{}'. {}\", job.getId(),\n+          updateParams.getInternal().getStatus().getName(), e.getMessage(), e);\n+      return 0;\n     }\n \n-    private int setStatus(Job job, Enums.ExecutionStatus status) {\n-        PrivateJobUpdateParams updateParams = new PrivateJobUpdateParams().setInternal(new JobInternal(status));\n+    job.getInternal().setStatus(status);\n+    notifyStatusChange(job);\n \n-        try {\n-            jobManager.update(job.getStudy().getId(), job.getId(), updateParams, QueryOptions.empty(), token);\n-        } catch (CatalogException e) {\n-            logger.error(\"Unexpected error. Cannot update job '{}' to status '{}'. {}\", job.getId(),\n-                    updateParams.getInternal().getStatus().getName(), e.getMessage(), e);\n-            return 0;\n-        }\n+    return 1;\n+  }\n \n-        job.getInternal().setStatus(status);\n-        notifyStatusChange(job);\n+  private Enums.ExecutionStatus getCurrentStatus(Job job) {\n \n-        return 1;\n-    }\n+    Path resultJson = getExecutionResultPath(job);\n \n-    private Enums.ExecutionStatus getCurrentStatus(Job job) {\n-\n-        Path resultJson = getExecutionResultPath(job);\n-\n-        // Check if analysis result file is there\n-        if (resultJson != null && Files.exists(resultJson)) {\n-            ExecutionResult execution = readExecutionResult(resultJson);\n-            if (execution != null) {\n-                Instant lastStatusUpdate = execution.getStatus().getDate().toInstant();\n-                if (lastStatusUpdate.until(Instant.now(), ChronoUnit.MINUTES) > EXECUTION_RESULT_FILE_EXPIRATION_MINUTES) {\n-                    logger.warn(\"Ignoring file '\" + resultJson + \"'. The file is more than \"\n-                            + EXECUTION_RESULT_FILE_EXPIRATION_MINUTES + \" minutes old\");\n-                } else {\n-                    return new Enums.ExecutionStatus(execution.getStatus().getName().name());\n-                }\n-            } else {\n-                if (Files.exists(resultJson)) {\n-                    logger.warn(\"File '\" + resultJson + \"' seems corrupted.\");\n-                } else {\n-                    logger.warn(\"Could not find file '\" + resultJson + \"'.\");\n-                }\n-            }\n+    // Check if analysis result file is there\n+    if (resultJson != null && Files.exists(resultJson)) {\n+      ExecutionResult execution = readExecutionResult(resultJson);\n+      if (execution != null) {\n+        Instant lastStatusUpdate = execution.getStatus().getDate().toInstant();\n+        if (lastStatusUpdate.until(Instant.now(), ChronoUnit.MINUTES) > EXECUTION_RESULT_FILE_EXPIRATION_MINUTES) {\n+          logger.warn(\"Ignoring file '\" + resultJson + \"'. The file is more than \"\n+              + EXECUTION_RESULT_FILE_EXPIRATION_MINUTES + \" minutes old\");\n+        } else {\n+          return new Enums.ExecutionStatus(execution.getStatus().getName().name());\n         }\n-\n-        String status = batchExecutor.getStatus(job.getId());\n-        if (!StringUtils.isEmpty(status) && !status.equals(Enums.ExecutionStatus.UNKNOWN)) {\n-            return new Enums.ExecutionStatus(status);\n+      } else {\n+        if (Files.exists(resultJson)) {\n+          logger.warn(\"File '\" + resultJson + \"' seems corrupted.\");\n         } else {\n-            Path tmpOutdirPath = Paths.get(job.getOutDir().getUri());\n-            // Check if the error file is present\n-            Path errorLog = tmpOutdirPath.resolve(getErrorLogFileName(job));\n-\n-            if (Files.exists(errorLog)) {\n-                // FIXME: This may not be true. There is a delay between job starts (i.e. error log appears) and\n-                //  the analysis result creation\n-\n-                // There must be some command line error. The job started running but did not finish well, otherwise we would find the\n-                // analysis-result.yml file\n-                return new Enums.ExecutionStatus(Enums.ExecutionStatus.ERROR, \"Command line error\");\n-            } else {\n-                return new Enums.ExecutionStatus(Enums.ExecutionStatus.QUEUED);\n-            }\n+          logger.warn(\"Could not find file '\" + resultJson + \"'.\");\n         }\n+      }\n+    }\n \n+    String status = batchExecutor.getStatus(job.getId());\n+    if (!StringUtils.isEmpty(status) && !status.equals(Enums.ExecutionStatus.UNKNOWN)) {\n+      return new Enums.ExecutionStatus(status);\n+    } else {\n+      Path tmpOutdirPath = Paths.get(job.getOutDir().getUri());\n+      // Check if the error file is present\n+      Path errorLog = tmpOutdirPath.resolve(getErrorLogFileName(job));\n+\n+      if (Files.exists(errorLog)) {\n+        // FIXME: This may not be true. There is a delay between job starts (i.e. error log appears) and\n+        //  the analysis result creation\n+\n+        // There must be some command line error. The job started running but did not finish well, otherwise we would find the\n+        // analysis-result.yml file\n+        return new Enums.ExecutionStatus(Enums.ExecutionStatus.ERROR, \"Command line error\");\n+      } else {\n+        return new Enums.ExecutionStatus(Enums.ExecutionStatus.QUEUED);\n+      }\n     }\n \n-    private Path getExecutionResultPath(Job job) {\n-        Path resultJson = null;\n-        try (Stream<Path> stream = Files.list(Paths.get(job.getOutDir().getUri()))) {\n-            resultJson = stream\n-                    .filter(path -> {\n-                        String str = path.toString();\n-                        return str.endsWith(ExecutionResultManager.FILE_EXTENSION)\n-                                && !str.endsWith(ExecutionResultManager.SWAP_FILE_EXTENSION);\n-                    })\n-                    .findFirst()\n-                    .orElse(null);\n-        } catch (IOException e) {\n-            logger.warn(\"Could not find AnalysisResult file\", e);\n-        }\n-        return resultJson;\n+  }\n+\n+  private Path getExecutionResultPath(Job job) {\n+    Path resultJson = null;\n+    try (Stream<Path> stream = Files.list(Paths.get(job.getOutDir().getUri()))) {\n+      resultJson = stream\n+          .filter(path -> {\n+            String str = path.toString();\n+            return str.endsWith(ExecutionResultManager.FILE_EXTENSION)\n+                && !str.endsWith(ExecutionResultManager.SWAP_FILE_EXTENSION);\n+          })\n+          .findFirst()\n+          .orElse(null);\n+    } catch (IOException e) {\n+      logger.warn(\"Could not find AnalysisResult file\", e);\n     }\n+    return resultJson;\n+  }\n \n-    private ExecutionResult readExecutionResult(Job job) {\n-        Path resultJson = getExecutionResultPath(job);\n-        if (resultJson != null) {\n-            return readExecutionResult(resultJson);\n-        }\n-        return null;\n+  private ExecutionResult readExecutionResult(Job job) {\n+    Path resultJson = getExecutionResultPath(job);\n+    if (resultJson != null) {\n+      return readExecutionResult(resultJson);\n     }\n+    return null;\n+  }\n \n-    private ExecutionResult readExecutionResult(Path file) {\n-        if (file == null) {\n-            return null;\n+  private ExecutionResult readExecutionResult(Path file) {\n+    if (file == null) {\n+      return null;\n+    }\n+    int attempts = 0;\n+    int maxAttempts = 3;\n+    while (attempts < maxAttempts) {\n+      attempts++;\n+      try {\n+        try (InputStream is = new BufferedInputStream(new FileInputStream(file.toFile()))) {\n+          return JacksonUtils.getDefaultObjectMapper().readValue(is, ExecutionResult.class);\n         }\n-        int attempts = 0;\n-        int maxAttempts = 3;\n-        while (attempts < maxAttempts) {\n-            attempts++;\n-            try {\n-                try (InputStream is = new BufferedInputStream(new FileInputStream(file.toFile()))) {\n-                    return JacksonUtils.getDefaultObjectMapper().readValue(is, ExecutionResult.class);\n-                }\n-            } catch (IOException e) {\n-                if (attempts == maxAttempts) {\n-                    logger.error(\"Could not load AnalysisResult file: \" + file.toAbsolutePath(), e);\n-                } else {\n-                    logger.warn(\"Could not load AnalysisResult file: \" + file.toAbsolutePath()\n-                            + \". Retry \" + attempts + \"/\" + maxAttempts\n-                            + \". \" + e.getMessage()\n-                    );\n-                    try {\n-                        Thread.sleep(100);\n-                    } catch (InterruptedException interruption) {\n-                        // Ignore interruption\n-                        Thread.currentThread().interrupt();\n-                    }\n-                }\n-            }\n+      } catch (IOException e) {\n+        if (attempts == maxAttempts) {\n+          logger.error(\"Could not load AnalysisResult file: \" + file.toAbsolutePath(), e);\n+        } else {\n+          logger.warn(\"Could not load AnalysisResult file: \" + file.toAbsolutePath()\n+              + \". Retry \" + attempts + \"/\" + maxAttempts\n+              + \". \" + e.getMessage()\n+          );\n+          try {\n+            Thread.sleep(100);\n+          } catch (InterruptedException interruption) {\n+            // Ignore interruption\n+            Thread.currentThread().interrupt();\n+          }\n         }\n-\n-        return null;\n+      }\n     }\n \n-    private int processFinishedJob(Job job, Enums.ExecutionStatus status) {\n-        logger.info(\"[{}] - Processing finished job with status {}\", job.getId(), status.getName());\n-\n-        Path outDirUri = Paths.get(job.getOutDir().getUri());\n-        Path analysisResultPath = getExecutionResultPath(job);\n-\n-        logger.info(\"[{}] - Registering job results from '{}'\", job.getId(), outDirUri);\n-\n-        ExecutionResult execution;\n-        if (analysisResultPath != null) {\n-            execution = readExecutionResult(analysisResultPath);\n-            if (execution != null) {\n-                PrivateJobUpdateParams updateParams = new PrivateJobUpdateParams().setExecution(execution);\n-                try {\n-                    jobManager.update(job.getStudy().getId(), job.getId(), updateParams, QueryOptions.empty(), token);\n-                } catch (CatalogException e) {\n-                    logger.error(\"[{}] - Catastrophic error. Could not update job information with final result {}: {}\", job.getId(),\n-                            updateParams.toString(), e.getMessage(), e);\n-                    return 0;\n-                }\n-            }\n-        } else {\n-            execution = null;\n-        }\n+    return null;\n+  }\n \n-        List<File> registeredFiles;\n-        try {\n-            Predicate<URI> uriPredicate = uri -> !uri.getPath().endsWith(ExecutionResultManager.FILE_EXTENSION)\n-                    && !uri.getPath().endsWith(ExecutionResultManager.SWAP_FILE_EXTENSION)\n-                    && !uri.getPath().contains(\"/scratch_\");\n-            registeredFiles = fileManager.syncUntrackedFiles(job.getStudy().getId(), job.getOutDir().getPath(), uriPredicate, job.getId(),\n-                    token).getResults();\n-        } catch (CatalogException e) {\n-            logger.error(\"Could not registered files in Catalog: {}\", e.getMessage(), e);\n-            return 0;\n-        }\n+  private int processFinishedJob(Job job, Enums.ExecutionStatus status) {\n+    logger.info(\"[{}] - Processing finished job with status {}\", job.getId(), status.getName());\n \n-        // Register the job information\n-        PrivateJobUpdateParams updateParams = new PrivateJobUpdateParams();\n-\n-        // Process output and log files\n-        List<File> outputFiles = new LinkedList<>();\n-        String logFileName = getLogFileName(job);\n-        String errorLogFileName = getErrorLogFileName(job);\n-        for (File registeredFile : registeredFiles) {\n-            if (registeredFile.getName().equals(logFileName)) {\n-                logger.info(\"[{}] - stdout file '{}'\", job.getId(), registeredFile.getUri().getPath());\n-                updateParams.setStdout(registeredFile);\n-            } else if (registeredFile.getName().equals(errorLogFileName)) {\n-                logger.info(\"[{}] - stderr file: '{}'\", job.getId(), registeredFile.getUri().getPath());\n-                updateParams.setStderr(registeredFile);\n-            } else {\n-                outputFiles.add(registeredFile);\n-            }\n-        }\n-        if (execution != null) {\n-            for (URI externalFile : execution.getExternalFiles()) {\n-                Query query = new Query(FileDBAdaptor.QueryParams.URI.key(), externalFile);\n-                try {\n-                    OpenCGAResult<File> search = fileManager.search(job.getStudy().getId(), query, FileManager.INCLUDE_FILE_URI_PATH,\n-                            token);\n-                    if (search.getNumResults() == 0) {\n-                        throw new CatalogException(\"File not found\");\n-                    }\n-                    outputFiles.add(search.first());\n-                } catch (CatalogException e) {\n-                    logger.error(\"Could not obtain external file {}: {}\", externalFile, e.getMessage(), e);\n-                    return 0;\n-                }\n-            }\n-        }\n-        updateParams.setOutput(outputFiles);\n+    Path outDirUri = Paths.get(job.getOutDir().getUri());\n+    Path analysisResultPath = getExecutionResultPath(job);\n \n+    logger.info(\"[{}] - Registering job results from '{}'\", job.getId(), outDirUri);\n \n-        updateParams.setInternal(new JobInternal());\n-        // Check status of analysis result or if there are files that could not be moved to outdir to decide the final result\n-        if (execution == null) {\n-            updateParams.getInternal().setStatus(new Enums.ExecutionStatus(Enums.ExecutionStatus.ERROR,\n-                    \"Job could not finish successfully. Missing execution result\"));\n-        } else if (execution.getStatus().getName().equals(Status.Type.ERROR)) {\n-            updateParams.getInternal().setStatus(new Enums.ExecutionStatus(Enums.ExecutionStatus.ERROR,\n-                    \"Job could not finish successfully\"));\n-        } else {\n-            switch (status.getName()) {\n-                case Enums.ExecutionStatus.DONE:\n-                case Enums.ExecutionStatus.READY:\n-                    updateParams.getInternal().setStatus(new Enums.ExecutionStatus(Enums.ExecutionStatus.DONE));\n-                    break;\n-                case Enums.ExecutionStatus.ABORTED:\n-                    updateParams.getInternal().setStatus(new Enums.ExecutionStatus(Enums.ExecutionStatus.ERROR, \"Job aborted!\"));\n-                    break;\n-                case Enums.ExecutionStatus.ERROR:\n-                default:\n-                    updateParams.getInternal().setStatus(new Enums.ExecutionStatus(Enums.ExecutionStatus.ERROR,\n-                            \"Job could not finish successfully\"));\n-                    break;\n-            }\n-        }\n-\n-        logger.info(\"[{}] - Updating job information\", job.getId());\n-        // We update the job information\n+    ExecutionResult execution;\n+    if (analysisResultPath != null) {\n+      execution = readExecutionResult(analysisResultPath);\n+      if (execution != null) {\n+        PrivateJobUpdateParams updateParams = new PrivateJobUpdateParams().setExecution(execution);\n         try {\n-            jobManager.update(job.getStudy().getId(), job.getId(), updateParams, QueryOptions.empty(), token);\n+          jobManager.update(job.getStudy().getId(), job.getId(), updateParams, QueryOptions.empty(), token);\n         } catch (CatalogException e) {\n-            logger.error(\"[{}] - Catastrophic error. Could not update job information with final result {}: {}\", job.getId(),\n-                    updateParams.toString(), e.getMessage(), e);\n-            return 0;\n+          logger.error(\"[{}] - Catastrophic error. Could not update job information with final result {}: {}\", job.getId(),\n+              updateParams.toString(), e.getMessage(), e);\n+          return 0;\n         }\n+      }\n+    } else {\n+      execution = null;\n+    }\n \n-        job.getInternal().setStatus(updateParams.getInternal().getStatus());\n-        notifyStatusChange(job);\n-\n-        return 1;\n+    List<File> registeredFiles;\n+    try {\n+      Predicate<URI> uriPredicate = uri -> !uri.getPath().endsWith(ExecutionResultManager.FILE_EXTENSION)\n+          && !uri.getPath().endsWith(ExecutionResultManager.SWAP_FILE_EXTENSION)\n+          && !uri.getPath().contains(\"/scratch_\");\n+      registeredFiles = fileManager.syncUntrackedFiles(job.getStudy().getId(), job.getOutDir().getPath(), uriPredicate, job.getId(),\n+          token).getResults();\n+    } catch (CatalogException e) {\n+      logger.error(\"Could not registered files in Catalog: {}\", e.getMessage(), e);\n+      return 0;\n     }\n \n-    private void notifyStatusChange(Job job) {\n-        if (job.getInternal().getWebhook().getUrl() != null) {\n-            executor.submit(() -> {\n-                try {\n-                    sendWebhookNotification(job, job.getInternal().getWebhook().getUrl());\n-                } catch (URISyntaxException | CatalogException | CloneNotSupportedException e) {\n-                    logger.warn(\"Could not store notification status: {}\", e.getMessage(), e);\n-                }\n-            });\n+    // Register the job information\n+    PrivateJobUpdateParams updateParams = new PrivateJobUpdateParams();\n+\n+    // Process output and log files\n+    List<File> outputFiles = new LinkedList<>();\n+    String logFileName = getLogFileName(job);\n+    String errorLogFileName = getErrorLogFileName(job);\n+    for (File registeredFile : registeredFiles) {\n+      if (registeredFile.getName().equals(logFileName)) {\n+        logger.info(\"[{}] - stdout file '{}'\", job.getId(), registeredFile.getUri().getPath());\n+        updateParams.setStdout(registeredFile);\n+      } else if (registeredFile.getName().equals(errorLogFileName)) {\n+        logger.info(\"[{}] - stderr file: '{}'\", job.getId(), registeredFile.getUri().getPath());\n+        updateParams.setStderr(registeredFile);\n+      } else {\n+        outputFiles.add(registeredFile);\n+      }\n+    }\n+    if (execution != null) {\n+      for (URI externalFile : execution.getExternalFiles()) {\n+        Query query = new Query(FileDBAdaptor.QueryParams.URI.key(), externalFile);\n+        try {\n+          OpenCGAResult<File> search = fileManager.search(job.getStudy().getId(), query, FileManager.INCLUDE_FILE_URI_PATH,\n+              token);\n+          if (search.getNumResults() == 0) {\n+            throw new CatalogException(\"File not found\");\n+          }\n+          outputFiles.add(search.first());\n+        } catch (CatalogException e) {\n+          logger.error(\"Could not obtain external file {}: {}\", externalFile, e.getMessage(), e);\n+          return 0;\n         }\n+      }\n+    }\n+    updateParams.setOutput(outputFiles);\n+\n+\n+    updateParams.setInternal(new JobInternal());\n+    // Check status of analysis result or if there are files that could not be moved to outdir to decide the final result\n+    if (execution == null) {\n+      updateParams.getInternal().setStatus(new Enums.ExecutionStatus(Enums.ExecutionStatus.ERROR,\n+          \"Job could not finish successfully. Missing execution result\"));\n+    } else if (execution.getStatus().getName().equals(Status.Type.ERROR)) {\n+      updateParams.getInternal().setStatus(new Enums.ExecutionStatus(Enums.ExecutionStatus.ERROR,\n+          \"Job could not finish successfully\"));\n+    } else {\n+      switch (status.getName()) {\n+        case Enums.ExecutionStatus.DONE:\n+        case Enums.ExecutionStatus.READY:\n+          updateParams.getInternal().setStatus(new Enums.ExecutionStatus(Enums.ExecutionStatus.DONE));\n+          break;\n+        case Enums.ExecutionStatus.ABORTED:\n+          updateParams.getInternal().setStatus(new Enums.ExecutionStatus(Enums.ExecutionStatus.ERROR, \"Job aborted!\"));\n+          break;\n+        case Enums.ExecutionStatus.ERROR:\n+        default:\n+          updateParams.getInternal().setStatus(new Enums.ExecutionStatus(Enums.ExecutionStatus.ERROR,\n+              \"Job could not finish successfully\"));\n+          break;\n+      }\n+    }\n+\n+    logger.info(\"[{}] - Updating job information\", job.getId());\n+    // We update the job information\n+    try {\n+      jobManager.update(job.getStudy().getId(), job.getId(), updateParams, QueryOptions.empty(), token);\n+    } catch (CatalogException e) {\n+      logger.error(\"[{}] - Catastrophic error. Could not update job information with final result {}: {}\", job.getId(),\n+          updateParams.toString(), e.getMessage(), e);\n+      return 0;\n     }\n \n-    private void sendWebhookNotification(Job job, URL url) throws URISyntaxException, CatalogException, CloneNotSupportedException {\n-        JobInternal jobInternal = new JobInternal(null, job.getInternal().getWebhook().clone(), null);\n-        PrivateJobUpdateParams updateParams = new PrivateJobUpdateParams()\n-                .setInternal(jobInternal);\n+    job.getInternal().setStatus(updateParams.getInternal().getStatus());\n+    notifyStatusChange(job);\n \n-        Map<String, Object> actionMap = new HashMap<>();\n-        actionMap.put(JobDBAdaptor.QueryParams.INTERNAL_EVENTS.key(), ParamUtils.BasicUpdateAction.ADD.name());\n-        QueryOptions options = new QueryOptions(Constants.ACTIONS, actionMap);\n+    return 1;\n+  }\n \n-        Client client = ClientBuilder.newClient();\n-        Response post;\n+  private void notifyStatusChange(Job job) {\n+    if (job.getInternal().getWebhook().getUrl() != null) {\n+      executor.submit(() -> {\n         try {\n-            post = client\n-                    .target(url.toURI())\n-                    .request(MediaType.APPLICATION_JSON)\n-                    .property(ClientProperties.CONNECT_TIMEOUT, 1000)\n-                    .property(ClientProperties.READ_TIMEOUT, 5000)\n-                    .post(Entity.json(job));\n-        } catch (ProcessingException e) {\n-            jobInternal.getWebhook().getStatus().put(job.getInternal().getStatus().getName(), JobInternalWebhook.Status.ERROR);\n-            jobInternal.setEvents(Collections.singletonList(new Event(Event.Type.ERROR, \"Could not notify through webhook. \"\n-                    + e.getMessage())));\n-\n-            jobManager.update(job.getStudy().getId(), job.getId(), updateParams, options, token);\n-\n-            return;\n+          sendWebhookNotification(job, job.getInternal().getWebhook().getUrl());\n+        } catch (URISyntaxException | CatalogException | CloneNotSupportedException e) {\n+          logger.warn(\"Could not store notification status: {}\", e.getMessage(), e);\n         }\n-        if (post.getStatus() == HttpStatus.SC_OK) {\n-            jobInternal.getWebhook().getStatus().put(job.getInternal().getStatus().getName(), JobInternalWebhook.Status.SUCCESS);\n-        } else {\n-            jobInternal.getWebhook().getStatus().put(job.getInternal().getStatus().getName(), JobInternalWebhook.Status.ERROR);\n-            jobInternal.setEvents(Collections.singletonList(new Event(Event.Type.ERROR, \"Could not notify through webhook. HTTP response \"\n-                    + \"code: \" + post.getStatus())));\n-        }\n-\n-        jobManager.update(job.getStudy().getId(), job.getId(), updateParams, options, token);\n+      });\n     }\n-\n-    private String getErrorLogFileName(Job job) {\n-        return job.getId() + \".err\";\n+  }\n+\n+  private void sendWebhookNotification(Job job, URL url) throws URISyntaxException, CatalogException, CloneNotSupportedException {\n+    JobInternal jobInternal = new JobInternal(null, job.getInternal().getWebhook().clone(), null);\n+    PrivateJobUpdateParams updateParams = new PrivateJobUpdateParams()\n+        .setInternal(jobInternal);\n+\n+    Map<String, Object> actionMap = new HashMap<>();\n+    actionMap.put(JobDBAdaptor.QueryParams.INTERNAL_EVENTS.key(), ParamUtils.BasicUpdateAction.ADD.name());\n+    QueryOptions options = new QueryOptions(Constants.ACTIONS, actionMap);\n+\n+    Client client = ClientBuilder.newClient();\n+    Response post;\n+    try {\n+      post = client\n+          .target(url.toURI())\n+          .request(MediaType.APPLICATION_JSON)\n+          .property(ClientProperties.CONNECT_TIMEOUT, 1000)\n+          .property(ClientProperties.READ_TIMEOUT, 5000)\n+          .post(Entity.json(job));\n+    } catch (ProcessingException e) {\n+      jobInternal.getWebhook().getStatus().put(job.getInternal().getStatus().getName(), JobInternalWebhook.Status.ERROR);\n+      jobInternal.setEvents(Collections.singletonList(new Event(Event.Type.ERROR, \"Could not notify through webhook. \"\n+          + e.getMessage())));\n+\n+      jobManager.update(job.getStudy().getId(), job.getId(), updateParams, options, token);\n+\n+      return;\n     }\n-\n-    private String getLogFileName(Job job) {\n-        // WARNING: If we change the way we name log files, we will also need to change it in the \"log\" method from the JobManager !!\n-        return job.getId() + \".log\";\n+    if (post.getStatus() == HttpStatus.SC_OK) {\n+      jobInternal.getWebhook().getStatus().put(job.getInternal().getStatus().getName(), JobInternalWebhook.Status.SUCCESS);\n+    } else {\n+      jobInternal.getWebhook().getStatus().put(job.getInternal().getStatus().getName(), JobInternalWebhook.Status.ERROR);\n+      jobInternal.setEvents(Collections.singletonList(new Event(Event.Type.ERROR, \"Could not notify through webhook. HTTP response \"\n+          + \"code: \" + post.getStatus())));\n     }\n \n+    jobManager.update(job.getStudy().getId(), job.getId(), updateParams, options, token);\n+  }\n+\n+  private String getErrorLogFileName(Job job) {\n+    return job.getId() + \".err\";\n+  }\n+\n+  private String getLogFileName(Job job) {\n+    // WARNING: If we change the way we name log files, we will also need to change it in the \"log\" method from the JobManager !!\n+    return job.getId() + \".log\";\n+  }\n+\n }\n",
            "diff_size": 1364
        },
        {
            "tool": "naturalize",
            "errors": [
                {
                    "line": "594",
                    "severity": "error",
                    "message": "Line is longer than 140 characters (found 144).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                }
            ],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/opencb-opencga/errored/1/278/ExecutionDaemon.java b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/opencb-opencga/naturalize/278/ExecutionDaemon.java\nindex 4ab7639085c..0a61f1edf19 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/opencb-opencga/errored/1/278/ExecutionDaemon.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/opencb-opencga/naturalize/278/ExecutionDaemon.java\n@@ -154,7 +154,8 @@ public class ExecutionDaemon extends MonitorParentDaemon {\n     private final ExecutorService executor = Executors.newSingleThreadExecutor();\n \n     static {\n-        TOOL_CLI_MAP = new HashMap<String, String>(){{\n+        TOOL_CLI_MAP = new HashMap<String, String>(){\n+    {\n             put(FileUnlinkTask.ID, \"files unlink\");\n             put(FileDeleteTask.ID, \"files delete\");\n             put(FetchAndRegisterTask.ID, \"files fetch\");\n@@ -224,7 +225,8 @@ public class ExecutionDaemon extends MonitorParentDaemon {\n             put(CancerTieringInterpretationAnalysis.ID, \"clinical \" + CancerTieringInterpretationAnalysis.ID + \"-run\");\n \n             put(JulieTool.ID, \"variant julie-run\");\n-        }};\n+        }\n+    };\n     }\n \n     public ExecutionDaemon(int interval, String token, CatalogManager catalogManager, String appHome) throws CatalogDBException {\n@@ -291,21 +293,18 @@ public class ExecutionDaemon extends MonitorParentDaemon {\n             logger.error(\"{}\", e.getMessage(), e);\n         }\n         logger.info(\"----- EXECUTION DAEMON  ----- pending={}, queued={}, running={}\", pendingJobs, queuedJobs, runningJobs);\n-\n-            /*\n+/*\n             PENDING JOBS\n              */\n-        checkPendingJobs();\n-\n-            /*\n+checkPendingJobs();\n+/*\n             QUEUED JOBS\n              */\n-        checkQueuedJobs();\n-\n-            /*\n+checkQueuedJobs();\n+/*\n             RUNNING JOBS\n              */\n-        checkRunningJobs();\n+checkRunningJobs();\n     }\n \n     protected void checkRunningJobs() {\n@@ -361,8 +360,7 @@ public class ExecutionDaemon extends MonitorParentDaemon {\n             default:\n                 logger.info(\"Unexpected status '{}' for job '{}'\", jobStatus.getName(), job.getId());\n                 return 0;\n-\n-        }\n+    }\n     }\n \n     protected void checkQueuedJobs() {\n@@ -687,7 +685,7 @@ public class ExecutionDaemon extends MonitorParentDaemon {\n         File folder = fileManager.createFolder(job.getStudy().getId(), \"JOBS/\" + job.getUserId() + \"/\" + TimeUtils.getDay() + \"/\"\n                         + job.getId(), true, \"Job \" + job.getTool().getId(), job.getId(), QueryOptions.empty(), token).first();\n \n-        // By default, OpenCGA will not create the physical folders until there is a file, so we need to create it manually\n+// By default, OpenCGA will not create the physical folders until there is a file, so we need to create it manually\n         try {\n             catalogManager.getIoManagerFactory().get(folder.getUri()).createDirectory(folder.getUri(), true);\n         } catch (CatalogIOException | IOException e) {\n@@ -752,8 +750,7 @@ public class ExecutionDaemon extends MonitorParentDaemon {\n                     // This should never happen\n                     throw new IllegalArgumentException(\"Invalid job param key '\" + key + \"'\");\n                 }\n-                cliBuilder\n-                        .append(\" --\").append(param)\n+                cliBuilder.append(\" --\").append(param)\n                         .append(\" \");\n                 escapeCliArg(cliBuilder, entry.getValue().toString());\n             }\n@@ -1149,4 +1146,4 @@ public class ExecutionDaemon extends MonitorParentDaemon {\n         return job.getId() + \".log\";\n     }\n \n-}\n+}\n\\ No newline at end of file\n",
            "diff_size": 19
        },
        {
            "tool": "codebuff",
            "errors": null,
            "diff": null
        },
        {
            "tool": "styler_random",
            "errors": [
                {
                    "line": "596",
                    "severity": "error",
                    "message": "Line is longer than 140 characters (found 227).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "596",
                    "column": "145",
                    "severity": "error",
                    "message": "';' is not followed by whitespace.",
                    "source": "com.puppycrawl.tools.checkstyle.checks.whitespace.WhitespaceAfterCheck"
                }
            ],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/opencb-opencga/errored/1/278/ExecutionDaemon.java b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/opencb-opencga/styler_random/278/ExecutionDaemon.java\nindex 4ab7639085c..d39e48dde7e 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/opencb-opencga/errored/1/278/ExecutionDaemon.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/opencb-opencga/styler_random/278/ExecutionDaemon.java\n@@ -593,8 +593,7 @@ public class ExecutionDaemon extends MonitorParentDaemon {\n \n             List<Study> studiesToValidate;\n             if (tool.scope() == Tool.Scope.PROJECT) {\n-                String projectFqn = job.getStudy().getId().substring(0, job.getStudy().getId().indexOf(ParamConstants.PROJECT_STUDY_SEPARATOR));\n-                studiesToValidate = catalogManager.getStudyManager().search(projectFqn, new Query(),\n+                String projectFqn = job.getStudy().getId().substring(0, job.getStudy().getId().indexOf(ParamConstants.PROJECT_STUDY_SEPARATOR));studiesToValidate= catalogManager.getStudyManager().search(projectFqn, new Query(),\n                         new QueryOptions(QueryOptions.INCLUDE, Arrays.asList(StudyDBAdaptor.QueryParams.GROUPS.key(),\n                                 StudyDBAdaptor.QueryParams.FQN.key())), token).getResults();\n             } else {\n",
            "diff_size": 2
        },
        {
            "tool": "styler_three_grams",
            "errors": [
                {
                    "line": "597",
                    "column": "18",
                    "severity": "error",
                    "message": "'.' is followed by whitespace.",
                    "source": "com.puppycrawl.tools.checkstyle.checks.whitespace.NoWhitespaceAfterCheck"
                },
                {
                    "line": "597",
                    "column": "25",
                    "severity": "error",
                    "message": "'(' is preceded with whitespace.",
                    "source": "com.puppycrawl.tools.checkstyle.checks.whitespace.MethodParamPadCheck"
                },
                {
                    "line": "597",
                    "column": "26",
                    "severity": "error",
                    "message": "'(' is followed by whitespace.",
                    "source": "com.puppycrawl.tools.checkstyle.checks.whitespace.ParenPadCheck"
                },
                {
                    "line": "597",
                    "column": "26",
                    "severity": "error",
                    "message": "')' is preceded with whitespace.",
                    "source": "com.puppycrawl.tools.checkstyle.checks.whitespace.ParenPadCheck"
                },
                {
                    "line": "597",
                    "column": "29",
                    "severity": "error",
                    "message": "'.' is followed by whitespace.",
                    "source": "com.puppycrawl.tools.checkstyle.checks.whitespace.NoWhitespaceAfterCheck"
                },
                {
                    "line": "597",
                    "column": "40",
                    "severity": "error",
                    "message": "'(' is preceded with whitespace.",
                    "source": "com.puppycrawl.tools.checkstyle.checks.whitespace.MethodParamPadCheck"
                }
            ],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/opencb-opencga/errored/1/278/ExecutionDaemon.java b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/opencb-opencga/styler_three_grams/278/ExecutionDaemon.java\nindex 4ab7639085c..ad11fa48598 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/opencb-opencga/errored/1/278/ExecutionDaemon.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/opencb-opencga/styler_three_grams/278/ExecutionDaemon.java\n@@ -593,8 +593,10 @@ public class ExecutionDaemon extends MonitorParentDaemon {\n \n             List<Study> studiesToValidate;\n             if (tool.scope() == Tool.Scope.PROJECT) {\n-                String projectFqn = job.getStudy().getId().substring(0, job.getStudy().getId().indexOf(ParamConstants.PROJECT_STUDY_SEPARATOR));\n-                studiesToValidate = catalogManager.getStudyManager().search(projectFqn, new Query(),\n+                String projectFqn =job.getStudy()\n+                . getId ( ). substring (0,\n+                job .getStudy().getId().indexOf(ParamConstants.PROJECT_STUDY_SEPARATOR));\n+                 studiesToValidate = catalogManager.getStudyManager().search(projectFqn, new Query(),\n                         new QueryOptions(QueryOptions.INCLUDE, Arrays.asList(StudyDBAdaptor.QueryParams.GROUPS.key(),\n                                 StudyDBAdaptor.QueryParams.FQN.key())), token).getResults();\n             } else {\n",
            "diff_size": 4
        }
    ],
    "repaired_by": [
        "intellij"
    ],
    "not_repaired_by": [
        "styler",
        "naturalize",
        "codebuff",
        "styler_random",
        "styler_three_grams"
    ]
}