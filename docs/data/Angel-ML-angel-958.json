{
    "project_name": "Angel-ML-angel",
    "error_id": "958",
    "information": {
        "errors": [
            {
                "line": "150",
                "severity": "error",
                "message": "Line is longer than 100 characters (found 104).",
                "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
            }
        ]
    },
    "source_code": "\n    private void createSketch(Tuple2<IntArrayList, FloatArrayList>[] features,\n                              int[] nnzLocal, int[] nnzGlobal, final GBDTModel model) throws Exception {\n        long createStart = System.currentTimeMillis();\n        // 1. create local quantile sketches\n        HeapQuantileSketch[] sketches = new HeapQuantileSketch[numFeatures];",
    "results": [
        {
            "tool": "styler",
            "errors": [],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/Angel-ML-angel/errored/1/958/FPDataStore.java b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/Angel-ML-angel/styler/958/FPDataStore.java\nindex c27d0aa2ff1..82e55d690ea 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/Angel-ML-angel/errored/1/958/FPDataStore.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/Angel-ML-angel/styler/958/FPDataStore.java\n@@ -147,7 +147,7 @@ public class FPDataStore extends DataStore {\n     }\n \n     private void createSketch(Tuple2<IntArrayList, FloatArrayList>[] features,\n-                              int[] nnzLocal, int[] nnzGlobal, final GBDTModel model) throws Exception {\n+    int[] nnzLocal, int[] nnzGlobal, final GBDTModel model) throws Exception {\n         long createStart = System.currentTimeMillis();\n         // 1. create local quantile sketches\n         HeapQuantileSketch[] sketches = new HeapQuantileSketch[numFeatures];\n",
            "diff_size": 1
        },
        {
            "tool": "intellij",
            "errors": [],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/Angel-ML-angel/errored/1/958/FPDataStore.java b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/Angel-ML-angel/intellij/958/FPDataStore.java\nindex c27d0aa2ff1..b27d1b0014a 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/Angel-ML-angel/errored/1/958/FPDataStore.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/Angel-ML-angel/intellij/958/FPDataStore.java\n@@ -29,250 +29,251 @@ import java.util.Map;\n  * Feature parallel data store\n  */\n public class FPDataStore extends DataStore {\n-    private static final Log LOG = LogFactory.getLog(FPDataStore.class);\n-\n-    private int[][] featIndices;\n-    private int[][] featBins;\n-\n-    private int featLo;\n-    private int featHi;\n-\n-    public FPDataStore(TaskContext taskContext, TreeParam param) {\n-        super(taskContext, param);\n-        featLo = taskContext.getTaskIndex() * (param.numFeature / param.numWorker);\n-        featHi = taskContext.getTaskIndex() + 1 == param.numWorker\n-                ? param.numFeature : featLo + param.numFeature / param.numWorker;\n-        LOG.info(String.format(\"Worker[%d] feature range: [%d, %d), %d features in total\",\n-                taskContext.getTaskIndex(), featLo, featHi, param.numFeature));\n+  private static final Log LOG = LogFactory.getLog(FPDataStore.class);\n+\n+  private int[][] featIndices;\n+  private int[][] featBins;\n+\n+  private int featLo;\n+  private int featHi;\n+\n+  public FPDataStore(TaskContext taskContext, TreeParam param) {\n+    super(taskContext, param);\n+    featLo = taskContext.getTaskIndex() * (param.numFeature / param.numWorker);\n+    featHi = taskContext.getTaskIndex() + 1 == param.numWorker\n+        ? param.numFeature : featLo + param.numFeature / param.numWorker;\n+    LOG.info(String.format(\"Worker[%d] feature range: [%d, %d), %d features in total\",\n+        taskContext.getTaskIndex(), featLo, featHi, param.numFeature));\n+  }\n+\n+  @Override\n+  public void init(DataBlock<LabeledData> dataStorage, final GBDTModel model) throws Exception {\n+    long initStart = System.currentTimeMillis();\n+\n+    LOG.info(\"Create feature parallel data meta, numFeature=\" + numFeatures);\n+    // 1. read data\n+    Tuple2<IntArrayList, FloatArrayList>[] features =\n+        readDataAndCreateSketch(dataStorage, model);\n+    // 2. turn feature values into bin indexes\n+    findBins(features, nnzLocal, nnzGlobal, model);\n+    // 3. ensure labels\n+    ensureLabel(((GBDTParam) param).numClass);\n+\n+\n+    LOG.info(String.format(\"Create feature-parallel data meta cost %d ms, numInstance=%d\",\n+        (System.currentTimeMillis() - initStart), numInstances));\n+  }\n+\n+  private Tuple2<IntArrayList, FloatArrayList>[] readDataAndCreateSketch(\n+      DataBlock<LabeledData> dataStorage, final GBDTModel model) throws Exception {\n+    long readStart = System.currentTimeMillis();\n+    // 1. read data\n+    Tuple2<IntArrayList, FloatArrayList>[] features = new Tuple2[numFeatures];\n+    Arrays.setAll(features, fid -> new Tuple2<>(new IntArrayList(), new FloatArrayList()));\n+    FloatArrayList labelsList = new FloatArrayList(dataStorage.size());\n+    nnzLocal = new int[numFeatures];\n+    numInstances = 0;\n+    dataStorage.resetReadIndex();\n+    LabeledData data = dataStorage.read();\n+    while (data != null) {\n+      SparseDoubleSortedVector x = (SparseDoubleSortedVector) data.getX();\n+      int[] indices = x.getIndices();\n+      double[] values = x.getValues();\n+      for (int i = 0; i < indices.length; i++) {\n+        int fid = indices[i];\n+        float fvalue = (float) values[i];\n+        features[fid]._1.add(numInstances);\n+        features[fid]._2.add(fvalue);\n+      }\n+      labelsList.add((float) data.getY());\n+      numInstances++;\n+      data = dataStorage.read();\n     }\n-\n-    @Override\n-    public void init(DataBlock<LabeledData> dataStorage, final GBDTModel model) throws Exception {\n-        long initStart = System.currentTimeMillis();\n-\n-        LOG.info(\"Create feature parallel data meta, numFeature=\" + numFeatures);\n-        // 1. read data\n-        Tuple2<IntArrayList, FloatArrayList>[] features =\n-                readDataAndCreateSketch(dataStorage, model);\n-        // 2. turn feature values into bin indexes\n-        findBins(features, nnzLocal, nnzGlobal, model);\n-        // 3. ensure labels\n-        ensureLabel(((GBDTParam) param).numClass);\n-\n-\n-        LOG.info(String.format(\"Create feature-parallel data meta cost %d ms, numInstance=%d\",\n-                (System.currentTimeMillis() - initStart), numInstances));\n+    LOG.info(String.format(\"Worker[%d] has %d instances\",\n+        taskContext.getTaskIndex(), numInstances));\n+    // 2. push local instance num, sum up feature nnz\n+    PSModel workerInsModel = model.getPSModel(GBDTModel.INSTANCE_NUM_MAT());\n+    PSModel nnzModel = model.getPSModel(GBDTModel.NNZ_NUM_MAT());\n+    if (taskContext.getTaskIndex() == 0) {\n+      workerInsModel.zero();\n+      nnzModel.zero();\n     }\n+    model.sync();\n \n-    private Tuple2<IntArrayList, FloatArrayList>[] readDataAndCreateSketch(\n-            DataBlock<LabeledData> dataStorage, final GBDTModel model) throws Exception {\n-        long readStart = System.currentTimeMillis();\n-        // 1. read data\n-        Tuple2<IntArrayList, FloatArrayList>[] features = new Tuple2[numFeatures];\n-        Arrays.setAll(features, fid -> new Tuple2<>(new IntArrayList(), new FloatArrayList()));\n-        FloatArrayList labelsList = new FloatArrayList(dataStorage.size());\n-        nnzLocal = new int[numFeatures];\n-        numInstances = 0;\n-        dataStorage.resetReadIndex();\n-        LabeledData data = dataStorage.read();\n-        while (data != null) {\n-            SparseDoubleSortedVector x = (SparseDoubleSortedVector) data.getX();\n-            int[] indices = x.getIndices();\n-            double[] values = x.getValues();\n-            for (int i = 0; i < indices.length; i++) {\n-                int fid = indices[i];\n-                float fvalue = (float) values[i];\n-                features[fid]._1.add(numInstances);\n-                features[fid]._2.add(fvalue);\n-            }\n-            labelsList.add((float) data.getY());\n-            numInstances++;\n-            data = dataStorage.read();\n-        }\n-        LOG.info(String.format(\"Worker[%d] has %d instances\",\n-                taskContext.getTaskIndex(), numInstances));\n-        // 2. push local instance num, sum up feature nnz\n-        PSModel workerInsModel = model.getPSModel(GBDTModel.INSTANCE_NUM_MAT());\n-        PSModel nnzModel = model.getPSModel(GBDTModel.NNZ_NUM_MAT());\n-        if (taskContext.getTaskIndex() == 0) {\n-            workerInsModel.zero();\n-            nnzModel.zero();\n-        }\n-        model.sync();\n-\n-        DenseIntVector workerInsVec = new DenseIntVector(param.numWorker);\n-        workerInsVec.set(taskContext.getTaskIndex(), numInstances);\n-        workerInsModel.increment(0, workerInsVec);\n+    DenseIntVector workerInsVec = new DenseIntVector(param.numWorker);\n+    workerInsVec.set(taskContext.getTaskIndex(), numInstances);\n+    workerInsModel.increment(0, workerInsVec);\n \n-        Arrays.setAll(nnzLocal, fid -> features[fid]._1.size());\n-        DenseIntVector nnzVec = new DenseIntVector(numFeatures, nnzLocal);\n-        nnzModel.increment(0, nnzVec);\n+    Arrays.setAll(nnzLocal, fid -> features[fid]._1.size());\n+    DenseIntVector nnzVec = new DenseIntVector(numFeatures, nnzLocal);\n+    nnzModel.increment(0, nnzVec);\n \n-        workerInsModel.clock(true).get();\n-        nnzModel.clock(true).get();\n+    workerInsModel.clock(true).get();\n+    nnzModel.clock(true).get();\n \n-        workerNumIns = ((DenseIntVector) workerInsModel.getRow(0)).getValues();\n-        nnzGlobal = ((DenseIntVector) nnzModel.getRow(0)).getValues();\n+    workerNumIns = ((DenseIntVector) workerInsModel.getRow(0)).getValues();\n+    nnzGlobal = ((DenseIntVector) nnzModel.getRow(0)).getValues();\n \n-        int globalNumIns = 0, insIdOffset = 0;\n-        for (int workerId = 0; workerId < param.numWorker; workerId++) {\n-            globalNumIns += workerNumIns[workerId];\n-            if (workerId < taskContext.getTaskIndex()) {\n-                insIdOffset += workerNumIns[workerId];\n-            }\n-        }\n-        LOG.info(String.format(\"Worker[%d] has %d instances, offset: %d, \" +\n-                \"instance number of all workers: %s, %d instances in total\",\n-                taskContext.getTaskIndex(), numInstances, insIdOffset,\n-                Arrays.toString(workerNumIns), globalNumIns));\n-        // 3. set label for each instance\n-        DenseFloatVector labelsVec = new DenseFloatVector(globalNumIns);\n-        for (int insId = 0; insId < numInstances; insId++) {\n-            int trueId = insId + insIdOffset;\n-            float label = labelsList.getFloat(insId);\n-            labelsVec.set(trueId, label);\n-        }\n-        PSModel labelsModel = model.getPSModel(GBDTModel.LABEL_MAT());\n-        labelsModel.increment(0, labelsVec);\n-        labelsModel.clock(true).get();\n-        labels = ((DenseFloatVector) labelsModel.getRow(0)).getValues();\n-        numInstances = globalNumIns;\n-\n-        // 4. create sketches\n-        createSketch(features, nnzLocal, nnzGlobal, model);\n-\n-        LOG.info(String.format(\"Read data and create sketch cost %d ms\",\n-                System.currentTimeMillis() - readStart));\n-        return features;\n+    int globalNumIns = 0, insIdOffset = 0;\n+    for (int workerId = 0; workerId < param.numWorker; workerId++) {\n+      globalNumIns += workerNumIns[workerId];\n+      if (workerId < taskContext.getTaskIndex()) {\n+        insIdOffset += workerNumIns[workerId];\n+      }\n     }\n-\n-    private void createSketch(Tuple2<IntArrayList, FloatArrayList>[] features,\n-                              int[] nnzLocal, int[] nnzGlobal, final GBDTModel model) throws Exception {\n-        long createStart = System.currentTimeMillis();\n-        // 1. create local quantile sketches\n-        HeapQuantileSketch[] sketches = new HeapQuantileSketch[numFeatures];\n-        for (int fid = 0; fid < numFeatures; fid++) {\n-            sketches[fid] = new HeapQuantileSketch((long) nnzLocal[fid]);\n-            for (int i = 0; i < nnzLocal[fid]; i++) {\n-                sketches[fid].update(features[fid]._2.getFloat(i));\n-            }\n-        }\n-        // 2. push to PS and merge on PS\n-        splits = mergeSketchAndPullQuantiles(sketches, nnzGlobal, model);\n-        // 3. set zero bin indexes\n-        zeroBins = new int[numFeatures];\n-        Arrays.setAll(zeroBins, i -> findZeroBin(splits[i]));\n-\n-        LOG.info(String.format(\"Create sketch cost %d ms\",\n-                System.currentTimeMillis() - createStart));\n+    LOG.info(String.format(\"Worker[%d] has %d instances, offset: %d, \" +\n+            \"instance number of all workers: %s, %d instances in total\",\n+        taskContext.getTaskIndex(), numInstances, insIdOffset,\n+        Arrays.toString(workerNumIns), globalNumIns));\n+    // 3. set label for each instance\n+    DenseFloatVector labelsVec = new DenseFloatVector(globalNumIns);\n+    for (int insId = 0; insId < numInstances; insId++) {\n+      int trueId = insId + insIdOffset;\n+      float label = labelsList.getFloat(insId);\n+      labelsVec.set(trueId, label);\n+    }\n+    PSModel labelsModel = model.getPSModel(GBDTModel.LABEL_MAT());\n+    labelsModel.increment(0, labelsVec);\n+    labelsModel.clock(true).get();\n+    labels = ((DenseFloatVector) labelsModel.getRow(0)).getValues();\n+    numInstances = globalNumIns;\n+\n+    // 4. create sketches\n+    createSketch(features, nnzLocal, nnzGlobal, model);\n+\n+    LOG.info(String.format(\"Read data and create sketch cost %d ms\",\n+        System.currentTimeMillis() - readStart));\n+    return features;\n+  }\n+\n+  private void createSketch(Tuple2<IntArrayList, FloatArrayList>[] features,\n+                            int[] nnzLocal, int[] nnzGlobal, final GBDTModel model)\n+      throws Exception {\n+    long createStart = System.currentTimeMillis();\n+    // 1. create local quantile sketches\n+    HeapQuantileSketch[] sketches = new HeapQuantileSketch[numFeatures];\n+    for (int fid = 0; fid < numFeatures; fid++) {\n+      sketches[fid] = new HeapQuantileSketch((long) nnzLocal[fid]);\n+      for (int i = 0; i < nnzLocal[fid]; i++) {\n+        sketches[fid].update(features[fid]._2.getFloat(i));\n+      }\n+    }\n+    // 2. push to PS and merge on PS\n+    splits = mergeSketchAndPullQuantiles(sketches, nnzGlobal, model);\n+    // 3. set zero bin indexes\n+    zeroBins = new int[numFeatures];\n+    Arrays.setAll(zeroBins, i -> findZeroBin(splits[i]));\n+\n+    LOG.info(String.format(\"Create sketch cost %d ms\",\n+        System.currentTimeMillis() - createStart));\n+  }\n+\n+  private void findBins(Tuple2<IntArrayList, FloatArrayList>[] features,\n+                        int[] nnzLocal, int[] nnzGlobal, final GBDTModel model) throws Exception {\n+    long startTime = System.currentTimeMillis();\n+\n+    PSModel featRowModel = model.getPSModel(GBDTModel.FEAT_ROW_MAT());\n+    int matrixId = featRowModel.getMatrixId();\n+\n+    int numFeature = param.numFeature;\n+    int numSplit = param.numSplit;\n+    int numWorker = param.numWorker;\n+\n+    int insIdOffset = 0;\n+    for (int i = 0; i < taskContext.getTaskIndex(); i++) {\n+      insIdOffset += workerNumIns[i];\n     }\n \n-    private void findBins(Tuple2<IntArrayList, FloatArrayList>[] features,\n-                          int[] nnzLocal, int[] nnzGlobal, final GBDTModel model) throws Exception {\n-        long startTime = System.currentTimeMillis();\n-\n-        PSModel featRowModel = model.getPSModel(GBDTModel.FEAT_ROW_MAT());\n-        int matrixId = featRowModel.getMatrixId();\n-\n-        int numFeature = param.numFeature;\n-        int numSplit = param.numSplit;\n-        int numWorker = param.numWorker;\n-\n-        int insIdOffset = 0;\n-        for (int i = 0; i < taskContext.getTaskIndex(); i++) {\n-            insIdOffset += workerNumIns[i];\n-        }\n-\n-        featIndices = new int[featHi - featLo][];\n-        featBins = new int[featHi - featLo][];\n-\n-        int fid = 0;\n-        int batchSize = 1024;\n-        int[] rowIndexes = new int[batchSize];\n+    featIndices = new int[featHi - featLo][];\n+    featBins = new int[featHi - featLo][];\n+\n+    int fid = 0;\n+    int batchSize = 1024;\n+    int[] rowIndexes = new int[batchSize];\n+    Arrays.setAll(rowIndexes, i -> i);\n+    while (fid < numFeature) {\n+      if (fid + batchSize > numFeature) {\n+        batchSize = numFeature - fid;\n+        rowIndexes = new int[batchSize];\n         Arrays.setAll(rowIndexes, i -> i);\n-        while (fid < numFeature) {\n-            if (fid + batchSize > numFeature) {\n-                batchSize = numFeature - fid;\n-                rowIndexes = new int[batchSize];\n-                Arrays.setAll(rowIndexes, i -> i);\n-            }\n-            FeatureRowsUpdateParam<Byte> updateParam = new FeatureRowsUpdateParam<>(\n-                    matrixId, true, numWorker, taskContext.getTaskIndex(), batchSize, numSplit);\n-            // 1. set up a batch\n-            for (int i = 0; i < batchSize; i++) {\n-                int nnz = nnzLocal[fid + i];\n-                int[] fIndices = new int[nnz];\n-                int[] fBins = new int[nnz];\n-                for (int j = 0; j < nnz; j++) {\n-                    int trueFid = fid + i;\n-                    fIndices[j] = features[trueFid]._1.getInt(j) + insIdOffset;\n-                    fBins[j] = indexOf(features[trueFid]._2.getFloat(j), trueFid);\n-                }\n-                updateParam.set(i, fIndices, fBins);\n-            }\n-            // 2. push local feature rows to PS\n-            featRowModel.update(new FeatureRowsUpdateFunc<>(updateParam)).get();\n-            model.sync();\n-            // 3. pull global feature rows from PS\n-            int start = fid, stop = fid + batchSize;\n-            if (featLo < stop && featHi > start) {\n-                int from = Math.max(featLo, start) - start;\n-                int to = Math.min(featHi, stop) - start;\n-                int[] getRowIndexes;\n-                if (to - from == batchSize) {\n-                    getRowIndexes = rowIndexes;\n-                } else {\n-                    getRowIndexes = new int[to - from];\n-                    Arrays.setAll(getRowIndexes, i -> i + from);\n-                }\n-                Map<Object, Tuple2<int[], int[]>> featRows =\n-                        ((FeatureRowsGetResult) featRowModel.get(new FeatureRowsGetFunc<>(\n-                                matrixId, numWorker, getRowIndexes, numSplit))).getFeatureRows();\n-                for (Map.Entry<Object, Tuple2<int[], int[]>> entry : featRows.entrySet()) {\n-                    int rowId = (Integer) entry.getKey();\n-                    int trueFid = rowId + start;\n-                    Tuple2<int[], int[]> featRow = entry.getValue();\n-                    featIndices[trueFid - featLo] = featRow._1;\n-                    featBins[trueFid - featLo] = featRow._2;\n-                    if (featIndices[trueFid - featLo].length != nnzGlobal[trueFid]) {\n-                        throw new AngelException(String.format(\n-                                \"Missing values: feature[%d] has %d but got %d\", trueFid,\n-                                featIndices[trueFid - featLo].length, nnzGlobal[trueFid]));\n-                    }\n-                }\n-            }\n-            model.sync();\n-            fid += batchSize;\n+      }\n+      FeatureRowsUpdateParam<Byte> updateParam = new FeatureRowsUpdateParam<>(\n+          matrixId, true, numWorker, taskContext.getTaskIndex(), batchSize, numSplit);\n+      // 1. set up a batch\n+      for (int i = 0; i < batchSize; i++) {\n+        int nnz = nnzLocal[fid + i];\n+        int[] fIndices = new int[nnz];\n+        int[] fBins = new int[nnz];\n+        for (int j = 0; j < nnz; j++) {\n+          int trueFid = fid + i;\n+          fIndices[j] = features[trueFid]._1.getInt(j) + insIdOffset;\n+          fBins[j] = indexOf(features[trueFid]._2.getFloat(j), trueFid);\n         }\n-\n-        LOG.info(String.format(\"Set feature rows cost %d ms\",\n-                System.currentTimeMillis() - startTime));\n-    }\n-\n-    @Override\n-    public float get(int fid, int insId, float defaultValue) {\n-        int index = Arrays.binarySearch(featIndices[fid - featLo], insId);\n-        if (index >= 0) {\n-            int binId = featBins[fid - featLo][index];\n-            return splits[fid - featLo][binId];\n+        updateParam.set(i, fIndices, fBins);\n+      }\n+      // 2. push local feature rows to PS\n+      featRowModel.update(new FeatureRowsUpdateFunc<>(updateParam)).get();\n+      model.sync();\n+      // 3. pull global feature rows from PS\n+      int start = fid, stop = fid + batchSize;\n+      if (featLo < stop && featHi > start) {\n+        int from = Math.max(featLo, start) - start;\n+        int to = Math.min(featHi, stop) - start;\n+        int[] getRowIndexes;\n+        if (to - from == batchSize) {\n+          getRowIndexes = rowIndexes;\n         } else {\n-            return defaultValue;\n+          getRowIndexes = new int[to - from];\n+          Arrays.setAll(getRowIndexes, i -> i + from);\n         }\n+        Map<Object, Tuple2<int[], int[]>> featRows =\n+            ((FeatureRowsGetResult) featRowModel.get(new FeatureRowsGetFunc<>(\n+                matrixId, numWorker, getRowIndexes, numSplit))).getFeatureRows();\n+        for (Map.Entry<Object, Tuple2<int[], int[]>> entry : featRows.entrySet()) {\n+          int rowId = (Integer) entry.getKey();\n+          int trueFid = rowId + start;\n+          Tuple2<int[], int[]> featRow = entry.getValue();\n+          featIndices[trueFid - featLo] = featRow._1;\n+          featBins[trueFid - featLo] = featRow._2;\n+          if (featIndices[trueFid - featLo].length != nnzGlobal[trueFid]) {\n+            throw new AngelException(String.format(\n+                \"Missing values: feature[%d] has %d but got %d\", trueFid,\n+                featIndices[trueFid - featLo].length, nnzGlobal[trueFid]));\n+          }\n+        }\n+      }\n+      model.sync();\n+      fid += batchSize;\n     }\n \n-    public int[] getFeatIndices(int fid) {\n-        return featIndices[fid - featLo];\n+    LOG.info(String.format(\"Set feature rows cost %d ms\",\n+        System.currentTimeMillis() - startTime));\n+  }\n+\n+  @Override\n+  public float get(int fid, int insId, float defaultValue) {\n+    int index = Arrays.binarySearch(featIndices[fid - featLo], insId);\n+    if (index >= 0) {\n+      int binId = featBins[fid - featLo][index];\n+      return splits[fid - featLo][binId];\n+    } else {\n+      return defaultValue;\n     }\n+  }\n \n-    public int[] getFeatBins(int fid) {\n-        return featBins[fid - featLo];\n-    }\n+  public int[] getFeatIndices(int fid) {\n+    return featIndices[fid - featLo];\n+  }\n \n-    public int getFeatLo() {\n-        return featLo;\n-    }\n+  public int[] getFeatBins(int fid) {\n+    return featBins[fid - featLo];\n+  }\n \n-    public int getFeatHi() {\n-        return featHi;\n-    }\n+  public int getFeatLo() {\n+    return featLo;\n+  }\n+\n+  public int getFeatHi() {\n+    return featHi;\n+  }\n }\n",
            "diff_size": 348
        },
        {
            "tool": "naturalize",
            "errors": [
                {
                    "line": "44",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 132).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "45",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 154).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "55",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 102).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "57",
                    "severity": "error",
                    "message": "Comment has incorrect indentation level 0, expected is 8, indentation should be the same level as line 58.",
                    "source": "com.puppycrawl.tools.checkstyle.checks.indentation.CommentsIndentationCheck"
                },
                {
                    "line": "61",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 144).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "64",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 152).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "89",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 105).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "90",
                    "severity": "error",
                    "message": "Comment has incorrect indentation level 0, expected is 8, indentation should be the same level as line 91.",
                    "source": "com.puppycrawl.tools.checkstyle.checks.indentation.CommentsIndentationCheck"
                },
                {
                    "line": "120",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 137).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "123",
                    "severity": "error",
                    "message": "Comment has incorrect indentation level 0, expected is 8, indentation should be the same level as line 124.",
                    "source": "com.puppycrawl.tools.checkstyle.checks.indentation.CommentsIndentationCheck"
                },
                {
                    "line": "139",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 114).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "143",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 153).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "160",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 102).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "163",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 149).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "192",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 160).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "193",
                    "severity": "error",
                    "message": "Comment has incorrect indentation level 0, expected is 12, indentation should be the same level as line 194.",
                    "source": "com.puppycrawl.tools.checkstyle.checks.indentation.CommentsIndentationCheck"
                },
                {
                    "line": "220",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 192).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "237",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 103).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                }
            ],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/Angel-ML-angel/errored/1/958/FPDataStore.java b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/Angel-ML-angel/naturalize/958/FPDataStore.java\nindex c27d0aa2ff1..34220e1e4b7 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/Angel-ML-angel/errored/1/958/FPDataStore.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/Angel-ML-angel/naturalize/958/FPDataStore.java\n@@ -29,7 +29,8 @@ import java.util.Map;\n  * Feature parallel data store\n  */\n public class FPDataStore extends DataStore {\n-    private static final Log LOG = LogFactory.getLog(FPDataStore.class);\n+\n+  private static final Log LOG = LogFactory.getLog(FPDataStore.class);\n \n     private int[][] featIndices;\n     private int[][] featBins;\n@@ -38,35 +39,31 @@ public class FPDataStore extends DataStore {\n     private int featHi;\n \n     public FPDataStore(TaskContext taskContext, TreeParam param) {\n-        super(taskContext, param);\n+  super(taskContext, param);\n         featLo = taskContext.getTaskIndex() * (param.numFeature / param.numWorker);\n-        featHi = taskContext.getTaskIndex() + 1 == param.numWorker\n-                ? param.numFeature : featLo + param.numFeature / param.numWorker;\n-        LOG.info(String.format(\"Worker[%d] feature range: [%d, %d), %d features in total\",\n-                taskContext.getTaskIndex(), featLo, featHi, param.numFeature));\n-    }\n+        featHi = taskContext.getTaskIndex() + 1 == param.numWorker ? param.numFeature : featLo + param.numFeature / param.numWorker;\n+        LOG.info(String.format(\"Worker[%d] feature range: [%d, %d), %d features in total\", taskContext.getTaskIndex(), featLo, featHi, param.numFeature));\n+  }\n \n     @Override\n     public void init(DataBlock<LabeledData> dataStorage, final GBDTModel model) throws Exception {\n-        long initStart = System.currentTimeMillis();\n+\n+  long initStart = System.currentTimeMillis();\n \n         LOG.info(\"Create feature parallel data meta, numFeature=\" + numFeatures);\n         // 1. read data\n-        Tuple2<IntArrayList, FloatArrayList>[] features =\n-                readDataAndCreateSketch(dataStorage, model);\n-        // 2. turn feature values into bin indexes\n+        Tuple2<IntArrayList, FloatArrayList>[] features = readDataAndCreateSketch(dataStorage, model);\n+\n+// 2. turn feature values into bin indexes\n         findBins(features, nnzLocal, nnzGlobal, model);\n         // 3. ensure labels\n         ensureLabel(((GBDTParam) param).numClass);\n+LOG.info(String.format(\"Create feature-parallel data meta cost %d ms, numInstance=%d\", (System.currentTimeMillis() - initStart), numInstances));\n+  }\n \n+    private Tuple2<IntArrayList, FloatArrayList>[] readDataAndCreateSketch(DataBlock<LabeledData> dataStorage, final GBDTModel model) throws Exception {\n \n-        LOG.info(String.format(\"Create feature-parallel data meta cost %d ms, numInstance=%d\",\n-                (System.currentTimeMillis() - initStart), numInstances));\n-    }\n-\n-    private Tuple2<IntArrayList, FloatArrayList>[] readDataAndCreateSketch(\n-            DataBlock<LabeledData> dataStorage, final GBDTModel model) throws Exception {\n-        long readStart = System.currentTimeMillis();\n+  long readStart = System.currentTimeMillis();\n         // 1. read data\n         Tuple2<IntArrayList, FloatArrayList>[] features = new Tuple2[numFeatures];\n         Arrays.setAll(features, fid -> new Tuple2<>(new IntArrayList(), new FloatArrayList()));\n@@ -76,28 +73,27 @@ public class FPDataStore extends DataStore {\n         dataStorage.resetReadIndex();\n         LabeledData data = dataStorage.read();\n         while (data != null) {\n-            SparseDoubleSortedVector x = (SparseDoubleSortedVector) data.getX();\n+  SparseDoubleSortedVector x = (SparseDoubleSortedVector) data.getX();\n             int[] indices = x.getIndices();\n             double[] values = x.getValues();\n             for (int i = 0; i < indices.length; i++) {\n-                int fid = indices[i];\n+  int fid = indices[i];\n                 float fvalue = (float) values[i];\n                 features[fid]._1.add(numInstances);\n                 features[fid]._2.add(fvalue);\n-            }\n+  }\n             labelsList.add((float) data.getY());\n             numInstances++;\n             data = dataStorage.read();\n-        }\n-        LOG.info(String.format(\"Worker[%d] has %d instances\",\n-                taskContext.getTaskIndex(), numInstances));\n-        // 2. push local instance num, sum up feature nnz\n+  }\n+        LOG.info(String.format(\"Worker[%d] has %d instances\", taskContext.getTaskIndex(), numInstances));\n+// 2. push local instance num, sum up feature nnz\n         PSModel workerInsModel = model.getPSModel(GBDTModel.INSTANCE_NUM_MAT());\n         PSModel nnzModel = model.getPSModel(GBDTModel.NNZ_NUM_MAT());\n         if (taskContext.getTaskIndex() == 0) {\n-            workerInsModel.zero();\n+  workerInsModel.zero();\n             nnzModel.zero();\n-        }\n+  }\n         model.sync();\n \n         DenseIntVector workerInsVec = new DenseIntVector(param.numWorker);\n@@ -116,22 +112,21 @@ public class FPDataStore extends DataStore {\n \n         int globalNumIns = 0, insIdOffset = 0;\n         for (int workerId = 0; workerId < param.numWorker; workerId++) {\n-            globalNumIns += workerNumIns[workerId];\n+  globalNumIns += workerNumIns[workerId];\n             if (workerId < taskContext.getTaskIndex()) {\n-                insIdOffset += workerNumIns[workerId];\n+  insIdOffset += workerNumIns[workerId];\n             }\n-        }\n-        LOG.info(String.format(\"Worker[%d] has %d instances, offset: %d, \" +\n-                \"instance number of all workers: %s, %d instances in total\",\n+  }\n+        LOG.info(String.format(\"Worker[%d] has %d instances, offset: %d, \" + \"instance number of all workers: %s, %d instances in total\",\n                 taskContext.getTaskIndex(), numInstances, insIdOffset,\n                 Arrays.toString(workerNumIns), globalNumIns));\n-        // 3. set label for each instance\n+// 3. set label for each instance\n         DenseFloatVector labelsVec = new DenseFloatVector(globalNumIns);\n         for (int insId = 0; insId < numInstances; insId++) {\n-            int trueId = insId + insIdOffset;\n+  int trueId = insId + insIdOffset;\n             float label = labelsList.getFloat(insId);\n             labelsVec.set(trueId, label);\n-        }\n+  }\n         PSModel labelsModel = model.getPSModel(GBDTModel.LABEL_MAT());\n         labelsModel.increment(0, labelsVec);\n         labelsModel.clock(true).get();\n@@ -141,35 +136,33 @@ public class FPDataStore extends DataStore {\n         // 4. create sketches\n         createSketch(features, nnzLocal, nnzGlobal, model);\n \n-        LOG.info(String.format(\"Read data and create sketch cost %d ms\",\n-                System.currentTimeMillis() - readStart));\n+        LOG.info(String.format(\"Read data and create sketch cost %d ms\", System.currentTimeMillis() - readStart));\n         return features;\n-    }\n+  }\n+\n+    private void createSketch(Tuple2<IntArrayList, FloatArrayList>[] features, int[] nnzLocal, int[] nnzGlobal, final GBDTModel model) throws Exception {\n \n-    private void createSketch(Tuple2<IntArrayList, FloatArrayList>[] features,\n-                              int[] nnzLocal, int[] nnzGlobal, final GBDTModel model) throws Exception {\n-        long createStart = System.currentTimeMillis();\n+  long createStart = System.currentTimeMillis();\n         // 1. create local quantile sketches\n         HeapQuantileSketch[] sketches = new HeapQuantileSketch[numFeatures];\n         for (int fid = 0; fid < numFeatures; fid++) {\n-            sketches[fid] = new HeapQuantileSketch((long) nnzLocal[fid]);\n+  sketches[fid] = new HeapQuantileSketch((long) nnzLocal[fid]);\n             for (int i = 0; i < nnzLocal[fid]; i++) {\n-                sketches[fid].update(features[fid]._2.getFloat(i));\n+  sketches[fid].update(features[fid]._2.getFloat(i));\n             }\n-        }\n+  }\n         // 2. push to PS and merge on PS\n         splits = mergeSketchAndPullQuantiles(sketches, nnzGlobal, model);\n         // 3. set zero bin indexes\n         zeroBins = new int[numFeatures];\n         Arrays.setAll(zeroBins, i -> findZeroBin(splits[i]));\n \n-        LOG.info(String.format(\"Create sketch cost %d ms\",\n-                System.currentTimeMillis() - createStart));\n-    }\n+        LOG.info(String.format(\"Create sketch cost %d ms\", System.currentTimeMillis() - createStart));\n+  }\n+\n+    private void findBins(Tuple2<IntArrayList, FloatArrayList>[] features, int[] nnzLocal, int[] nnzGlobal, final GBDTModel model) throws Exception {\n \n-    private void findBins(Tuple2<IntArrayList, FloatArrayList>[] features,\n-                          int[] nnzLocal, int[] nnzGlobal, final GBDTModel model) throws Exception {\n-        long startTime = System.currentTimeMillis();\n+  long startTime = System.currentTimeMillis();\n \n         PSModel featRowModel = model.getPSModel(GBDTModel.FEAT_ROW_MAT());\n         int matrixId = featRowModel.getMatrixId();\n@@ -180,8 +173,8 @@ public class FPDataStore extends DataStore {\n \n         int insIdOffset = 0;\n         for (int i = 0; i < taskContext.getTaskIndex(); i++) {\n-            insIdOffset += workerNumIns[i];\n-        }\n+  insIdOffset += workerNumIns[i];\n+  }\n \n         featIndices = new int[featHi - featLo][];\n         featBins = new int[featHi - featLo][];\n@@ -191,88 +184,83 @@ public class FPDataStore extends DataStore {\n         int[] rowIndexes = new int[batchSize];\n         Arrays.setAll(rowIndexes, i -> i);\n         while (fid < numFeature) {\n-            if (fid + batchSize > numFeature) {\n-                batchSize = numFeature - fid;\n+  if (fid + batchSize > numFeature) {\n+  batchSize = numFeature - fid;\n                 rowIndexes = new int[batchSize];\n                 Arrays.setAll(rowIndexes, i -> i);\n-            }\n-            FeatureRowsUpdateParam<Byte> updateParam = new FeatureRowsUpdateParam<>(\n-                    matrixId, true, numWorker, taskContext.getTaskIndex(), batchSize, numSplit);\n-            // 1. set up a batch\n+  }\n+            FeatureRowsUpdateParam<Byte> updateParam = new FeatureRowsUpdateParam<>(matrixId, true, numWorker, taskContext.getTaskIndex(), batchSize, numSplit);\n+// 1. set up a batch\n             for (int i = 0; i < batchSize; i++) {\n-                int nnz = nnzLocal[fid + i];\n+  int nnz = nnzLocal[fid + i];\n                 int[] fIndices = new int[nnz];\n                 int[] fBins = new int[nnz];\n                 for (int j = 0; j < nnz; j++) {\n-                    int trueFid = fid + i;\n+  int trueFid = fid + i;\n                     fIndices[j] = features[trueFid]._1.getInt(j) + insIdOffset;\n                     fBins[j] = indexOf(features[trueFid]._2.getFloat(j), trueFid);\n-                }\n+  }\n                 updateParam.set(i, fIndices, fBins);\n-            }\n+  }\n             // 2. push local feature rows to PS\n             featRowModel.update(new FeatureRowsUpdateFunc<>(updateParam)).get();\n             model.sync();\n             // 3. pull global feature rows from PS\n             int start = fid, stop = fid + batchSize;\n             if (featLo < stop && featHi > start) {\n-                int from = Math.max(featLo, start) - start;\n+  int from = Math.max(featLo, start) - start;\n                 int to = Math.min(featHi, stop) - start;\n                 int[] getRowIndexes;\n                 if (to - from == batchSize) {\n-                    getRowIndexes = rowIndexes;\n+  getRowIndexes = rowIndexes;\n                 } else {\n-                    getRowIndexes = new int[to - from];\n+  getRowIndexes = new int[to - from];\n                     Arrays.setAll(getRowIndexes, i -> i + from);\n-                }\n-                Map<Object, Tuple2<int[], int[]>> featRows =\n-                        ((FeatureRowsGetResult) featRowModel.get(new FeatureRowsGetFunc<>(\n-                                matrixId, numWorker, getRowIndexes, numSplit))).getFeatureRows();\n-                for (Map.Entry<Object, Tuple2<int[], int[]>> entry : featRows.entrySet()) {\n-                    int rowId = (Integer) entry.getKey();\n+  }\n+                Map<Object, Tuple2<int[], int[]>> featRows = ((FeatureRowsGetResult) featRowModel.get(new FeatureRowsGetFunc<>(matrixId, numWorker, getRowIndexes, numSplit))).getFeatureRows();\n+for (Map.Entry<Object, Tuple2<int[], int[]>> entry : featRows.entrySet()) {\n+  int rowId = (Integer) entry.getKey();\n                     int trueFid = rowId + start;\n                     Tuple2<int[], int[]> featRow = entry.getValue();\n                     featIndices[trueFid - featLo] = featRow._1;\n                     featBins[trueFid - featLo] = featRow._2;\n                     if (featIndices[trueFid - featLo].length != nnzGlobal[trueFid]) {\n-                        throw new AngelException(String.format(\n-                                \"Missing values: feature[%d] has %d but got %d\", trueFid,\n+  throw new AngelException(String.format(\"Missing values: feature[%d] has %d but got %d\", trueFid,\n                                 featIndices[trueFid - featLo].length, nnzGlobal[trueFid]));\n-                    }\n-                }\n-            }\n+  }\n+  }\n+  }\n             model.sync();\n             fid += batchSize;\n         }\n \n-        LOG.info(String.format(\"Set feature rows cost %d ms\",\n-                System.currentTimeMillis() - startTime));\n-    }\n+        LOG.info(String.format(\"Set feature rows cost %d ms\", System.currentTimeMillis() - startTime));\n+  }\n \n     @Override\n     public float get(int fid, int insId, float defaultValue) {\n-        int index = Arrays.binarySearch(featIndices[fid - featLo], insId);\n+  int index = Arrays.binarySearch(featIndices[fid - featLo], insId);\n         if (index >= 0) {\n-            int binId = featBins[fid - featLo][index];\n+  int binId = featBins[fid - featLo][index];\n             return splits[fid - featLo][binId];\n         } else {\n-            return defaultValue;\n+  return defaultValue;\n         }\n-    }\n+  }\n \n     public int[] getFeatIndices(int fid) {\n-        return featIndices[fid - featLo];\n-    }\n+  return featIndices[fid - featLo];\n+  }\n \n     public int[] getFeatBins(int fid) {\n-        return featBins[fid - featLo];\n-    }\n+  return featBins[fid - featLo];\n+  }\n \n     public int getFeatLo() {\n-        return featLo;\n-    }\n+  return featLo;\n+  }\n \n     public int getFeatHi() {\n-        return featHi;\n+  return featHi;\n     }\n-}\n+  }\n\\ No newline at end of file\n",
            "diff_size": 99
        },
        {
            "tool": "codebuff",
            "errors": [
                {
                    "line": "42",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 128).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "43",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 150).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "50",
                    "severity": "error",
                    "message": "Comment has incorrect indentation level 8, expected is 4, indentation should be the same level as line 51.",
                    "source": "com.puppycrawl.tools.checkstyle.checks.indentation.CommentsIndentationCheck"
                },
                {
                    "line": "52",
                    "severity": "error",
                    "message": "Comment has incorrect indentation level 8, expected is 4, indentation should be the same level as line 53.",
                    "source": "com.puppycrawl.tools.checkstyle.checks.indentation.CommentsIndentationCheck"
                },
                {
                    "line": "54",
                    "severity": "error",
                    "message": "Comment has incorrect indentation level 8, expected is 4, indentation should be the same level as line 55.",
                    "source": "com.puppycrawl.tools.checkstyle.checks.indentation.CommentsIndentationCheck"
                },
                {
                    "line": "60",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 150).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "62",
                    "severity": "error",
                    "message": "Comment has incorrect indentation level 8, expected is 4, indentation should be the same level as line 63.",
                    "source": "com.puppycrawl.tools.checkstyle.checks.indentation.CommentsIndentationCheck"
                },
                {
                    "line": "84",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 101).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "85",
                    "severity": "error",
                    "message": "Comment has incorrect indentation level 8, expected is 4, indentation should be the same level as line 86.",
                    "source": "com.puppycrawl.tools.checkstyle.checks.indentation.CommentsIndentationCheck"
                },
                {
                    "line": "111",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 235).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "112",
                    "severity": "error",
                    "message": "Comment has incorrect indentation level 8, expected is 4, indentation should be the same level as line 113.",
                    "source": "com.puppycrawl.tools.checkstyle.checks.indentation.CommentsIndentationCheck"
                },
                {
                    "line": "126",
                    "severity": "error",
                    "message": "Comment has incorrect indentation level 8, expected is 4, indentation should be the same level as line 127.",
                    "source": "com.puppycrawl.tools.checkstyle.checks.indentation.CommentsIndentationCheck"
                },
                {
                    "line": "128",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 110).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "133",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 127).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "135",
                    "severity": "error",
                    "message": "Comment has incorrect indentation level 8, expected is 4, indentation should be the same level as line 136.",
                    "source": "com.puppycrawl.tools.checkstyle.checks.indentation.CommentsIndentationCheck"
                },
                {
                    "line": "143",
                    "severity": "error",
                    "message": "Comment has incorrect indentation level 8, expected is 4, indentation should be the same level as line 144.",
                    "source": "com.puppycrawl.tools.checkstyle.checks.indentation.CommentsIndentationCheck"
                },
                {
                    "line": "145",
                    "severity": "error",
                    "message": "Comment has incorrect indentation level 8, expected is 4, indentation should be the same level as line 146.",
                    "source": "com.puppycrawl.tools.checkstyle.checks.indentation.CommentsIndentationCheck"
                },
                {
                    "line": "152",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 127).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "178",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 154).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "179",
                    "severity": "error",
                    "message": "Comment has incorrect indentation level 12, expected is 6, indentation should be the same level as line 180.",
                    "source": "com.puppycrawl.tools.checkstyle.checks.indentation.CommentsIndentationCheck"
                },
                {
                    "line": "191",
                    "severity": "error",
                    "message": "Comment has incorrect indentation level 12, expected is 6, indentation should be the same level as line 192.",
                    "source": "com.puppycrawl.tools.checkstyle.checks.indentation.CommentsIndentationCheck"
                },
                {
                    "line": "194",
                    "severity": "error",
                    "message": "Comment has incorrect indentation level 12, expected is 6, indentation should be the same level as line 196.",
                    "source": "com.puppycrawl.tools.checkstyle.checks.indentation.CommentsIndentationCheck"
                },
                {
                    "line": "208",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 184).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "216",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 168).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                }
            ],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/Angel-ML-angel/errored/1/958/FPDataStore.java b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/Angel-ML-angel/codebuff/958/FPDataStore.java\nindex c27d0aa2ff1..9cc1ddbcda0 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/Angel-ML-angel/errored/1/958/FPDataStore.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/Angel-ML-angel/codebuff/958/FPDataStore.java\n@@ -21,258 +21,233 @@ import it.unimi.dsi.fastutil.ints.IntArrayList;\n import org.apache.commons.logging.Log;\n import org.apache.commons.logging.LogFactory;\n import scala.Tuple2;\n-\n import java.util.Arrays;\n import java.util.Map;\n \n /**\n  * Feature parallel data store\n  */\n-public class FPDataStore extends DataStore {\n-    private static final Log LOG = LogFactory.getLog(FPDataStore.class);\n-\n-    private int[][] featIndices;\n-    private int[][] featBins;\n-\n-    private int featLo;\n-    private int featHi;\n \n-    public FPDataStore(TaskContext taskContext, TreeParam param) {\n-        super(taskContext, param);\n-        featLo = taskContext.getTaskIndex() * (param.numFeature / param.numWorker);\n-        featHi = taskContext.getTaskIndex() + 1 == param.numWorker\n-                ? param.numFeature : featLo + param.numFeature / param.numWorker;\n-        LOG.info(String.format(\"Worker[%d] feature range: [%d, %d), %d features in total\",\n-                taskContext.getTaskIndex(), featLo, featHi, param.numFeature));\n-    }\n-\n-    @Override\n-    public void init(DataBlock<LabeledData> dataStorage, final GBDTModel model) throws Exception {\n-        long initStart = System.currentTimeMillis();\n+public class FPDataStore extends DataStore {\n \n-        LOG.info(\"Create feature parallel data meta, numFeature=\" + numFeatures);\n+  private static final Log LOG = LogFactory.getLog(FPDataStore.class);\n+  private int[][] featIndices;\n+  private int[][] featBins;\n+  private int featLo;\n+  private int featHi;\n+\n+  public FPDataStore(TaskContext taskContext, TreeParam param) {\n+    super(taskContext, param);\n+    featLo = taskContext.getTaskIndex() * (param.numFeature / param.numWorker);\n+    featHi = taskContext.getTaskIndex() + 1 == param.numWorker ? param.numFeature : featLo + param.numFeature / param.numWorker;\n+    LOG.info(String.format(\"Worker[%d] feature range: [%d, %d), %d features in total\", taskContext.getTaskIndex(), featLo, featHi, param.numFeature));\n+  }\n+\n+  @Override\n+  public void init(DataBlock<LabeledData> dataStorage, final GBDTModel model) throws Exception {\n+    long initStart = System.currentTimeMillis();\n+    LOG.info(\"Create feature parallel data meta, numFeature=\" + numFeatures);\n         // 1. read data\n-        Tuple2<IntArrayList, FloatArrayList>[] features =\n-                readDataAndCreateSketch(dataStorage, model);\n+    Tuple2<IntArrayList, FloatArrayList>[] features = readDataAndCreateSketch(dataStorage, model);\n         // 2. turn feature values into bin indexes\n-        findBins(features, nnzLocal, nnzGlobal, model);\n+    findBins(features, nnzLocal, nnzGlobal, model);\n         // 3. ensure labels\n-        ensureLabel(((GBDTParam) param).numClass);\n+    ensureLabel(((GBDTParam) param).numClass);\n+    LOG.info(String.format(\"Create feature-parallel data meta cost %d ms, numInstance=%d\",\n+        (System.currentTimeMillis() - initStart), numInstances));\n+  }\n \n-\n-        LOG.info(String.format(\"Create feature-parallel data meta cost %d ms, numInstance=%d\",\n-                (System.currentTimeMillis() - initStart), numInstances));\n-    }\n-\n-    private Tuple2<IntArrayList, FloatArrayList>[] readDataAndCreateSketch(\n-            DataBlock<LabeledData> dataStorage, final GBDTModel model) throws Exception {\n-        long readStart = System.currentTimeMillis();\n+  private Tuple2<IntArrayList, FloatArrayList>[] readDataAndCreateSketch(DataBlock<LabeledData> dataStorage, final GBDTModel model) throws Exception {\n+    long readStart = System.currentTimeMillis();\n         // 1. read data\n-        Tuple2<IntArrayList, FloatArrayList>[] features = new Tuple2[numFeatures];\n-        Arrays.setAll(features, fid -> new Tuple2<>(new IntArrayList(), new FloatArrayList()));\n-        FloatArrayList labelsList = new FloatArrayList(dataStorage.size());\n-        nnzLocal = new int[numFeatures];\n-        numInstances = 0;\n-        dataStorage.resetReadIndex();\n-        LabeledData data = dataStorage.read();\n-        while (data != null) {\n-            SparseDoubleSortedVector x = (SparseDoubleSortedVector) data.getX();\n-            int[] indices = x.getIndices();\n-            double[] values = x.getValues();\n-            for (int i = 0; i < indices.length; i++) {\n-                int fid = indices[i];\n-                float fvalue = (float) values[i];\n-                features[fid]._1.add(numInstances);\n-                features[fid]._2.add(fvalue);\n-            }\n-            labelsList.add((float) data.getY());\n-            numInstances++;\n-            data = dataStorage.read();\n-        }\n-        LOG.info(String.format(\"Worker[%d] has %d instances\",\n-                taskContext.getTaskIndex(), numInstances));\n+    Tuple2<IntArrayList, FloatArrayList>[] features = new Tuple2[numFeatures];\n+    Arrays.setAll(features, fid-> new Tuple2<>(new IntArrayList(), new FloatArrayList()));\n+    FloatArrayList labelsList = new FloatArrayList(dataStorage.size());\n+    nnzLocal = new int[numFeatures];\n+    numInstances = 0;\n+    dataStorage.resetReadIndex();\n+    LabeledData data = dataStorage.read();\n+    while (data != null) {\n+      SparseDoubleSortedVector x = (SparseDoubleSortedVector) data.getX();\n+      int[] indices = x.getIndices();\n+      double[] values = x.getValues();\n+      for (int i = 0; i < indices.length; i++) {\n+        int fid = indices[i];\n+        float fvalue = (float) values[i];\n+        features[fid]._1.add(numInstances);\n+        features[fid]._2.add(fvalue);\n+      }\n+      labelsList.add((float) data.getY());\n+      numInstances++;\n+      data = dataStorage.read();\n+    }\n+    LOG.info(String.format(\"Worker[%d] has %d instances\", taskContext.getTaskIndex(), numInstances));\n         // 2. push local instance num, sum up feature nnz\n-        PSModel workerInsModel = model.getPSModel(GBDTModel.INSTANCE_NUM_MAT());\n-        PSModel nnzModel = model.getPSModel(GBDTModel.NNZ_NUM_MAT());\n-        if (taskContext.getTaskIndex() == 0) {\n-            workerInsModel.zero();\n-            nnzModel.zero();\n-        }\n-        model.sync();\n-\n-        DenseIntVector workerInsVec = new DenseIntVector(param.numWorker);\n-        workerInsVec.set(taskContext.getTaskIndex(), numInstances);\n-        workerInsModel.increment(0, workerInsVec);\n-\n-        Arrays.setAll(nnzLocal, fid -> features[fid]._1.size());\n-        DenseIntVector nnzVec = new DenseIntVector(numFeatures, nnzLocal);\n-        nnzModel.increment(0, nnzVec);\n-\n-        workerInsModel.clock(true).get();\n-        nnzModel.clock(true).get();\n-\n-        workerNumIns = ((DenseIntVector) workerInsModel.getRow(0)).getValues();\n-        nnzGlobal = ((DenseIntVector) nnzModel.getRow(0)).getValues();\n-\n-        int globalNumIns = 0, insIdOffset = 0;\n-        for (int workerId = 0; workerId < param.numWorker; workerId++) {\n-            globalNumIns += workerNumIns[workerId];\n-            if (workerId < taskContext.getTaskIndex()) {\n-                insIdOffset += workerNumIns[workerId];\n-            }\n-        }\n-        LOG.info(String.format(\"Worker[%d] has %d instances, offset: %d, \" +\n-                \"instance number of all workers: %s, %d instances in total\",\n-                taskContext.getTaskIndex(), numInstances, insIdOffset,\n-                Arrays.toString(workerNumIns), globalNumIns));\n+    PSModel workerInsModel = model.getPSModel(GBDTModel.INSTANCE_NUM_MAT());\n+    PSModel nnzModel = model.getPSModel(GBDTModel.NNZ_NUM_MAT());\n+    if (taskContext.getTaskIndex() == 0) {\n+      workerInsModel.zero();\n+      nnzModel.zero();\n+    }\n+    model.sync();\n+    DenseIntVector workerInsVec = new DenseIntVector(param.numWorker);\n+    workerInsVec.set(taskContext.getTaskIndex(), numInstances);\n+    workerInsModel.increment(0, workerInsVec);\n+    Arrays.setAll(nnzLocal, fid-> features[fid]._1.size());\n+    DenseIntVector nnzVec = new DenseIntVector(numFeatures, nnzLocal);\n+    nnzModel.increment(0, nnzVec);\n+    workerInsModel.clock(true).get();\n+    nnzModel.clock(true).get();\n+    workerNumIns = ((DenseIntVector) workerInsModel.getRow(0)).getValues();\n+    nnzGlobal = ((DenseIntVector) nnzModel.getRow(0)).getValues();\n+\n+    int globalNumIns = 0, insIdOffset = 0;\n+    for (int workerId = 0; workerId < param.numWorker; workerId++) {\n+      globalNumIns += workerNumIns[workerId];\n+      if (workerId < taskContext.getTaskIndex()) {\n+        insIdOffset += workerNumIns[workerId];\n+      }\n+    }\n+    LOG.info(String.format(\"Worker[%d] has %d instances, offset: %d, \" + \"instance number of all workers: %s, %d instances in total\", taskContext.getTaskIndex(), numInstances, insIdOffset, Arrays.toString(workerNumIns), globalNumIns));\n         // 3. set label for each instance\n-        DenseFloatVector labelsVec = new DenseFloatVector(globalNumIns);\n-        for (int insId = 0; insId < numInstances; insId++) {\n-            int trueId = insId + insIdOffset;\n-            float label = labelsList.getFloat(insId);\n-            labelsVec.set(trueId, label);\n-        }\n-        PSModel labelsModel = model.getPSModel(GBDTModel.LABEL_MAT());\n-        labelsModel.increment(0, labelsVec);\n-        labelsModel.clock(true).get();\n-        labels = ((DenseFloatVector) labelsModel.getRow(0)).getValues();\n-        numInstances = globalNumIns;\n-\n-        // 4. create sketches\n-        createSketch(features, nnzLocal, nnzGlobal, model);\n-\n-        LOG.info(String.format(\"Read data and create sketch cost %d ms\",\n-                System.currentTimeMillis() - readStart));\n-        return features;\n+    DenseFloatVector labelsVec = new DenseFloatVector(globalNumIns);\n+    for (int insId = 0; insId < numInstances; insId++) {\n+      int trueId = insId + insIdOffset;\n+      float label = labelsList.getFloat(insId);\n+      labelsVec.set(trueId, label);\n     }\n \n-    private void createSketch(Tuple2<IntArrayList, FloatArrayList>[] features,\n-                              int[] nnzLocal, int[] nnzGlobal, final GBDTModel model) throws Exception {\n-        long createStart = System.currentTimeMillis();\n+    PSModel labelsModel = model.getPSModel(GBDTModel.LABEL_MAT());\n+    labelsModel.increment(0, labelsVec);\n+    labelsModel.clock(true).get();\n+    labels = ((DenseFloatVector) labelsModel.getRow(0)).getValues();\n+    numInstances = globalNumIns;\n+\n+        // 4. create sketches\n+    createSketch(features, nnzLocal, nnzGlobal, model);\n+    LOG.info(String.format(\"Read data and create sketch cost %d ms\", System.currentTimeMillis() - readStart));\n+    return features;\n+  }\n+\n+  private void createSketch(\n+    Tuple2<IntArrayList, FloatArrayList>[] features, int[] nnzLocal, int[] nnzGlobal, final GBDTModel model) throws Exception {\n+    long createStart = System.currentTimeMillis();\n         // 1. create local quantile sketches\n-        HeapQuantileSketch[] sketches = new HeapQuantileSketch[numFeatures];\n-        for (int fid = 0; fid < numFeatures; fid++) {\n-            sketches[fid] = new HeapQuantileSketch((long) nnzLocal[fid]);\n-            for (int i = 0; i < nnzLocal[fid]; i++) {\n-                sketches[fid].update(features[fid]._2.getFloat(i));\n-            }\n-        }\n+    HeapQuantileSketch[] sketches = new HeapQuantileSketch[numFeatures];\n+    for (int fid = 0; fid < numFeatures; fid++) {\n+      sketches[fid] = new HeapQuantileSketch((long) nnzLocal[fid]);\n+      for (int i = 0; i < nnzLocal[fid]; i++) {\n+        sketches[fid].update(features[fid]._2.getFloat(i));\n+      }\n+    }\n         // 2. push to PS and merge on PS\n-        splits = mergeSketchAndPullQuantiles(sketches, nnzGlobal, model);\n+    splits = mergeSketchAndPullQuantiles(sketches, nnzGlobal, model);\n         // 3. set zero bin indexes\n-        zeroBins = new int[numFeatures];\n-        Arrays.setAll(zeroBins, i -> findZeroBin(splits[i]));\n-\n-        LOG.info(String.format(\"Create sketch cost %d ms\",\n-                System.currentTimeMillis() - createStart));\n+    zeroBins = new int[numFeatures];\n+    Arrays.setAll(zeroBins, i-> findZeroBin(splits[i]));\n+    LOG.info(String.format(\"Create sketch cost %d ms\", System.currentTimeMillis() - createStart));\n+  }\n+\n+  private void findBins(\n+    Tuple2<IntArrayList, FloatArrayList>[] features, int[] nnzLocal, int[] nnzGlobal, final GBDTModel model) throws Exception {\n+    long startTime = System.currentTimeMillis();\n+    PSModel featRowModel = model.getPSModel(GBDTModel.FEAT_ROW_MAT());\n+    int matrixId = featRowModel.getMatrixId();\n+    int numFeature = param.numFeature;\n+    int numSplit = param.numSplit;\n+    int numWorker = param.numWorker;\n+    int insIdOffset = 0;\n+    for (int i = 0; i < taskContext.getTaskIndex(); i++) {\n+      insIdOffset += workerNumIns[i];\n     }\n-\n-    private void findBins(Tuple2<IntArrayList, FloatArrayList>[] features,\n-                          int[] nnzLocal, int[] nnzGlobal, final GBDTModel model) throws Exception {\n-        long startTime = System.currentTimeMillis();\n-\n-        PSModel featRowModel = model.getPSModel(GBDTModel.FEAT_ROW_MAT());\n-        int matrixId = featRowModel.getMatrixId();\n-\n-        int numFeature = param.numFeature;\n-        int numSplit = param.numSplit;\n-        int numWorker = param.numWorker;\n-\n-        int insIdOffset = 0;\n-        for (int i = 0; i < taskContext.getTaskIndex(); i++) {\n-            insIdOffset += workerNumIns[i];\n-        }\n-\n-        featIndices = new int[featHi - featLo][];\n-        featBins = new int[featHi - featLo][];\n-\n-        int fid = 0;\n-        int batchSize = 1024;\n-        int[] rowIndexes = new int[batchSize];\n-        Arrays.setAll(rowIndexes, i -> i);\n-        while (fid < numFeature) {\n-            if (fid + batchSize > numFeature) {\n-                batchSize = numFeature - fid;\n-                rowIndexes = new int[batchSize];\n-                Arrays.setAll(rowIndexes, i -> i);\n-            }\n-            FeatureRowsUpdateParam<Byte> updateParam = new FeatureRowsUpdateParam<>(\n-                    matrixId, true, numWorker, taskContext.getTaskIndex(), batchSize, numSplit);\n+    featIndices = new int[featHi - featLo][];\n+    featBins = new int[featHi - featLo][];\n+\n+    int fid = 0;\n+    int batchSize = 1024;\n+    int[] rowIndexes = new int[batchSize];\n+    Arrays.setAll(rowIndexes, i-> i);\n+\n+    while (fid < numFeature) {\n+      if (fid + batchSize > numFeature) {\n+        batchSize = numFeature - fid;\n+        rowIndexes = new int[batchSize];\n+        Arrays.setAll(rowIndexes, i-> i);\n+      }\n+\n+      FeatureRowsUpdateParam<Byte> updateParam = new FeatureRowsUpdateParam<>(matrixId, true, numWorker, taskContext.getTaskIndex(), batchSize, numSplit);\n             // 1. set up a batch\n-            for (int i = 0; i < batchSize; i++) {\n-                int nnz = nnzLocal[fid + i];\n-                int[] fIndices = new int[nnz];\n-                int[] fBins = new int[nnz];\n-                for (int j = 0; j < nnz; j++) {\n-                    int trueFid = fid + i;\n-                    fIndices[j] = features[trueFid]._1.getInt(j) + insIdOffset;\n-                    fBins[j] = indexOf(features[trueFid]._2.getFloat(j), trueFid);\n-                }\n-                updateParam.set(i, fIndices, fBins);\n-            }\n+      for (int i = 0; i < batchSize; i++) {\n+        int nnz = nnzLocal[fid + i];\n+        int[] fIndices = new int[nnz];\n+        int[] fBins = new int[nnz];\n+        for (int j = 0; j < nnz; j++) {\n+          int trueFid = fid + i;\n+          fIndices[j] = features[trueFid]._1.getInt(j) + insIdOffset;\n+          fBins[j] = indexOf(features[trueFid]._2.getFloat(j), trueFid);\n+        }\n+        updateParam.set(i, fIndices, fBins);\n+      }\n             // 2. push local feature rows to PS\n-            featRowModel.update(new FeatureRowsUpdateFunc<>(updateParam)).get();\n-            model.sync();\n+      featRowModel.update(new FeatureRowsUpdateFunc<>(updateParam)).get();\n+      model.sync();\n             // 3. pull global feature rows from PS\n-            int start = fid, stop = fid + batchSize;\n-            if (featLo < stop && featHi > start) {\n-                int from = Math.max(featLo, start) - start;\n-                int to = Math.min(featHi, stop) - start;\n-                int[] getRowIndexes;\n-                if (to - from == batchSize) {\n-                    getRowIndexes = rowIndexes;\n-                } else {\n-                    getRowIndexes = new int[to - from];\n-                    Arrays.setAll(getRowIndexes, i -> i + from);\n-                }\n-                Map<Object, Tuple2<int[], int[]>> featRows =\n-                        ((FeatureRowsGetResult) featRowModel.get(new FeatureRowsGetFunc<>(\n-                                matrixId, numWorker, getRowIndexes, numSplit))).getFeatureRows();\n-                for (Map.Entry<Object, Tuple2<int[], int[]>> entry : featRows.entrySet()) {\n-                    int rowId = (Integer) entry.getKey();\n-                    int trueFid = rowId + start;\n-                    Tuple2<int[], int[]> featRow = entry.getValue();\n-                    featIndices[trueFid - featLo] = featRow._1;\n-                    featBins[trueFid - featLo] = featRow._2;\n-                    if (featIndices[trueFid - featLo].length != nnzGlobal[trueFid]) {\n-                        throw new AngelException(String.format(\n-                                \"Missing values: feature[%d] has %d but got %d\", trueFid,\n-                                featIndices[trueFid - featLo].length, nnzGlobal[trueFid]));\n-                    }\n-                }\n-            }\n-            model.sync();\n-            fid += batchSize;\n-        }\n-\n-        LOG.info(String.format(\"Set feature rows cost %d ms\",\n-                System.currentTimeMillis() - startTime));\n-    }\n \n-    @Override\n-    public float get(int fid, int insId, float defaultValue) {\n-        int index = Arrays.binarySearch(featIndices[fid - featLo], insId);\n-        if (index >= 0) {\n-            int binId = featBins[fid - featLo][index];\n-            return splits[fid - featLo][binId];\n+      int start = fid, stop = fid + batchSize;\n+      if (featLo < stop && featHi > start) {\n+        int from = Math.max(featLo, start) - start;\n+        int to = Math.min(featHi, stop) - start;\n+        int[] getRowIndexes;\n+        if (to - from == batchSize) {\n+          getRowIndexes = rowIndexes;\n         } else {\n-            return defaultValue;\n+          getRowIndexes = new int[to - from];\n+          Arrays.setAll(getRowIndexes, i-> i + from);\n         }\n-    }\n \n-    public int[] getFeatIndices(int fid) {\n-        return featIndices[fid - featLo];\n+        Map<Object, Tuple2<int[], int[]>> featRows = ((FeatureRowsGetResult) featRowModel.get(new FeatureRowsGetFunc<>(matrixId, numWorker, getRowIndexes, numSplit))).getFeatureRows();\n+        for (Map.Entry<Object, Tuple2<int[], int[]>> entry : featRows.entrySet()) {\n+          int rowId = (Integer) entry.getKey();\n+          int trueFid = rowId + start;\n+          Tuple2<int[], int[]> featRow = entry.getValue();\n+          featIndices[trueFid - featLo] = featRow._1;\n+          featBins[trueFid - featLo] = featRow._2;\n+          if (featIndices[trueFid - featLo].length != nnzGlobal[trueFid]) {\n+            throw new AngelException(String.format(\"Missing values: feature[%d] has %d but got %d\", trueFid, featIndices[trueFid - featLo].length, nnzGlobal[trueFid]));\n+          }\n+        }\n+      }\n+      model.sync();\n+      fid += batchSize;\n     }\n-\n-    public int[] getFeatBins(int fid) {\n-        return featBins[fid - featLo];\n+    LOG.info(String.format(\"Set feature rows cost %d ms\", System.currentTimeMillis() - startTime));\n+  }\n+\n+  @Override\n+  public float get(int fid, int insId, float defaultValue) {\n+    int index = Arrays.binarySearch(featIndices[fid - featLo], insId);\n+    if (index >= 0) {\n+      int binId = featBins[fid - featLo][index];\n+      return splits[fid - featLo][binId];\n+    } else {\n+      return defaultValue;\n     }\n+  }\n \n-    public int getFeatLo() {\n-        return featLo;\n-    }\n+  public int[] getFeatIndices(int fid) {\n+    return featIndices[fid - featLo];\n+  }\n \n-    public int getFeatHi() {\n-        return featHi;\n-    }\n-}\n+  public int[] getFeatBins(int fid) {\n+    return featBins[fid - featLo];\n+  }\n+\n+  public int getFeatLo() {\n+    return featLo;\n+  }\n+\n+  public int getFeatHi() {\n+    return featHi;\n+  }\n+\n+}\n\\ No newline at end of file\n",
            "diff_size": 297
        },
        {
            "tool": "styler_random",
            "errors": [],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/Angel-ML-angel/errored/1/958/FPDataStore.java b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/Angel-ML-angel/styler_random/958/FPDataStore.java\nindex c27d0aa2ff1..cff03dd791d 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/Angel-ML-angel/errored/1/958/FPDataStore.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/Angel-ML-angel/styler_random/958/FPDataStore.java\n@@ -147,8 +147,8 @@ public class FPDataStore extends DataStore {\n     }\n \n     private void createSketch(Tuple2<IntArrayList, FloatArrayList>[] features,\n-                              int[] nnzLocal, int[] nnzGlobal, final GBDTModel model) throws Exception {\n-        long createStart = System.currentTimeMillis();\n+        int[] nnzLocal, int[] nnzGlobal, final GBDTModel model) throws Exception {\n+  long createStart = System.currentTimeMillis();\n         // 1. create local quantile sketches\n         HeapQuantileSketch[] sketches = new HeapQuantileSketch[numFeatures];\n         for (int fid = 0; fid < numFeatures; fid++) {\n",
            "diff_size": 2
        },
        {
            "tool": "styler_three_grams",
            "errors": [],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/Angel-ML-angel/errored/1/958/FPDataStore.java b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/Angel-ML-angel/styler_three_grams/958/FPDataStore.java\nindex c27d0aa2ff1..82e55d690ea 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/Angel-ML-angel/errored/1/958/FPDataStore.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/Angel-ML-angel/styler_three_grams/958/FPDataStore.java\n@@ -147,7 +147,7 @@ public class FPDataStore extends DataStore {\n     }\n \n     private void createSketch(Tuple2<IntArrayList, FloatArrayList>[] features,\n-                              int[] nnzLocal, int[] nnzGlobal, final GBDTModel model) throws Exception {\n+    int[] nnzLocal, int[] nnzGlobal, final GBDTModel model) throws Exception {\n         long createStart = System.currentTimeMillis();\n         // 1. create local quantile sketches\n         HeapQuantileSketch[] sketches = new HeapQuantileSketch[numFeatures];\n",
            "diff_size": 1
        }
    ],
    "repaired_by": [
        "styler",
        "intellij",
        "styler_random",
        "styler_three_grams"
    ],
    "not_repaired_by": [
        "naturalize",
        "codebuff"
    ]
}