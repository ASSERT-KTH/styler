{
    "project_name": "DSC-SPIDAL-harp",
    "error_id": "22",
    "information": {
        "errors": [
            {
                "line": "3",
                "severity": "error",
                "message": "Line has trailing spaces.",
                "source": "com.puppycrawl.tools.checkstyle.checks.regexp.RegexpSinglelineCheck"
            }
        ]
    },
    "source_code": "/*\n * Copyright 2013-2017 Indiana University\n * \n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at",
    "results": [
        {
            "tool": "styler",
            "errors": [
                {
                    "line": "3",
                    "severity": "error",
                    "message": "Line has trailing spaces.",
                    "source": "com.puppycrawl.tools.checkstyle.checks.regexp.RegexpSinglelineCheck"
                }
            ],
            "diff": "",
            "diff_size": 0
        },
        {
            "tool": "intellij",
            "errors": [],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/DSC-SPIDAL-harp/errored/1/22/MultiFileInputFormat.java b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/DSC-SPIDAL-harp/intellij/22/MultiFileInputFormat.java\nindex b16ff22ddb1..f50b1a32630 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/DSC-SPIDAL-harp/errored/1/22/MultiFileInputFormat.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/DSC-SPIDAL-harp/intellij/22/MultiFileInputFormat.java\n@@ -1,6 +1,6 @@\n /*\r\n  * Copyright 2013-2017 Indiana University\r\n- * \r\n+ *\r\n  * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n  * you may not use this file except in compliance with the License.\r\n  * You may obtain a copy of the License at\r\n@@ -37,125 +37,125 @@ import org.apache.hadoop.mapreduce.TaskAttemptContext;\n import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;\r\n \r\n public class MultiFileInputFormat\r\n-  extends FileInputFormat<String, String> {\r\n+    extends FileInputFormat<String, String> {\r\n \r\n-  private static final Log LOG =\r\n-    LogFactory.getLog(MultiFileInputFormat.class);\r\n+    private static final Log LOG =\r\n+        LogFactory.getLog(MultiFileInputFormat.class);\r\n \r\n-  static final String NUM_INPUT_FILES =\r\n-    \"mapreduce.input.num.files\";\r\n+    static final String NUM_INPUT_FILES =\r\n+        \"mapreduce.input.num.files\";\r\n \r\n-  @Override\r\n-  public List<InputSplit>\r\n+    @Override\r\n+    public List<InputSplit>\r\n     getSplits(JobContext job) throws IOException {\r\n-    // Generate splits\r\n-    List<InputSplit> splits =\r\n-      new ArrayList<InputSplit>();\r\n-    List<FileStatus> files = listStatus(job);\r\n-    org.apache.hadoop.mapred.JobConf jobConf =\r\n-      (JobConf) job.getConfiguration();\r\n-    int numMaps = jobConf.getNumMapTasks();\r\n-    LOG.info(\"NUMBER OF FILES: \" + files.size());\r\n-    LOG.info(\"NUMBER OF MAPS: \" + numMaps);\r\n-    // randomizeFileListOrder(files);\r\n-    int avg = files.size() / numMaps;\r\n-    int rest = files.size() % numMaps;\r\n-    int tmp = 0;\r\n-    long length = 0;\r\n-    List<Path> pathList = null;\r\n-    Set<String> hostSet = null;\r\n-    for (FileStatus file : files) {\r\n-      if (tmp == 0) {\r\n-        pathList = new ArrayList<Path>();\r\n-        hostSet = new HashSet<String>();\r\n-      }\r\n-      if (tmp < avg) {\r\n-        pathList.add(file.getPath());\r\n-        length = length + file.getLen();\r\n-        FileSystem fs = file.getPath()\r\n-          .getFileSystem(job.getConfiguration());\r\n-        BlockLocation[] blkLocations =\r\n-          fs.getFileBlockLocations(file, 0,\r\n-            file.getLen());\r\n-        for (BlockLocation blockLocation : blkLocations) {\r\n-          for (String host : blockLocation\r\n-            .getHosts()) {\r\n-            hostSet.add(host);\r\n-          }\r\n-        }\r\n-        tmp++;\r\n-        if (tmp == avg && rest == 0) {\r\n-          LOG.info(\"Split on host: \"\r\n-            + getHostsString(hostSet));\r\n-          splits.add(\r\n-            new MultiFileSplit(pathList, length,\r\n-              hostSet.toArray(new String[0])));\r\n-          tmp = 0;\r\n-          length = 0;\r\n-        }\r\n-      } else if (tmp == avg && rest > 0) {\r\n-        pathList.add(file.getPath());\r\n-        length = length + file.getLen();\r\n-        FileSystem fs = file.getPath()\r\n-          .getFileSystem(job.getConfiguration());\r\n-        BlockLocation[] blkLocations =\r\n-          fs.getFileBlockLocations(file, 0,\r\n-            file.getLen());\r\n-        for (BlockLocation blockLocation : blkLocations) {\r\n-          for (String host : blockLocation\r\n-            .getHosts()) {\r\n-            hostSet.add(host);\r\n-          }\r\n+        // Generate splits\r\n+        List<InputSplit> splits =\r\n+            new ArrayList<InputSplit>();\r\n+        List<FileStatus> files = listStatus(job);\r\n+        org.apache.hadoop.mapred.JobConf jobConf =\r\n+            (JobConf) job.getConfiguration();\r\n+        int numMaps = jobConf.getNumMapTasks();\r\n+        LOG.info(\"NUMBER OF FILES: \" + files.size());\r\n+        LOG.info(\"NUMBER OF MAPS: \" + numMaps);\r\n+        // randomizeFileListOrder(files);\r\n+        int avg = files.size() / numMaps;\r\n+        int rest = files.size() % numMaps;\r\n+        int tmp = 0;\r\n+        long length = 0;\r\n+        List<Path> pathList = null;\r\n+        Set<String> hostSet = null;\r\n+        for (FileStatus file : files) {\r\n+            if (tmp == 0) {\r\n+                pathList = new ArrayList<Path>();\r\n+                hostSet = new HashSet<String>();\r\n+            }\r\n+            if (tmp < avg) {\r\n+                pathList.add(file.getPath());\r\n+                length = length + file.getLen();\r\n+                FileSystem fs = file.getPath()\r\n+                    .getFileSystem(job.getConfiguration());\r\n+                BlockLocation[] blkLocations =\r\n+                    fs.getFileBlockLocations(file, 0,\r\n+                        file.getLen());\r\n+                for (BlockLocation blockLocation : blkLocations) {\r\n+                    for (String host : blockLocation\r\n+                        .getHosts()) {\r\n+                        hostSet.add(host);\r\n+                    }\r\n+                }\r\n+                tmp++;\r\n+                if (tmp == avg && rest == 0) {\r\n+                    LOG.info(\"Split on host: \"\r\n+                        + getHostsString(hostSet));\r\n+                    splits.add(\r\n+                        new MultiFileSplit(pathList, length,\r\n+                            hostSet.toArray(new String[0])));\r\n+                    tmp = 0;\r\n+                    length = 0;\r\n+                }\r\n+            } else if (tmp == avg && rest > 0) {\r\n+                pathList.add(file.getPath());\r\n+                length = length + file.getLen();\r\n+                FileSystem fs = file.getPath()\r\n+                    .getFileSystem(job.getConfiguration());\r\n+                BlockLocation[] blkLocations =\r\n+                    fs.getFileBlockLocations(file, 0,\r\n+                        file.getLen());\r\n+                for (BlockLocation blockLocation : blkLocations) {\r\n+                    for (String host : blockLocation\r\n+                        .getHosts()) {\r\n+                        hostSet.add(host);\r\n+                    }\r\n+                }\r\n+                rest--;\r\n+                LOG.info(\"Split on host: \"\r\n+                    + getHostsString(hostSet));\r\n+                splits.add(\r\n+                    new MultiFileSplit(pathList, length,\r\n+                        hostSet.toArray(new String[0])));\r\n+                tmp = 0;\r\n+                length = 0;\r\n+            }\r\n         }\r\n-        rest--;\r\n-        LOG.info(\"Split on host: \"\r\n-          + getHostsString(hostSet));\r\n-        splits.add(\r\n-          new MultiFileSplit(pathList, length,\r\n-            hostSet.toArray(new String[0])));\r\n-        tmp = 0;\r\n-        length = 0;\r\n-      }\r\n+        // Save the number of input files in the\r\n+        // job-conf\r\n+        job.getConfiguration()\r\n+            .setLong(NUM_INPUT_FILES, numMaps);\r\n+        LOG.info(\r\n+            \"Total # of splits: \" + splits.size());\r\n+        return splits;\r\n     }\r\n-    // Save the number of input files in the\r\n-    // job-conf\r\n-    job.getConfiguration()\r\n-      .setLong(NUM_INPUT_FILES, numMaps);\r\n-    LOG.info(\r\n-      \"Total # of splits: \" + splits.size());\r\n-    return splits;\r\n-  }\r\n \r\n-  @SuppressWarnings(\"unused\")\r\n-  private void randomizeFileListOrder(\r\n-    List<FileStatus> files) {\r\n-    Random random =\r\n-      new Random(System.currentTimeMillis());\r\n-    int numFiles = files.size();\r\n-    for (int i = numFiles - 1; i > 0; i--) {\r\n-      int nextRandom = random.nextInt(i + 1);\r\n-      if (nextRandom != i) {\r\n-        FileStatus tmpFile = files.get(i);\r\n-        files.set(i, files.get(nextRandom));\r\n-        files.set(nextRandom, tmpFile);\r\n-      }\r\n+    @SuppressWarnings(\"unused\")\r\n+    private void randomizeFileListOrder(\r\n+        List<FileStatus> files) {\r\n+        Random random =\r\n+            new Random(System.currentTimeMillis());\r\n+        int numFiles = files.size();\r\n+        for (int i = numFiles - 1; i > 0; i--) {\r\n+            int nextRandom = random.nextInt(i + 1);\r\n+            if (nextRandom != i) {\r\n+                FileStatus tmpFile = files.get(i);\r\n+                files.set(i, files.get(nextRandom));\r\n+                files.set(nextRandom, tmpFile);\r\n+            }\r\n+        }\r\n     }\r\n-  }\r\n \r\n-  private String\r\n+    private String\r\n     getHostsString(Set<String> hosts) {\r\n-    StringBuffer buffer = new StringBuffer();\r\n-    for (String host : hosts) {\r\n-      buffer.append(host + \" \");\r\n+        StringBuffer buffer = new StringBuffer();\r\n+        for (String host : hosts) {\r\n+            buffer.append(host + \" \");\r\n+        }\r\n+        return buffer.toString();\r\n     }\r\n-    return buffer.toString();\r\n-  }\r\n \r\n-  @Override\r\n-  public RecordReader<String, String>\r\n+    @Override\r\n+    public RecordReader<String, String>\r\n     createRecordReader(InputSplit split,\r\n-      TaskAttemptContext context)\r\n-      throws IOException, InterruptedException {\r\n-    return new MultiFileRecordReader();\r\n-  }\r\n+                       TaskAttemptContext context)\r\n+        throws IOException, InterruptedException {\r\n+        return new MultiFileRecordReader();\r\n+    }\r\n }\r\n",
            "diff_size": 122
        },
        {
            "tool": "naturalize",
            "errors": [
                {
                    "line": "3",
                    "severity": "error",
                    "message": "Line has trailing spaces.",
                    "source": "com.puppycrawl.tools.checkstyle.checks.regexp.RegexpSinglelineCheck"
                }
            ],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/DSC-SPIDAL-harp/errored/1/22/MultiFileInputFormat.java b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/DSC-SPIDAL-harp/naturalize/22/MultiFileInputFormat.java\nindex b16ff22ddb1..de8e60f7c3d 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/DSC-SPIDAL-harp/errored/1/22/MultiFileInputFormat.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/DSC-SPIDAL-harp/naturalize/22/MultiFileInputFormat.java\n@@ -40,9 +40,9 @@ public class MultiFileInputFormat\n   extends FileInputFormat<String, String> {\r\n \r\n   private static final Log LOG =\r\n-    LogFactory.getLog(MultiFileInputFormat.class);\r\n-\r\n-  static final String NUM_INPUT_FILES =\r\n+    LogFactory.getLog(MultiFileInputFormat.class);\n+\n+    static final String NUM_INPUT_FILES =\r\n     \"mapreduce.input.num.files\";\r\n \r\n   @Override\r\n@@ -142,8 +142,7 @@ public class MultiFileInputFormat\n     }\r\n   }\r\n \r\n-  private String\r\n-    getHostsString(Set<String> hosts) {\r\n+  private String getHostsString(Set<String> hosts) {\r\n     StringBuffer buffer = new StringBuffer();\r\n     for (String host : hosts) {\r\n       buffer.append(host + \" \");\r\n@@ -158,4 +157,4 @@ public class MultiFileInputFormat\n       throws IOException, InterruptedException {\r\n     return new MultiFileRecordReader();\r\n   }\r\n-}\r\n+}\n\\ No newline at end of file\n",
            "diff_size": 6
        },
        {
            "tool": "codebuff",
            "errors": [
                {
                    "line": "3",
                    "severity": "error",
                    "message": "Line has trailing spaces.",
                    "source": "com.puppycrawl.tools.checkstyle.checks.regexp.RegexpSinglelineCheck"
                }
            ],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/DSC-SPIDAL-harp/errored/1/22/MultiFileInputFormat.java b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/DSC-SPIDAL-harp/codebuff/22/MultiFileInputFormat.java\nindex b16ff22ddb1..7fe26cb8471 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/DSC-SPIDAL-harp/errored/1/22/MultiFileInputFormat.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/python/experiments/results/DSC-SPIDAL-harp/codebuff/22/MultiFileInputFormat.java\n@@ -14,148 +14,129 @@\n  * limitations under the License.\r\n  */\r\n \r\n-package edu.iu.fileformat;\r\n-\r\n-import java.io.IOException;\r\n-import java.util.ArrayList;\r\n-import java.util.HashSet;\r\n-import java.util.List;\r\n-import java.util.Random;\r\n-import java.util.Set;\r\n-\r\n-import org.apache.commons.logging.Log;\r\n-import org.apache.commons.logging.LogFactory;\r\n-import org.apache.hadoop.fs.BlockLocation;\r\n-import org.apache.hadoop.fs.FileStatus;\r\n-import org.apache.hadoop.fs.FileSystem;\r\n-import org.apache.hadoop.fs.Path;\r\n-import org.apache.hadoop.mapred.JobConf;\r\n-import org.apache.hadoop.mapreduce.InputSplit;\r\n-import org.apache.hadoop.mapreduce.JobContext;\r\n-import org.apache.hadoop.mapreduce.RecordReader;\r\n-import org.apache.hadoop.mapreduce.TaskAttemptContext;\r\n-import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;\r\n-\r\n-public class MultiFileInputFormat\r\n-  extends FileInputFormat<String, String> {\r\n-\r\n-  private static final Log LOG =\r\n-    LogFactory.getLog(MultiFileInputFormat.class);\r\n-\r\n-  static final String NUM_INPUT_FILES =\r\n-    \"mapreduce.input.num.files\";\r\n-\r\n-  @Override\r\n-  public List<InputSplit>\r\n-    getSplits(JobContext job) throws IOException {\r\n-    // Generate splits\r\n-    List<InputSplit> splits =\r\n-      new ArrayList<InputSplit>();\r\n-    List<FileStatus> files = listStatus(job);\r\n-    org.apache.hadoop.mapred.JobConf jobConf =\r\n-      (JobConf) job.getConfiguration();\r\n-    int numMaps = jobConf.getNumMapTasks();\r\n-    LOG.info(\"NUMBER OF FILES: \" + files.size());\r\n+package edu.iu.fileformat;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Random;\n+import java.util.Set;\n+import org.apache.commons.logging.Log;\n+import org.apache.commons.logging.LogFactory;\n+import org.apache.hadoop.fs.BlockLocation;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.mapred.JobConf;\n+import org.apache.hadoop.mapreduce.InputSplit;\n+import org.apache.hadoop.mapreduce.JobContext;\n+import org.apache.hadoop.mapreduce.RecordReader;\n+import org.apache.hadoop.mapreduce.TaskAttemptContext;\n+import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;\n+\n+\n+public class MultiFileInputFormat extends\n+  FileInputFormat<String, String> {\n+  private static final Log LOG = LogFactory.getLog(MultiFileInputFormat.class);\n+  static final String NUM_INPUT_FILES =\n+    \"mapreduce.input.num.files\";\n+\n+  @Override\n+  public List<InputSplit> getSplits(JobContext job)\n+    throws IOException {\r\n+    // Generate splits\n+    List<InputSplit> splits = new ArrayList<InputSplit>();\n+    List<FileStatus> files = listStatus(job);\n+    org.apache.hadoop.mapred.JobConf jobConf =\n+      (JobConf) job.getConfiguration();\n+    int numMaps = jobConf.getNumMapTasks();\n+    LOG.info(\"NUMBER OF FILES: \" + files.size());\n     LOG.info(\"NUMBER OF MAPS: \" + numMaps);\r\n-    // randomizeFileListOrder(files);\r\n-    int avg = files.size() / numMaps;\r\n-    int rest = files.size() % numMaps;\r\n-    int tmp = 0;\r\n-    long length = 0;\r\n-    List<Path> pathList = null;\r\n-    Set<String> hostSet = null;\r\n-    for (FileStatus file : files) {\r\n-      if (tmp == 0) {\r\n-        pathList = new ArrayList<Path>();\r\n-        hostSet = new HashSet<String>();\r\n-      }\r\n-      if (tmp < avg) {\r\n-        pathList.add(file.getPath());\r\n-        length = length + file.getLen();\r\n-        FileSystem fs = file.getPath()\r\n-          .getFileSystem(job.getConfiguration());\r\n-        BlockLocation[] blkLocations =\r\n-          fs.getFileBlockLocations(file, 0,\r\n-            file.getLen());\r\n-        for (BlockLocation blockLocation : blkLocations) {\r\n-          for (String host : blockLocation\r\n-            .getHosts()) {\r\n-            hostSet.add(host);\r\n-          }\r\n-        }\r\n-        tmp++;\r\n-        if (tmp == avg && rest == 0) {\r\n-          LOG.info(\"Split on host: \"\r\n-            + getHostsString(hostSet));\r\n-          splits.add(\r\n-            new MultiFileSplit(pathList, length,\r\n-              hostSet.toArray(new String[0])));\r\n-          tmp = 0;\r\n-          length = 0;\r\n-        }\r\n-      } else if (tmp == avg && rest > 0) {\r\n-        pathList.add(file.getPath());\r\n-        length = length + file.getLen();\r\n-        FileSystem fs = file.getPath()\r\n-          .getFileSystem(job.getConfiguration());\r\n-        BlockLocation[] blkLocations =\r\n-          fs.getFileBlockLocations(file, 0,\r\n-            file.getLen());\r\n-        for (BlockLocation blockLocation : blkLocations) {\r\n-          for (String host : blockLocation\r\n-            .getHosts()) {\r\n-            hostSet.add(host);\r\n-          }\r\n-        }\r\n-        rest--;\r\n-        LOG.info(\"Split on host: \"\r\n-          + getHostsString(hostSet));\r\n-        splits.add(\r\n-          new MultiFileSplit(pathList, length,\r\n-            hostSet.toArray(new String[0])));\r\n-        tmp = 0;\r\n-        length = 0;\r\n-      }\r\n+    // randomizeFileListOrder(files);\n+    int avg = files.size() / numMaps;\n+    int rest = files.size()\n+% numMaps;\n+    int tmp = 0;\n+    long length = 0;\n+    List<Path> pathList = null;\n+    Set<String> hostSet = null;\n+    for (FileStatus file : files) {\n+      if (tmp == 0) {\n+        pathList = new ArrayList<Path>();\n+        hostSet = new HashSet<String>();\n+      }\n+      if (tmp < avg) {\n+        pathList.add(file.getPath());\n+        length = length + file.getLen();\n+        FileSystem fs = file.getPath().getFileSystem(job.getConfiguration());\n+        BlockLocation[] blkLocations = fs.getFileBlockLocations(file, 0, file.getLen());\n+        for (BlockLocation blockLocation : blkLocations) {\n+          for (String host : blockLocation.getHosts()) {\n+            hostSet.add(host);\n+          }\n+        }\n+        tmp++;\n+        if (tmp == avg\n+            && rest == 0) {\n+          LOG.info(\"Split on host: \" + getHostsString(hostSet));\n+          splits.add(new MultiFileSplit(pathList, length, hostSet.toArray(new String[0])));\n+          tmp = 0;\n+          length = 0;\n+        }\n+      } else if (tmp == avg\n+                 && rest > 0) {\n+        pathList.add(file.getPath());\n+        length = length + file.getLen();\n+        FileSystem fs = file.getPath().getFileSystem(job.getConfiguration());\n+        BlockLocation[] blkLocations = fs.getFileBlockLocations(file, 0, file.getLen());\n+        for (BlockLocation blockLocation : blkLocations) {\n+          for (String host : blockLocation.getHosts()) {\n+            hostSet.add(host);\n+          }\n+        }\n+        rest--;\n+        LOG.info(\"Split on host: \" + getHostsString(hostSet));\n+        splits.add(new MultiFileSplit(pathList, length, hostSet.toArray(new String[0])));\n+        tmp = 0;\n+        length = 0;\n+      }\n     }\r\n     // Save the number of input files in the\r\n-    // job-conf\r\n-    job.getConfiguration()\r\n-      .setLong(NUM_INPUT_FILES, numMaps);\r\n-    LOG.info(\r\n-      \"Total # of splits: \" + splits.size());\r\n-    return splits;\r\n-  }\r\n-\r\n-  @SuppressWarnings(\"unused\")\r\n-  private void randomizeFileListOrder(\r\n-    List<FileStatus> files) {\r\n-    Random random =\r\n-      new Random(System.currentTimeMillis());\r\n-    int numFiles = files.size();\r\n-    for (int i = numFiles - 1; i > 0; i--) {\r\n-      int nextRandom = random.nextInt(i + 1);\r\n-      if (nextRandom != i) {\r\n-        FileStatus tmpFile = files.get(i);\r\n-        files.set(i, files.get(nextRandom));\r\n-        files.set(nextRandom, tmpFile);\r\n-      }\r\n-    }\r\n-  }\r\n-\r\n-  private String\r\n-    getHostsString(Set<String> hosts) {\r\n-    StringBuffer buffer = new StringBuffer();\r\n-    for (String host : hosts) {\r\n-      buffer.append(host + \" \");\r\n-    }\r\n-    return buffer.toString();\r\n-  }\r\n-\r\n-  @Override\r\n-  public RecordReader<String, String>\r\n-    createRecordReader(InputSplit split,\r\n-      TaskAttemptContext context)\r\n-      throws IOException, InterruptedException {\r\n-    return new MultiFileRecordReader();\r\n-  }\r\n-}\r\n+    // job-conf\n+    job.getConfiguration().setLong(NUM_INPUT_FILES, numMaps);\n+    LOG.info(\"Total # of splits: \" + splits.size());\n+    return splits;\n+  }\n+\n+\n+  @SuppressWarnings(\"unused\")\n+  private void randomizeFileListOrder(List<FileStatus> files) {\n+    Random random = new Random(System.currentTimeMillis());\n+    int numFiles = files.size();\n+    for (int i = numFiles - 1; i > 0; i--) {\n+      int nextRandom = random.nextInt(i + 1);\n+      if (nextRandom != i) {\n+        FileStatus tmpFile = files.get(i);\n+        files.set(i, files.get(nextRandom));\n+        files.set(nextRandom, tmpFile);\n+      }\n+    }\n+  }\n+\n+  private String getHostsString(Set<String> hosts) {\n+    StringBuffer buffer = new StringBuffer();\n+    for (String host : hosts) {\n+      buffer.append(host + \" \");\n+    }\n+    return buffer.toString();\n+  }\n+\n+\n+  @Override\n+  public RecordReader<String, String> createRecordReader(InputSplit split,\n+                                                         TaskAttemptContext context)\n+                                                           throws IOException, InterruptedException {\n+    return new MultiFileRecordReader();\n+  }\n+}\n\\ No newline at end of file\n",
            "diff_size": 142
        },
        {
            "tool": "styler_random",
            "errors": [
                {
                    "line": "3",
                    "severity": "error",
                    "message": "Line has trailing spaces.",
                    "source": "com.puppycrawl.tools.checkstyle.checks.regexp.RegexpSinglelineCheck"
                }
            ],
            "diff": "",
            "diff_size": 0
        },
        {
            "tool": "styler_three_grams",
            "errors": [
                {
                    "line": "3",
                    "severity": "error",
                    "message": "Line has trailing spaces.",
                    "source": "com.puppycrawl.tools.checkstyle.checks.regexp.RegexpSinglelineCheck"
                }
            ],
            "diff": "",
            "diff_size": 0
        }
    ],
    "repaired_by": [
        "intellij"
    ],
    "not_repaired_by": [
        "styler",
        "naturalize",
        "codebuff",
        "styler_random",
        "styler_three_grams"
    ]
}