[
    ".gitignore",
    "01_loggen",
    "01_loggen/README.md",
    "01_loggen/generate_apache_logs.py",
    "01_loggen/generate_apache_logs.sh",
    "02_ingestion",
    "02_ingestion/Flume",
    "02_ingestion/Flume/README.md",
    "02_ingestion/Flume/client.conf",
    "02_ingestion/Flume/collector1.conf",
    "02_ingestion/Flume/collector2.conf",
    "02_ingestion/Flume/start_client.sh",
    "02_ingestion/Flume/start_collector1.sh",
    "02_ingestion/Flume/start_collector2.sh",
    "03_processing",
    "03_processing/01_dedup",
    "03_processing/01_dedup/pig",
    "03_processing/01_dedup/pig/dedup.pig",
    "03_processing/01_dedup/pig/dedup.sh",
    "03_processing/02_sessionization",
    "03_processing/02_sessionization/deprecated-hive",
    "03_processing/02_sessionization/deprecated-hive/01-create-raw-log-table.hql",
    "03_processing/02_sessionization/deprecated-hive/02-create-parquet-log-table.hql",
    "03_processing/02_sessionization/deprecated-hive/03-populate-parquet-log-table.hql",
    "03_processing/02_sessionization/deprecated-hive/04-query-parquet-log-table.hql",
    "03_processing/02_sessionization/deprecated-hive/run_all.sh",
    "03_processing/02_sessionization/mr",
    "03_processing/02_sessionization/mr/MRSessionize.iml",
    "03_processing/02_sessionization/mr/README.md",
    "03_processing/02_sessionization/mr/pom.xml",
    "03_processing/02_sessionization/mr/run.sh",
    "03_processing/02_sessionization/mr/src",
    "03_processing/02_sessionization/mr/src/main",
    "03_processing/02_sessionization/mr/src/main/java",
    "03_processing/02_sessionization/mr/src/main/java/com",
    "03_processing/02_sessionization/mr/src/main/java/com/hadooparchitecturebook",
    "03_processing/02_sessionization/mr/src/main/java/com/hadooparchitecturebook/CompositeKeyComparator.java",
    "03_processing/02_sessionization/mr/src/main/java/com/hadooparchitecturebook/IpTimestampKey.java",
    "03_processing/02_sessionization/mr/src/main/java/com/hadooparchitecturebook/MRSessionize.java",
    "03_processing/02_sessionization/mr/src/main/java/com/hadooparchitecturebook/NaturalKeyComparator.java",
    "03_processing/02_sessionization/mr/src/main/java/com/hadooparchitecturebook/NaturalKeyPartitioner.java",
    "03_processing/02_sessionization/spark",
    "03_processing/02_sessionization/spark/JavaSessionize.iml",
    "03_processing/02_sessionization/spark/README.md",
    "03_processing/02_sessionization/spark/pom.xml",
    "03_processing/02_sessionization/spark/spark_sessionize.sh",
    "03_processing/02_sessionization/spark/src",
    "03_processing/02_sessionization/spark/src/main",
    "03_processing/02_sessionization/spark/src/main/java",
    "03_processing/02_sessionization/spark/src/main/java/com",
    "03_processing/02_sessionization/spark/src/main/java/com/hadooparchitecturebook",
    "03_processing/02_sessionization/spark/src/main/java/com/hadooparchitecturebook/clickstream",
    "03_processing/02_sessionization/spark/src/main/java/com/hadooparchitecturebook/clickstream/JavaSessionize.java",
    "03_processing/02_sessionization/spark/src/main/resources",
    "03_processing/02_sessionization/spark/src/main/resources/avro",
    "03_processing/02_sessionization/spark/src/main/resources/avro/LogLine.avsc",
    "03_processing/03_parquetize",
    "03_processing/03_parquetize/hive",
    "03_processing/03_parquetize/hive/01-create-sessionized-log-table.hql",
    "03_processing/03_parquetize/hive/01_parquetize.hql",
    "03_processing/03_parquetize/hive/02-create-parquet-log-table.hql",
    "03_processing/03_parquetize/hive/03-populate-parquet-log-table.hql",
    "03_processing/03_parquetize/hive/run_all.sh",
    "03_processing/04_query",
    "03_processing/04_query/query-parquet-log-table.hql",
    "04_orchestration",
    "04_orchestration/.gitignore",
    "04_orchestration/coord-app.xml",
    "04_orchestration/dedup.pig",
    "04_orchestration/job.properties",
    "04_orchestration/processing.xml",
    "04_orchestration/run.sh",
    "04_orchestration/setup.sh",
    "LICENSE",
    "README.md",
    "cleanup.sh",
    "setup.sh"
]